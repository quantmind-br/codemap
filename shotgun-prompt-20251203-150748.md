## Context

You are an AI assistant helping with software development tasks.

**Current Date:** 2025-12-03 15:07:48

---

## Task Description

Faça uma análise crítica de PLAN.md e sugira melhorias no plano, seja em funcionalidades ou na implementação.

---

## Project Constraints & Rules



---

## Project Structure

└── codemap/
    ├── assets/
    ├── development-docs/
    │   ├── 0001-enhanced-code-analysis-plan.md [41.0KB]
    │   ├── 0001-enhanced-code-analysis.md [7.0KB]
    │   ├── 0002-token-heuristics-symbol-search-plan.md [16.1KB]
    │   └── 0002-token-heuristics-symbol-search.md [9.1KB]
    ├── mcp/
    │   └── main.go [16.9KB]
    ├── render/
    │   ├── api.go [3.9KB]
    │   ├── colors.go [3.3KB]
    │   ├── depgraph.go [11.3KB]
    │   ├── skyline.go [16.0KB]
    │   └── tree.go [10.9KB]
    ├── scanner/
    │   ├── grammars/
    │   ├── queries/
    │   │   ├── bash.scm [252B]
    │   │   ├── c.scm [413B]
    │   │   ├── c_sharp.scm [781B]
    │   │   ├── cpp.scm [442B]
    │   │   ├── dart.scm [559B]
    │   │   ├── go.scm [749B]
    │   │   ├── java.scm [660B]
    │   │   ├── javascript.scm [827B]
    │   │   ├── kotlin.scm [181B]
    │   │   ├── php.scm [459B]
    │   │   ├── python.scm [540B]
    │   │   ├── r.scm [783B]
    │   │   ├── ruby.scm [449B]
    │   │   ├── rust.scm [631B]
    │   │   ├── swift.scm [361B]
    │   │   └── typescript.scm [928B]
    │   ├── build-grammars.sh [3.4KB]
    │   ├── deps.go [4.2KB]
    │   ├── git.go [6.8KB]
    │   ├── grammar.go [12.0KB]
    │   ├── grammar_unix.go [618B]
    │   ├── grammar_windows.go [795B]
    │   ├── symbol.go [1.9KB]
    │   ├── types.go [4.7KB]
    │   └── walker.go [3.3KB]
    ├── CLAUDE.md [2.4KB]
    ├── CODE_OF_CONDUCT.md [5.1KB]
    ├── CONTRIBUTING.md [2.3KB]
    ├── LICENSE [1.0KB]
    ├── Makefile [1.5KB]
    ├── PLAN.md [87.8KB]
    ├── README.md [16.1KB]
    ├── README.pt-br.md [11.7KB]
    ├── codemap.rb [5.1KB]
    ├── go.mod [1.5KB]
    ├── go.sum [9.1KB]
    ├── main.go [6.8KB]
    └── release.sh [3.1KB]

<file path="development-docs/0001-enhanced-code-analysis-plan.md">
# PLAN.md - Enhanced Code Analysis Features

## Executive Summary

Este plano descreve a implementação de recursos avançados de análise de código para o `codemap`, focando em:
1. **Assinaturas de funções completas** (parâmetros e retornos)
2. **Extração de tipos** (structs, classes, interfaces, traits, enums)
3. **Modo API Surface** para visualização compacta de APIs públicas

O objetivo é fornecer um mapa mais rico para LLMs sem comprometer a token-efficiency que é o diferencial do codemap.

---

## Princípios de Design

### 1. Backward Compatibility
- Output atual deve permanecer inalterado por padrão
- Novas features ativadas via flags opcionais
- JSON schema deve ser extensível sem quebrar consumers

### 2. Token Efficiency
- Modo padrão continua mostrando apenas nomes
- Detalhes extras são opt-in via `--detail`
- Modo `--api` oferece visualização ultra-compacta

### 3. Consistência Semântica
- Tipos são categorizados por `Kind` semântico normalizado
- Cada linguagem mapeia seus constructos para Kinds universais
- Evita falsos cognatos (Rust `trait` ≠ Java `interface`)

---

## Arquitetura de Mudanças

```
┌─────────────────────────────────────────────────────────────────┐
│                         main.go                                  │
│  + --detail flag (0, 1, 2)                                      │
│  + --api flag                                                    │
└─────────────────────────────────────────────────────────────────┘
                                │
                                ▼
┌─────────────────────────────────────────────────────────────────┐
│                      scanner/types.go                            │
│  + FuncInfo struct (Name, Signature, Receiver, IsExported)      │
│  + TypeInfo struct (Name, Kind, Fields, IsExported)             │
│  ~ FileAnalysis (Functions: []string → []FuncInfo)              │
│  ~ FileAnalysis (+ Types: []TypeInfo)                           │
└─────────────────────────────────────────────────────────────────┘
                                │
                                ▼
┌─────────────────────────────────────────────────────────────────┐
│                     scanner/grammar.go                           │
│  ~ AnalyzeFile() - extended capture handling                    │
│  + buildSignature() - reconstructs signature from parts         │
│  + parseTypeInfo() - extracts type metadata                     │
│  + DetailLevel parameter propagation                            │
└─────────────────────────────────────────────────────────────────┘
                                │
                                ▼
┌─────────────────────────────────────────────────────────────────┐
│                    scanner/queries/*.scm                         │
│  ~ All 16 language queries updated with:                        │
│    - @func.name, @func.params, @func.result, @func.receiver     │
│    - @type.name, @type.kind, @type.fields                       │
└─────────────────────────────────────────────────────────────────┘
                                │
                                ▼
┌─────────────────────────────────────────────────────────────────┐
│                      render/depgraph.go                          │
│  ~ Depgraph() - conditional signature display                   │
│  + renderTypes() - type listing in output                       │
└─────────────────────────────────────────────────────────────────┘
                                │
                                ▼
┌─────────────────────────────────────────────────────────────────┐
│                       render/api.go (NEW)                        │
│  + APIView() - compact public API visualization                 │
└─────────────────────────────────────────────────────────────────┘
```

---

## Fase 1: Estruturas de Dados Base

### 1.1 Novos Tipos em `scanner/types.go`

```go
// DetailLevel controls how much information is extracted
type DetailLevel int

const (
    DetailNone      DetailLevel = 0 // Only names (current behavior)
    DetailSignature DetailLevel = 1 // Names + signatures
    DetailFull      DetailLevel = 2 // Signatures + type fields
)

// FuncInfo represents a function/method with optional detail
type FuncInfo struct {
    Name       string `json:"name"`
    Signature  string `json:"signature,omitempty"`  // Full signature when detail >= 1
    Receiver   string `json:"receiver,omitempty"`   // For methods (Go, Rust, etc.)
    IsExported bool   `json:"exported,omitempty"`   // Public visibility
}

// TypeKind represents normalized type categories across languages
type TypeKind string

const (
    KindStruct    TypeKind = "struct"    // Go struct, C struct, Rust struct
    KindClass     TypeKind = "class"     // Python/Java/C#/TS class
    KindInterface TypeKind = "interface" // Go interface, Java/C#/TS interface
    KindTrait     TypeKind = "trait"     // Rust trait
    KindEnum      TypeKind = "enum"      // All languages
    KindTypeAlias TypeKind = "alias"     // Go type alias, TS type
    KindProtocol  TypeKind = "protocol"  // Swift protocol
)

// TypeInfo represents a type definition
type TypeInfo struct {
    Name       string   `json:"name"`
    Kind       TypeKind `json:"kind"`
    Fields     []string `json:"fields,omitempty"`     // Field names when detail = 2
    Methods    []string `json:"methods,omitempty"`    // Method names (for classes)
    IsExported bool     `json:"exported,omitempty"`
}

// FileAnalysis holds extracted info about a single file for deps mode.
// UPDATED: Functions now use FuncInfo, added Types field
type FileAnalysis struct {
    Path      string     `json:"path"`
    Language  string     `json:"language"`
    Functions []FuncInfo `json:"functions"`           // CHANGED from []string
    Types     []TypeInfo `json:"types,omitempty"`     // NEW
    Imports   []string   `json:"imports"`
}
```

### 1.2 Compatibilidade JSON

Para manter backward compatibility na serialização JSON:

```go
// MarshalJSON customizes JSON output based on detail level
func (f FuncInfo) MarshalJSON() ([]byte, error) {
    // Se Signature está vazio, serializa apenas como string (comportamento antigo)
    if f.Signature == "" && f.Receiver == "" {
        return json.Marshal(f.Name)
    }
    // Caso contrário, serializa objeto completo
    type Alias FuncInfo
    return json.Marshal(Alias(f))
}
```

---

## Fase 2: Queries Tree-sitter Expandidas

### 2.1 Estratégia de Captura

**Problema:** Capturar `(function_declaration) @function` inclui o corpo inteiro.

**Solução:** Usar captures nomeados para componentes específicos:
- `@func.name` - nome da função
- `@func.params` - lista de parâmetros (texto do nó)
- `@func.result` - tipo de retorno
- `@func.receiver` - receiver para métodos

O código Go reconstruirá a signature a partir dos componentes.

### 2.2 Query Go (`scanner/queries/go.scm`)

```scheme
; ============================================
; GO QUERY - Enhanced for signatures and types
; ============================================

; --- FUNCTIONS ---

; Function declarations with full signature components
(function_declaration
  name: (identifier) @func.name
  parameters: (parameter_list) @func.params
  result: (_)? @func.result)

; Method declarations (functions with receivers)
(method_declaration
  receiver: (parameter_list) @func.receiver
  name: (field_identifier) @func.name
  parameters: (parameter_list) @func.params
  result: (_)? @func.result)

; --- TYPES ---

; Struct type definitions
(type_declaration
  (type_spec
    name: (type_identifier) @type.name
    type: (struct_type
      (field_declaration_list)? @type.fields))) @type.struct

; Interface type definitions
(type_declaration
  (type_spec
    name: (type_identifier) @type.name
    type: (interface_type
      (method_spec_list)? @type.methods))) @type.interface

; Type aliases
(type_declaration
  (type_spec
    name: (type_identifier) @type.name
    type: (type_identifier) @type.alias.target)) @type.alias

; --- IMPORTS (unchanged) ---
(import_spec
  path: (interpreted_string_literal) @import)
```

### 2.3 Query Python (`scanner/queries/python.scm`)

```scheme
; ============================================
; PYTHON QUERY - Enhanced for signatures and types
; ============================================

; --- FUNCTIONS ---

; Function definitions with parameters
(function_definition
  name: (identifier) @func.name
  parameters: (parameters) @func.params
  return_type: (type)? @func.result)

; Async function definitions
(function_definition
  "async"
  name: (identifier) @func.name
  parameters: (parameters) @func.params
  return_type: (type)? @func.result) @func.async

; --- CLASSES ---

; Class definitions
(class_definition
  name: (identifier) @type.name
  superclasses: (argument_list)? @type.bases) @type.class

; --- IMPORTS (unchanged) ---
(import_statement
  name: (dotted_name) @import)

(import_from_statement
  module_name: (dotted_name) @import)

(import_from_statement
  module_name: (relative_import) @import)
```

### 2.4 Query TypeScript (`scanner/queries/typescript.scm`)

```scheme
; ============================================
; TYPESCRIPT QUERY - Enhanced for signatures and types
; ============================================

; --- FUNCTIONS ---

; Function declarations
(function_declaration
  name: (identifier) @func.name
  parameters: (formal_parameters) @func.params
  return_type: (type_annotation)? @func.result)

; Arrow functions assigned to const/let
(lexical_declaration
  (variable_declarator
    name: (identifier) @func.name
    type: (type_annotation)? @func.result
    value: (arrow_function
      parameters: (formal_parameters) @func.params)))

; Method definitions in classes
(method_definition
  name: (property_identifier) @func.name
  parameters: (formal_parameters) @func.params
  return_type: (type_annotation)? @func.result)

; --- TYPES ---

; Interface declarations
(interface_declaration
  name: (type_identifier) @type.name
  body: (interface_body) @type.fields) @type.interface

; Class declarations
(class_declaration
  name: (type_identifier) @type.name
  body: (class_body) @type.fields) @type.class

; Type aliases
(type_alias_declaration
  name: (type_identifier) @type.name
  value: (_) @type.alias.target) @type.alias

; Enum declarations
(enum_declaration
  name: (identifier) @type.name
  body: (enum_body) @type.fields) @type.enum

; --- IMPORTS (unchanged) ---
(import_statement
  source: (string) @import)
```

### 2.5 Query Rust (`scanner/queries/rust.scm`)

```scheme
; ============================================
; RUST QUERY - Enhanced for signatures and types
; ============================================

; --- FUNCTIONS ---

; Function definitions
(function_item
  name: (identifier) @func.name
  parameters: (parameters) @func.params
  return_type: (_)? @func.result)

; Methods in impl blocks (capture self for receiver detection)
(impl_item
  type: (_) @func.receiver.type
  body: (declaration_list
    (function_item
      name: (identifier) @func.name
      parameters: (parameters) @func.params
      return_type: (_)? @func.result)))

; --- TYPES ---

; Struct definitions
(struct_item
  name: (type_identifier) @type.name
  body: (field_declaration_list)? @type.fields) @type.struct

; Enum definitions
(enum_item
  name: (type_identifier) @type.name
  body: (enum_variant_list) @type.fields) @type.enum

; Trait definitions
(trait_item
  name: (type_identifier) @type.name
  body: (declaration_list) @type.methods) @type.trait

; Type aliases
(type_item
  name: (type_identifier) @type.name
  type: (_) @type.alias.target) @type.alias

; --- IMPORTS (unchanged) ---
(use_declaration
  argument: (scoped_identifier) @import)

(use_declaration
  argument: (identifier) @import)

(mod_item
  name: (identifier) @module)
```

### 2.6 Query Java (`scanner/queries/java.scm`)

```scheme
; ============================================
; JAVA QUERY - Enhanced for signatures and types
; ============================================

; --- FUNCTIONS ---

; Method declarations
(method_declaration
  type: (_) @func.result
  name: (identifier) @func.name
  parameters: (formal_parameters) @func.params)

; Constructor declarations
(constructor_declaration
  name: (identifier) @func.name
  parameters: (formal_parameters) @func.params)

; --- TYPES ---

; Class declarations
(class_declaration
  name: (identifier) @type.name
  interfaces: (super_interfaces)? @type.implements
  body: (class_body) @type.fields) @type.class

; Interface declarations
(interface_declaration
  name: (identifier) @type.name
  body: (interface_body) @type.methods) @type.interface

; Enum declarations
(enum_declaration
  name: (identifier) @type.name
  body: (enum_body) @type.fields) @type.enum

; --- IMPORTS (unchanged) ---
(import_declaration
  (scoped_identifier) @import)
```

### 2.7 Query C# (`scanner/queries/c_sharp.scm`)

```scheme
; ============================================
; C# QUERY - Enhanced for signatures and types
; ============================================

; --- FUNCTIONS ---

; Method declarations
(method_declaration
  returns: (_) @func.result
  name: (identifier) @func.name
  parameters: (parameter_list) @func.params)

; Constructor declarations
(constructor_declaration
  name: (identifier) @func.name
  parameters: (parameter_list) @func.params)

; --- TYPES ---

; Class declarations
(class_declaration
  name: (identifier) @type.name
  bases: (base_list)? @type.bases
  body: (declaration_list) @type.fields) @type.class

; Interface declarations
(interface_declaration
  name: (identifier) @type.name
  body: (declaration_list) @type.methods) @type.interface

; Struct declarations
(struct_declaration
  name: (identifier) @type.name
  body: (declaration_list) @type.fields) @type.struct

; Enum declarations
(enum_declaration
  name: (identifier) @type.name
  body: (enum_member_declaration_list) @type.fields) @type.enum

; --- IMPORTS (unchanged) ---
(using_directive
  (qualified_name) @import)

(using_directive
  (identifier) @import)
```

---

## Fase 3: Lógica de Análise Expandida

### 3.1 Modificação em `scanner/grammar.go`

```go
// AnalyzeFile extracts functions, types, and imports
// detailLevel controls depth of extraction:
//   0 = names only (current behavior)
//   1 = names + signatures
//   2 = names + signatures + type fields
func (l *GrammarLoader) AnalyzeFile(filePath string, detailLevel DetailLevel) (*FileAnalysis, error) {
    lang := DetectLanguage(filePath)
    if lang == "" {
        return nil, nil
    }

    if err := l.LoadLanguage(lang); err != nil {
        return nil, nil
    }

    config := l.configs[lang]
    content, err := os.ReadFile(filePath)
    if err != nil {
        return nil, err
    }

    parser := tree_sitter.NewParser()
    defer parser.Close()
    parser.SetLanguage(config.Language)

    tree := parser.Parse(content, nil)
    defer tree.Close()

    cursor := tree_sitter.NewQueryCursor()
    defer cursor.Close()

    analysis := &FileAnalysis{Path: filePath, Language: lang}

    // Temporary storage for building composite captures
    funcBuilder := make(map[uint32]*funcCapture) // match_id -> components
    typeBuilder := make(map[uint32]*typeCapture)

    matches := cursor.Matches(config.Query, tree.RootNode(), content)
    for match := matches.Next(); match != nil; match = matches.Next() {
        for _, capture := range match.Captures {
            name := config.Query.CaptureNames()[capture.Index]
            text := strings.Trim(capture.Node.Utf8Text(content), `"'`)

            // Route to appropriate handler based on capture name prefix
            switch {
            case strings.HasPrefix(name, "func."):
                handleFuncCapture(funcBuilder, match.ID, name, text, capture.Node)
            case strings.HasPrefix(name, "type."):
                handleTypeCapture(typeBuilder, match.ID, name, text, capture.Node, detailLevel)
            case name == "import" || name == "module":
                analysis.Imports = append(analysis.Imports, text)
            // Legacy support: plain @function capture
            case name == "function" || name == "method":
                analysis.Functions = append(analysis.Functions, FuncInfo{Name: text})
            }
        }
    }

    // Build final function list from captured components
    for _, fc := range funcBuilder {
        funcInfo := fc.Build(detailLevel, lang)
        analysis.Functions = append(analysis.Functions, funcInfo)
    }

    // Build final type list
    for _, tc := range typeBuilder {
        typeInfo := tc.Build(detailLevel)
        analysis.Types = append(analysis.Types, typeInfo)
    }

    analysis.Functions = dedupeFuncs(analysis.Functions)
    analysis.Types = dedupeTypes(analysis.Types)
    analysis.Imports = dedupe(analysis.Imports)

    return analysis, nil
}

// funcCapture collects components of a function signature
type funcCapture struct {
    name     string
    params   string
    result   string
    receiver string
    node     *tree_sitter.Node
}

// Build constructs FuncInfo from captured components
func (fc *funcCapture) Build(detail DetailLevel, lang string) FuncInfo {
    info := FuncInfo{
        Name:       fc.name,
        IsExported: isExported(fc.name, lang),
    }

    if detail >= DetailSignature && fc.params != "" {
        info.Signature = buildSignature(fc, lang)
    }

    if fc.receiver != "" {
        info.Receiver = fc.receiver
    }

    return info
}

// buildSignature reconstructs function signature from components
func buildSignature(fc *funcCapture, lang string) string {
    var sig strings.Builder

    switch lang {
    case "go":
        sig.WriteString("func ")
        if fc.receiver != "" {
            sig.WriteString(fc.receiver)
            sig.WriteString(" ")
        }
        sig.WriteString(fc.name)
        sig.WriteString(fc.params)
        if fc.result != "" {
            sig.WriteString(" ")
            sig.WriteString(fc.result)
        }

    case "python":
        sig.WriteString("def ")
        sig.WriteString(fc.name)
        sig.WriteString(fc.params)
        if fc.result != "" {
            sig.WriteString(" -> ")
            sig.WriteString(fc.result)
        }

    case "typescript", "javascript":
        sig.WriteString("function ")
        sig.WriteString(fc.name)
        sig.WriteString(fc.params)
        if fc.result != "" {
            sig.WriteString(": ")
            sig.WriteString(fc.result)
        }

    case "rust":
        sig.WriteString("fn ")
        sig.WriteString(fc.name)
        sig.WriteString(fc.params)
        if fc.result != "" {
            sig.WriteString(" -> ")
            sig.WriteString(fc.result)
        }

    case "java", "c_sharp":
        if fc.result != "" {
            sig.WriteString(fc.result)
            sig.WriteString(" ")
        }
        sig.WriteString(fc.name)
        sig.WriteString(fc.params)

    default:
        sig.WriteString(fc.name)
        sig.WriteString(fc.params)
    }

    return sig.String()
}

// isExported checks if a symbol is publicly visible
func isExported(name, lang string) bool {
    if name == "" {
        return false
    }

    switch lang {
    case "go":
        // Go: exported if starts with uppercase
        r := []rune(name)
        return unicode.IsUpper(r[0])

    case "python":
        // Python: exported if doesn't start with _
        return !strings.HasPrefix(name, "_")

    case "rust":
        // Rust: would need `pub` keyword analysis
        // For now, assume all are potentially public
        return true

    default:
        // Most languages: assume public unless private keyword
        return true
    }
}

// typeCapture collects components of a type definition
type typeCapture struct {
    name   string
    kind   TypeKind
    fields string // Raw text of fields block
    node   *tree_sitter.Node
}

// Build constructs TypeInfo from captured components
func (tc *typeCapture) Build(detail DetailLevel) TypeInfo {
    info := TypeInfo{
        Name: tc.name,
        Kind: tc.kind,
    }

    if detail >= DetailFull && tc.fields != "" {
        info.Fields = parseFieldNames(tc.fields)
    }

    return info
}

// parseFieldNames extracts field/member names from raw block text
func parseFieldNames(fieldsText string) []string {
    // Simple extraction: find identifiers at start of lines
    var fields []string
    lines := strings.Split(fieldsText, "\n")

    for _, line := range lines {
        line = strings.TrimSpace(line)
        if line == "" || line == "{" || line == "}" {
            continue
        }

        // Extract first identifier (field name)
        parts := strings.Fields(line)
        if len(parts) > 0 {
            name := strings.TrimSuffix(parts[0], ":")
            name = strings.TrimSuffix(name, ",")
            if name != "" && !strings.HasPrefix(name, "//") {
                fields = append(fields, name)
            }
        }
    }

    return fields
}
```

### 3.2 Handler para Captures

```go
// handleFuncCapture routes function-related captures to builder
func handleFuncCapture(builders map[uint32]*funcCapture, matchID uint32, name, text string, node *tree_sitter.Node) {
    if builders[matchID] == nil {
        builders[matchID] = &funcCapture{}
    }
    fc := builders[matchID]

    switch name {
    case "func.name":
        fc.name = text
    case "func.params":
        fc.params = text
    case "func.result":
        fc.result = text
    case "func.receiver":
        fc.receiver = text
    }
    fc.node = node
}

// handleTypeCapture routes type-related captures to builder
func handleTypeCapture(builders map[uint32]*typeCapture, matchID uint32, name, text string, node *tree_sitter.Node, detail DetailLevel) {
    if builders[matchID] == nil {
        builders[matchID] = &typeCapture{}
    }
    tc := builders[matchID]

    switch name {
    case "type.name":
        tc.name = text
    case "type.fields", "type.methods":
        if detail >= DetailFull {
            tc.fields = text
        }
    case "type.struct":
        tc.kind = KindStruct
    case "type.class":
        tc.kind = KindClass
    case "type.interface":
        tc.kind = KindInterface
    case "type.trait":
        tc.kind = KindTrait
    case "type.enum":
        tc.kind = KindEnum
    case "type.alias":
        tc.kind = KindTypeAlias
    case "type.protocol":
        tc.kind = KindProtocol
    }
    tc.node = node
}
```

---

## Fase 4: CLI e Flags

### 4.1 Modificação em `main.go`

```go
func main() {
    // Existing flags...
    skylineMode := flag.Bool("skyline", false, "Enable skyline visualization mode")
    animateMode := flag.Bool("animate", false, "Enable animation (use with --skyline)")
    depsMode := flag.Bool("deps", false, "Enable dependency graph mode (function/import analysis)")
    diffMode := flag.Bool("diff", false, "Only show files changed vs main (or use --ref to specify branch)")
    diffRef := flag.String("ref", "main", "Branch/ref to compare against (use with --diff)")
    jsonMode := flag.Bool("json", false, "Output JSON (for Python renderer compatibility)")
    debugMode := flag.Bool("debug", false, "Show debug info (gitignore loading, paths, etc.)")
    helpMode := flag.Bool("help", false, "Show help")

    // NEW FLAGS
    detailLevel := flag.Int("detail", 0, "Detail level: 0=names, 1=signatures, 2=full (use with --deps)")
    apiMode := flag.Bool("api", false, "Show public API surface only (compact view)")

    flag.Parse()

    // ... rest of main
}

func runDepsMode(absRoot, root string, gitignore *ignore.GitIgnore, jsonMode bool, diffRef string, changedFiles map[string]bool, detailLevel int, apiMode bool) {
    loader := scanner.NewGrammarLoader()

    // ... grammar check ...

    analyses, err := scanner.ScanForDeps(root, gitignore, loader, scanner.DetailLevel(detailLevel))
    if err != nil {
        fmt.Fprintf(os.Stderr, "Error scanning for deps: %v\n", err)
        os.Exit(1)
    }

    // ... filter changed files ...

    depsProject := scanner.DepsProject{
        Root:         absRoot,
        Mode:         "deps",
        Files:        analyses,
        ExternalDeps: scanner.ReadExternalDeps(absRoot),
        DiffRef:      diffRef,
        DetailLevel:  detailLevel, // NEW field
    }

    if jsonMode {
        json.NewEncoder(os.Stdout).Encode(depsProject)
    } else if apiMode {
        render.APIView(depsProject) // NEW renderer
    } else {
        render.Depgraph(depsProject)
    }
}
```

### 4.2 Help Text Atualizado

```go
if *helpMode {
    fmt.Println("codemap - Generate a brain map of your codebase for LLM context")
    fmt.Println()
    fmt.Println("Usage: codemap [options] [path]")
    fmt.Println()
    fmt.Println("Options:")
    fmt.Println("  --help              Show this help message")
    fmt.Println("  --skyline           City skyline visualization")
    fmt.Println("  --animate           Animated skyline (use with --skyline)")
    fmt.Println("  --deps              Dependency flow map (functions & imports)")
    fmt.Println("  --detail <level>    Detail level for --deps: 0=names, 1=signatures, 2=full")
    fmt.Println("  --api               Show public API surface (compact, use with --deps)")
    fmt.Println("  --diff              Only show files changed vs main")
    fmt.Println("  --ref <branch>      Branch to compare against (default: main)")
    fmt.Println()
    fmt.Println("Examples:")
    fmt.Println("  codemap .                       # Basic tree view")
    fmt.Println("  codemap --deps .                # Dependency flow (names only)")
    fmt.Println("  codemap --deps --detail 1 .    # Dependencies with signatures")
    fmt.Println("  codemap --deps --api .         # Public API surface view")
    fmt.Println("  codemap --deps --detail 2 .    # Full detail with type fields")
    os.Exit(0)
}
```

---

## Fase 5: Renderização

### 5.1 Modificação em `render/depgraph.go`

```go
// Depgraph renders the dependency flow visualization
func Depgraph(project scanner.DepsProject) {
    files := project.Files
    detailLevel := project.DetailLevel

    // ... existing code ...

    // Render each system
    for _, system := range systemNames {
        sysFiles := systems[system]
        systemName := getSystemName(system)

        // ... existing header code ...

        for _, f := range sysFiles {
            basename := filepath.Base(f.Path)
            nameNoExt := extPattern.ReplaceAllString(basename, "")

            // NEW: Show types if present
            if len(f.Types) > 0 && detailLevel >= 1 {
                renderTypes(f.Types, detailLevel)
            }

            // ... existing dependency rendering ...

            // NEW: Show function signatures if detail level warrants
            if detailLevel >= 1 {
                renderFunctionsDetailed(f.Functions)
            }
        }
    }

    // ... existing summary code ...
}

// renderTypes displays type definitions
func renderTypes(types []scanner.TypeInfo, detail int) {
    for _, t := range types {
        icon := typeIcon(t.Kind)
        if detail >= 2 && len(t.Fields) > 0 {
            fmt.Printf("    %s %s { %s }\n", icon, t.Name, strings.Join(t.Fields, ", "))
        } else {
            fmt.Printf("    %s %s\n", icon, t.Name)
        }
    }
}

// typeIcon returns an ASCII icon for the type kind
func typeIcon(kind scanner.TypeKind) string {
    switch kind {
    case scanner.KindStruct:
        return "[S]"
    case scanner.KindClass:
        return "[C]"
    case scanner.KindInterface:
        return "[I]"
    case scanner.KindTrait:
        return "[T]"
    case scanner.KindEnum:
        return "[E]"
    case scanner.KindTypeAlias:
        return "[A]"
    case scanner.KindProtocol:
        return "[P]"
    default:
        return "[?]"
    }
}

// renderFunctionsDetailed shows functions with signatures
func renderFunctionsDetailed(funcs []scanner.FuncInfo) {
    for _, f := range funcs {
        if f.Signature != "" {
            fmt.Printf("      ƒ %s\n", f.Signature)
        } else {
            fmt.Printf("      ƒ %s()\n", f.Name)
        }
    }
}
```

### 5.2 Novo arquivo `render/api.go`

```go
package render

import (
    "fmt"
    "path/filepath"
    "sort"
    "strings"

    "codemap/scanner"
)

// APIView renders a compact public API surface view
func APIView(project scanner.DepsProject) {
    files := project.Files
    projectName := filepath.Base(project.Root)

    if len(files) == 0 {
        fmt.Println("  No source files found.")
        return
    }

    fmt.Println()
    fmt.Printf("=== API Surface: %s ===\n", projectName)
    fmt.Println()

    // Group by directory
    packages := make(map[string][]scanner.FileAnalysis)
    for _, f := range files {
        dir := filepath.Dir(f.Path)
        if dir == "." {
            dir = projectName
        }
        packages[dir] = append(packages[dir], f)
    }

    // Sort package names
    var pkgNames []string
    for name := range packages {
        pkgNames = append(pkgNames, name)
    }
    sort.Strings(pkgNames)

    for _, pkg := range pkgNames {
        pkgFiles := packages[pkg]

        // Collect all exported types and functions
        var exportedTypes []scanner.TypeInfo
        var exportedFuncs []scanner.FuncInfo

        for _, f := range pkgFiles {
            for _, t := range f.Types {
                if t.IsExported {
                    exportedTypes = append(exportedTypes, t)
                }
            }
            for _, fn := range f.Functions {
                if fn.IsExported {
                    exportedFuncs = append(exportedFuncs, fn)
                }
            }
        }

        // Skip packages with no exports
        if len(exportedTypes) == 0 && len(exportedFuncs) == 0 {
            continue
        }

        fmt.Printf("%s/\n", pkg)

        // Group methods by receiver type
        methodsByType := make(map[string][]scanner.FuncInfo)
        var standaloneFuncs []scanner.FuncInfo

        for _, fn := range exportedFuncs {
            if fn.Receiver != "" {
                // Extract type name from receiver
                typeName := extractTypeName(fn.Receiver)
                methodsByType[typeName] = append(methodsByType[typeName], fn)
            } else {
                standaloneFuncs = append(standaloneFuncs, fn)
            }
        }

        // Print types with their methods
        for _, t := range exportedTypes {
            icon := typeIcon(t.Kind)

            if len(t.Fields) > 0 {
                fmt.Printf("  %s %s {%s}\n", icon, t.Name, strings.Join(t.Fields, ", "))
            } else {
                fmt.Printf("  %s %s\n", icon, t.Name)
            }

            // Print methods for this type
            if methods, ok := methodsByType[t.Name]; ok {
                for _, m := range methods {
                    if m.Signature != "" {
                        fmt.Printf("    + %s\n", m.Signature)
                    } else {
                        fmt.Printf("    + (%s) %s()\n", m.Receiver, m.Name)
                    }
                }
            }
        }

        // Print standalone functions
        if len(standaloneFuncs) > 0 {
            for _, fn := range standaloneFuncs {
                if fn.Signature != "" {
                    fmt.Printf("  + %s\n", fn.Signature)
                } else {
                    fmt.Printf("  + %s()\n", fn.Name)
                }
            }
        }

        fmt.Println()
    }

    // Summary
    totalTypes := 0
    totalFuncs := 0
    for _, f := range files {
        for _, t := range f.Types {
            if t.IsExported {
                totalTypes++
            }
        }
        for _, fn := range f.Functions {
            if fn.IsExported {
                totalFuncs++
            }
        }
    }

    fmt.Printf("─────────────────────────────────────────────────────────────\n")
    fmt.Printf("Exported: %d types · %d functions\n", totalTypes, totalFuncs)
    fmt.Println()
}

// extractTypeName extracts type name from receiver like "(l *GrammarLoader)"
func extractTypeName(receiver string) string {
    // Remove parentheses
    r := strings.Trim(receiver, "()")

    // Split by space, take last part (the type)
    parts := strings.Fields(r)
    if len(parts) == 0 {
        return ""
    }

    typePart := parts[len(parts)-1]
    // Remove pointer asterisk
    return strings.TrimPrefix(typePart, "*")
}
```

---

## Fase 6: MCP Server Updates

### 6.1 Modificação em `mcp/main.go`

Atualizar as tools MCP para suportar o novo detail level:

```go
// get_dependencies tool - add detail parameter
case "get_dependencies":
    path := getStringArg(args, "path", ".")
    detail := getIntArg(args, "detail", 0) // NEW

    absPath, _ := filepath.Abs(path)
    gitignore := scanner.LoadGitignore(absPath)
    loader := scanner.NewGrammarLoader()

    if !loader.HasGrammars() {
        return mcp.NewToolResultError("No tree-sitter grammars found")
    }

    analyses, err := scanner.ScanForDeps(absPath, gitignore, loader, scanner.DetailLevel(detail))
    if err != nil {
        return mcp.NewToolResultError(err.Error())
    }

    project := scanner.DepsProject{
        Root:         absPath,
        Mode:         "deps",
        Files:        analyses,
        ExternalDeps: scanner.ReadExternalDeps(absPath),
        DetailLevel:  detail,
    }

    result, _ := json.MarshalIndent(project, "", "  ")
    return mcp.NewToolResultText(string(result))
```

---

## Fase 7: Testes

### 7.1 Estrutura de Testes

```
scanner/
  grammar_test.go      # Test signature extraction
  types_test.go        # Test type parsing

render/
  api_test.go          # Test API view rendering

testdata/
  go/
    sample.go          # Test Go parsing
  python/
    sample.py          # Test Python parsing
  typescript/
    sample.ts          # Test TS parsing
  rust/
    sample.rs          # Test Rust parsing
```

### 7.2 Test Cases para Go

```go
// scanner/grammar_test.go
func TestAnalyzeGoSignatures(t *testing.T) {
    loader := NewGrammarLoader()

    // Create temp file with test content
    content := `package test

type Config struct {
    Name string
    Port int
}

type Handler interface {
    Handle(ctx context.Context, req Request) (Response, error)
}

func NewConfig(name string, port int) *Config {
    return &Config{Name: name, Port: port}
}

func (c *Config) Validate() error {
    if c.Port < 0 {
        return errors.New("invalid port")
    }
    return nil
}
`
    tmpFile := createTempFile(t, "test.go", content)
    defer os.Remove(tmpFile)

    // Test detail level 0 (names only)
    analysis, err := loader.AnalyzeFile(tmpFile, DetailNone)
    require.NoError(t, err)
    require.Len(t, analysis.Functions, 2)
    assert.Equal(t, "NewConfig", analysis.Functions[0].Name)
    assert.Empty(t, analysis.Functions[0].Signature)

    // Test detail level 1 (signatures)
    analysis, err = loader.AnalyzeFile(tmpFile, DetailSignature)
    require.NoError(t, err)
    require.Len(t, analysis.Functions, 2)
    assert.Equal(t, "func NewConfig(name string, port int) *Config", analysis.Functions[0].Signature)
    assert.Equal(t, "func (c *Config) Validate() error", analysis.Functions[1].Signature)

    // Test types
    require.Len(t, analysis.Types, 2)
    assert.Equal(t, "Config", analysis.Types[0].Name)
    assert.Equal(t, KindStruct, analysis.Types[0].Kind)
    assert.Equal(t, "Handler", analysis.Types[1].Name)
    assert.Equal(t, KindInterface, analysis.Types[1].Kind)

    // Test detail level 2 (fields)
    analysis, err = loader.AnalyzeFile(tmpFile, DetailFull)
    require.NoError(t, err)
    assert.Contains(t, analysis.Types[0].Fields, "Name")
    assert.Contains(t, analysis.Types[0].Fields, "Port")
}
```

### 7.3 Test Cases para Python

```go
func TestAnalyzePythonSignatures(t *testing.T) {
    content := `
class UserService:
    def __init__(self, db: Database):
        self.db = db

    async def get_user(self, user_id: int) -> User:
        return await self.db.get(user_id)

    def _private_method(self):
        pass

def create_app(config: Config) -> Application:
    return Application(config)
`
    tmpFile := createTempFile(t, "test.py", content)
    defer os.Remove(tmpFile)

    loader := NewGrammarLoader()
    analysis, err := loader.AnalyzeFile(tmpFile, DetailSignature)
    require.NoError(t, err)

    // Check class
    require.Len(t, analysis.Types, 1)
    assert.Equal(t, "UserService", analysis.Types[0].Name)
    assert.Equal(t, KindClass, analysis.Types[0].Kind)

    // Check functions
    require.Len(t, analysis.Functions, 4)

    // Check exported detection
    var exported []string
    for _, f := range analysis.Functions {
        if f.IsExported {
            exported = append(exported, f.Name)
        }
    }
    assert.Contains(t, exported, "__init__")
    assert.Contains(t, exported, "get_user")
    assert.Contains(t, exported, "create_app")
    assert.NotContains(t, exported, "_private_method")
}
```

---

## Cronograma de Implementação

### Sprint 1: Fundação (Types + Basic Signatures)
- [ ] Implementar `FuncInfo` e `TypeInfo` em `types.go`
- [ ] Atualizar `FileAnalysis` struct
- [ ] Implementar JSON marshaling customizado
- [ ] Adicionar flag `--detail` em `main.go`
- [ ] Atualizar `ScanForDeps` para aceitar `DetailLevel`

### Sprint 2: Go + Python Queries
- [ ] Reescrever `go.scm` com captures granulares
- [ ] Reescrever `python.scm` com captures granulares
- [ ] Implementar `handleFuncCapture` e `handleTypeCapture`
- [ ] Implementar `buildSignature` para Go e Python
- [ ] Escrever testes unitários

### Sprint 3: TypeScript/JavaScript + Rust
- [ ] Reescrever `typescript.scm`
- [ ] Reescrever `javascript.scm`
- [ ] Reescrever `rust.scm`
- [ ] Implementar `buildSignature` para TS/JS/Rust
- [ ] Adicionar testes

### Sprint 4: Java + C# + Demais
- [ ] Reescrever `java.scm`
- [ ] Reescrever `c_sharp.scm`
- [ ] Atualizar queries restantes (C, C++, Swift, etc.)
- [ ] Implementar `buildSignature` para linguagens restantes

### Sprint 5: Renderização + API View
- [ ] Atualizar `depgraph.go` para signatures
- [ ] Implementar `render/api.go`
- [ ] Adicionar flag `--api`
- [ ] Testes de integração

### Sprint 6: MCP + Polish
- [ ] Atualizar MCP tools com `detail` parameter
- [ ] Atualizar documentação
- [ ] Performance testing
- [ ] Bug fixes finais

---

## Riscos e Mitigações

| Risco | Probabilidade | Impacto | Mitigação |
|-------|--------------|---------|-----------|
| Tree-sitter query syntax errors | Alta | Médio | Testar cada query isoladamente com playground |
| Quebra de backward compatibility | Média | Alto | Custom JSON marshaling mantém output antigo |
| Performance degradation | Baixa | Médio | DetailLevel 0 usa código otimizado atual |
| Queries inconsistentes entre linguagens | Alta | Médio | Definir spec clara de captures obrigatórios |

---

## Definições de Pronto

### Feature "Completa" quando:
1. Todas as 16 linguagens suportam o feature
2. Testes unitários cobrem casos de borda
3. JSON output é backward compatible
4. Documentação atualizada no README
5. MCP server atualizado

### Aceitação:
- `codemap --deps .` funciona identicamente ao atual
- `codemap --deps --detail 1 .` mostra signatures
- `codemap --deps --api .` mostra API surface compacta
- JSON output é parseável por consumers existentes

---

## Notas de Implementação

### Ordem de Prioridade das Linguagens
1. **Go** - Linguagem do projeto, mais fácil de testar
2. **Python** - Alta demanda, syntax clara
3. **TypeScript** - Muito usado, tipos explícitos
4. **Rust** - Syntax complexa mas bem definida
5. **Java/C#** - Similar entre si
6. **C/C++** - Mais complexo, menor prioridade

### Padrões de Código
- Preferir funções puras para transformações
- Usar table-driven tests
- Manter cada query file sob 100 linhas se possível
- Documentar edge cases nas queries com comentários

---

*Documento criado em: 2024-12-03*
*Última atualização: 2024-12-03*
*Autor: Claude Code Analysis*
</file>
<file path="development-docs/0001-enhanced-code-analysis.md">
# TASKS.md - Enhanced Code Analysis Features

## Project Briefing

**Objective:** Implement advanced code analysis features for `codemap` including:
1. Full function signatures (parameters and return types)
2. Type extraction (structs, classes, interfaces, traits, enums)
3. API Surface mode for compact public API visualization

**Design Principles:**
- Backward compatibility - existing output unchanged by default
- Token efficiency - new details are opt-in via `--detail` flag
- Semantic consistency - types normalized across languages

**Key Files Modified:**
- `scanner/types.go` - New data structures
- `scanner/grammar.go` - Enhanced analysis logic
- `scanner/queries/*.scm` - Updated tree-sitter queries
- `render/depgraph.go` - Updated rendering
- `render/api.go` - New API surface view
- `main.go` - New CLI flags
- `mcp/main.go` - MCP server updates

---

## Phase 1: Base Data Structures

### 1.1 New Types in scanner/types.go
- [x] Add `DetailLevel` type and constants (DetailNone=0, DetailSignature=1, DetailFull=2)
- [x] Add `FuncInfo` struct (Name, Signature, Receiver, IsExported)
- [x] Add `TypeKind` type and constants (struct, class, interface, trait, enum, alias, protocol)
- [x] Add `TypeInfo` struct (Name, Kind, Fields, Methods, IsExported)
- [x] Update `FileAnalysis` struct (Functions: []FuncInfo, add Types: []TypeInfo)
- [x] Add `DetailLevel` field to `DepsProject` struct

### 1.2 JSON Backward Compatibility
- [x] Implement custom `MarshalJSON` for `FuncInfo` (serialize as string when no signature)
- [x] Implement custom `UnmarshalJSON` for backward compatibility
- [x] Ensure existing JSON consumers still work

### 1.3 CLI Flags in main.go
- [x] Add `--detail` flag (int, 0-2)
- [x] Add `--api` flag (bool)
- [x] Update help text with new flags
- [x] Wire flags through to `runDepsMode`

### 1.4 Scanner Integration
- [x] Update `ScanForDeps` to accept `DetailLevel` parameter
- [x] Update `AnalyzeFile` to accept `DetailLevel` parameter
- [x] Propagate detail level through the analysis pipeline

### 1.5 Validation
- [x] Build succeeds: `go build -o codemap .`
- [x] `./codemap --deps .` still works (backward compatibility)
- [x] `./codemap --help` shows new flags

---

## Phase 2: Go + Python Queries

### 2.1 Go Query (scanner/queries/go.scm)
- [x] Rewrite query with granular captures:
  - [x] `@func.name`, `@func.params` for functions
  - [x] `@func.receiver` for methods
  - [x] `@type.name`, `@type.struct`, `@type.interface`
- [x] Keep existing `@import` captures

### 2.2 Python Query (scanner/queries/python.scm)
- [x] Rewrite query with granular captures:
  - [x] `@func.name`, `@func.params` for functions
  - [x] `@type.name`, `@type.class`
- [x] Keep existing `@import` captures

### 2.3 Analysis Logic in scanner/grammar.go
- [x] Add `funcCapture` struct for collecting function components
- [x] Add `typeCapture` struct for collecting type components
- [x] Implement `handleFuncCapture` function
- [x] Implement `handleTypeCapture` function
- [x] Implement `buildSignature` function for Go and Python
- [x] Implement `IsExportedName` function for Go and Python
- [x] Add deduplication helpers: `dedupeFuncs`, `dedupeTypes`

### 2.4 Validation
- [x] Build succeeds
- [x] Test Go file with `--detail 0` (names only)
- [x] Test Go file with `--detail 1` (shows signatures)
- [x] JSON output is valid and backward compatible

---

## Phase 3: TypeScript + JavaScript + Rust Queries

### 3.1 TypeScript Query (scanner/queries/typescript.scm)
- [x] Rewrite query with granular captures for:
  - [x] Functions with parameters
  - [x] Arrow functions
  - [x] Method definitions
  - [x] Interfaces, classes, type aliases, enums

### 3.2 JavaScript Query (scanner/queries/javascript.scm)
- [x] Rewrite query with granular captures

### 3.3 Rust Query (scanner/queries/rust.scm)
- [x] Rewrite query with granular captures for:
  - [x] Functions with parameters
  - [x] Structs, enums, traits

---

## Phase 4: Java + C# Queries

### 4.1 Java Query (scanner/queries/java.scm)
- [x] Rewrite query with granular captures:
  - [x] Methods and constructors with params
  - [x] Classes, interfaces, enums

### 4.2 C# Query (scanner/queries/c_sharp.scm)
- [x] Rewrite query with granular captures:
  - [x] Methods and constructors
  - [x] Classes, interfaces, structs, enums

---

## Phase 5: Rendering Updates

### 5.1 Update render/depgraph.go
- [x] Update summary to show type counts

### 5.2 Create render/api.go
- [x] Implement `APIView` function:
  - [x] Group files by package/directory
  - [x] Filter to exported types and functions only
  - [x] Group methods by their receiver type
  - [x] Render compact view with type icons
- [x] Implement `typeIcon` helper for ASCII type icons ([S], [C], [I], etc.)
- [x] Implement `extractTypeName` helper for receiver parsing
- [x] Add summary statistics (exported types/functions count)

### 5.3 Wire API Mode in main.go
- [x] Call `render.APIView` when `--api` flag is set

---

## Phase 6: MCP Server Updates

### 6.1 Update mcp/main.go
- [x] Add `DepsInput` type with `detail` parameter
- [x] Update `get_dependencies` tool to use new input type
- [x] Pass detail level to `ScanForDeps`
- [x] Update tool description for new parameter

### 6.2 Validation
- [x] Build MCP server: `go build -o codemap-mcp ./mcp/`

---

## Phase 7: Testing & Documentation

### 7.1 Manual Testing
- [x] Test on codemap itself with all flags
- [x] Test tree mode (basic view)
- [x] Test deps mode (detail=0)
- [x] Test deps mode with signatures (detail=1)
- [x] Test API surface mode

### 7.2 Final Validation
- [x] All existing modes still work (tree, deps, diff, skyline)
- [x] Build both binaries successfully
- [x] Run `go fmt ./...`

---

## Completion Summary

**Status:** [x] Completed

| Phase | Description | Status |
|-------|-------------|--------|
| 1 | Base Data Structures | [x] Complete |
| 2 | Go + Python Queries | [x] Complete |
| 3 | TypeScript + Rust Queries | [x] Complete |
| 4 | Java + C# Queries | [x] Complete |
| 5 | Rendering Updates | [x] Complete |
| 6 | MCP Server Updates | [x] Complete |
| 7 | Testing & Documentation | [x] Complete |

### Implementation Notes

1. **Function Signatures**: Function parameters are captured via `@func.params` and methods include receivers via `@func.receiver`. Signatures are built using the `buildSignature` function in `grammar.go`.

2. **Type Extraction**: Types are captured with pattern markers (`@type.struct`, `@type.class`, etc.) that set the `Kind` field in `TypeInfo`. Type fields are not extracted in this implementation to keep queries simple.

3. **Return Types**: Due to tree-sitter query syntax limitations with optional fields, function return types are not captured. Signatures show function name and parameters only.

4. **Backward Compatibility**: `FuncInfo.MarshalJSON()` serializes as plain string when no extended info is present, ensuring existing JSON consumers continue to work.

5. **Queries Updated**: Go, Python, TypeScript, JavaScript, Rust, Java, and C# queries have been updated with the new capture patterns. Other languages (C, C++, Swift, etc.) continue to use legacy `@function` captures.

---

*Created: 2024-12-03*
*Completed: 2024-12-03*
</file>
<file path="development-docs/0002-token-heuristics-symbol-search-plan.md">
# Refactoring/Design Plan: Token Heuristics, `get_symbol` Tool e Melhorias MCP

> **Versão:** 2.0 (Otimizado)
> **Data:** 2025-12-03
> **Status:** Pronto para implementação

---

## 1. Executive Summary & Goals

O objetivo principal é **melhorar a utilidade do `codemap` para agentes LLM**, focando em:

1. **Context Management (Tokens):** Estimativa de tokens por arquivo com alertas visuais (P0)
2. **Semantic Search (`get_symbol`):** Busca precisa de funções/tipos por nome (P0)
3. **MCP Enhancement:** Exposição do modo `--api` e refatoração de path validation (P1)

### Mudanças-Chave vs. Plano Original

| Aspecto | Plano Original | Plano Otimizado |
|---------|----------------|-----------------|
| Token Heuristics | Map `TokenRatios` por linguagem | Ratio fixo universal (3.5 chars/token) |
| Captura de Linha | Mencionada como "questão aberta" | **Fase 0 obrigatória** - Prerequisito |
| `SymbolInfo` | Novo struct com campos duplicados | Reutiliza `FuncInfo`/`TypeInfo` + campo `Line` |
| Formato de Saída | "ASCII formatado" (vago) | Especificação exata definida |

---

## 2. Current Situation Analysis

### Arquitetura Existente

```
scanner/types.go     → FileInfo, FuncInfo, TypeInfo, FileAnalysis
scanner/walker.go    → ScanFiles(), ScanForDeps()
scanner/grammar.go   → AnalyzeFile(), funcCapture, typeCapture
render/tree.go       → Tree()
render/api.go        → APIView()
mcp/main.go          → 7 handlers existentes
```

### Gap Crítico Identificado

**`funcCapture` e `typeCapture` NÃO capturam linha de definição:**

```go
// scanner/grammar.go:256-261 - ATUAL
type funcCapture struct {
    name     string
    params   string
    result   string
    receiver string
    // FALTA: line int
}
```

Isso **bloqueia** a implementação de `get_symbol` com localização.

---

## 3. Proposed Solution

### 3.1. High-Level Architecture

```
┌─────────────────────────────────────────────────────────────────┐
│                         CLI / MCP Layer                          │
├─────────────────────────────────────────────────────────────────┤
│  main.go         mcp/main.go                                    │
│     │               │                                            │
│     │               ├── handleGetSymbol (NEW)                   │
│     │               ├── handleGetDependencies (mode param)      │
│     │               └── validatePath (refactored)               │
└─────────────────────────────────────────────────────────────────┘
                              │
┌─────────────────────────────────────────────────────────────────┐
│                        Scanner Layer                             │
├─────────────────────────────────────────────────────────────────┤
│  types.go                                                        │
│     ├── FileInfo { ..., Tokens int }  (modified)                │
│     ├── FuncInfo { ..., Line int }    (modified)                │
│     └── TypeInfo { ..., Line int }    (modified)                │
│                                                                  │
│  walker.go                                                       │
│     └── ScanFiles() → calcula Tokens                            │
│                                                                  │
│  grammar.go                                                      │
│     ├── funcCapture { ..., line int } (modified)                │
│     └── typeCapture { ..., line int } (modified)                │
│                                                                  │
│  symbol.go (NEW)                                                 │
│     └── SearchSymbols(analyses, query) → []SymbolMatch          │
└─────────────────────────────────────────────────────────────────┘
                              │
┌─────────────────────────────────────────────────────────────────┐
│                        Render Layer                              │
├─────────────────────────────────────────────────────────────────┤
│  tree.go                                                         │
│     └── Tree() → exibe tokens + warnings                        │
└─────────────────────────────────────────────────────────────────┘
```

### 3.2. Data Model Changes

#### `scanner/types.go`

```go
// MODIFICAÇÃO: FileInfo
type FileInfo struct {
    Path    string `json:"path"`
    Size    int64  `json:"size"`
    Ext     string `json:"ext"`
    Tokens  int    `json:"tokens,omitempty"`  // NEW: Estimativa de tokens
    IsNew   bool   `json:"is_new,omitempty"`
    Added   int    `json:"added,omitempty"`
    Removed int    `json:"removed,omitempty"`
}

// MODIFICAÇÃO: FuncInfo
type FuncInfo struct {
    Name       string `json:"name"`
    Signature  string `json:"signature,omitempty"`
    Receiver   string `json:"receiver,omitempty"`
    IsExported bool   `json:"exported,omitempty"`
    Line       int    `json:"line,omitempty"`  // NEW: Linha de definição
}

// MODIFICAÇÃO: TypeInfo
type TypeInfo struct {
    Name       string   `json:"name"`
    Kind       TypeKind `json:"kind"`
    Fields     []string `json:"fields,omitempty"`
    Methods    []string `json:"methods,omitempty"`
    IsExported bool     `json:"exported,omitempty"`
    Line       int      `json:"line,omitempty"`  // NEW: Linha de definição
}

// NEW: Constante para estimativa de tokens
const CharsPerToken = 3.5  // Conservador para maioria dos tokenizers BPE

// NEW: Threshold para warning
const LargeFileTokens = 8000

// NEW: Função helper
func EstimateTokens(size int64) int {
    return int(float64(size) / CharsPerToken)
}
```

#### `scanner/grammar.go`

```go
// MODIFICAÇÃO: funcCapture
type funcCapture struct {
    name     string
    params   string
    result   string
    receiver string
    line     int  // NEW
}

// MODIFICAÇÃO: typeCapture
type typeCapture struct {
    name   string
    kind   TypeKind
    fields string
    line   int  // NEW
}
```

#### `scanner/symbol.go` (NEW)

```go
package scanner

// SymbolQuery representa os filtros de busca
type SymbolQuery struct {
    Name string   // Substring match (case-insensitive)
    Kind string   // "function", "type", "all"
    File string   // Filtrar por arquivo específico (opcional)
}

// SymbolMatch representa um símbolo encontrado
type SymbolMatch struct {
    Name      string `json:"name"`
    Kind      string `json:"kind"`      // "function" ou "type"
    Signature string `json:"signature"` // Para funções
    TypeKind  string `json:"type_kind"` // Para tipos (struct, class, etc.)
    File      string `json:"file"`
    Line      int    `json:"line"`
    Exported  bool   `json:"exported"`
}

// SearchSymbols busca símbolos nas análises existentes
func SearchSymbols(analyses []FileAnalysis, query SymbolQuery) []SymbolMatch
```

#### `mcp/main.go`

```go
// MODIFICAÇÃO: DepsInput
type DepsInput struct {
    Path   string `json:"path" jsonschema:"Path to the project directory"`
    Detail int    `json:"detail,omitempty" jsonschema:"0=names, 1=signatures, 2=full"`
    Mode   string `json:"mode,omitempty" jsonschema:"deps (default), api"`  // NEW
}

// NEW: SymbolInput
type SymbolInput struct {
    Path string `json:"path" jsonschema:"Path to the project directory"`
    Name string `json:"name" jsonschema:"Symbol name to search (substring match)"`
    Kind string `json:"kind,omitempty" jsonschema:"function, type, or all (default)"`
    File string `json:"file,omitempty" jsonschema:"Filter to specific file"`
}
```

---

## 4. Detailed Action Plan

### Phase 0: Line Capture Fix (BLOCKER)

**Objetivo:** Corrigir o gap crítico que impede `get_symbol` de reportar localização.

| Task | Arquivo | Mudança | Critério de Conclusão |
|------|---------|---------|----------------------|
| 0.1 | `scanner/grammar.go` | Adicionar campo `line int` em `funcCapture` e `typeCapture` | Structs atualizados |
| 0.2 | `scanner/grammar.go` | Em `AnalyzeFile`, capturar linha via `node.StartPosition().Row + 1` | Linha capturada durante parsing |
| 0.3 | `scanner/types.go` | Adicionar campo `Line int` em `FuncInfo` e `TypeInfo` | Structs atualizados |
| 0.4 | `scanner/grammar.go` | Propagar linha em `Build()` de `funcCapture` e `typeCapture` | `FuncInfo.Line` e `TypeInfo.Line` preenchidos |

**Implementação `0.2`:**
```go
// Em AnalyzeFile, no loop de captures:
for i, capture := range match.Captures {
    captureName := query.CaptureNames()[capture.Index]
    text := capture.Node.Utf8Text(content)
    startLine := int(capture.Node.StartPosition().Row) + 1  // 1-indexed

    if strings.HasPrefix(captureName, "func.") {
        handleFuncCapture(funcBuilders, match.ID(), captureName, text, startLine)
    }
    // similar para types
}
```

---

### Phase 1: Token Estimation (P0)

**Objetivo:** Fornecer visibilidade de context window para LLMs.

| Task | Arquivo | Mudança | Critério de Conclusão |
|------|---------|---------|----------------------|
| 1.1 | `scanner/types.go` | Adicionar `Tokens int` em `FileInfo`, `CharsPerToken`, `LargeFileTokens`, `EstimateTokens()` | Constantes e helper definidos |
| 1.2 | `scanner/walker.go` | Em `ScanFiles`, calcular e preencher `Tokens` para cada arquivo | `FileInfo.Tokens` preenchido |
| 1.3 | `render/tree.go` | Exibir tokens no formato `~Xk` e `⚠` para arquivos > 8k tokens | Output visual atualizado |
| 1.4 | `render/tree.go` | Adicionar total de tokens no header | Header exibe `Tokens: ~Xk` |

**Formato de Saída (Task 1.3):**
```
├── scanner/
│   ├── grammar.go        (~4.2k tokens)
│   ├── walker.go         (~1.8k tokens)
│   └── huge_file.go      (~12k tokens) ⚠
```

**Formato Header (Task 1.4):**
```
╭──────────────────── codemap ────────────────────╮
│ Files: 42 | Size: 156KB | Tokens: ~45k          │
│ Top Extensions: .go (28), .md (8), .yaml (4)    │
╰─────────────────────────────────────────────────╯
```

---

### Phase 2: Symbol Search - `get_symbol` (P0)

**Objetivo:** Permitir busca semântica precisa de símbolos.

| Task | Arquivo | Mudança | Critério de Conclusão |
|------|---------|---------|----------------------|
| 2.1 | `scanner/symbol.go` | Criar arquivo com `SymbolQuery`, `SymbolMatch`, `SearchSymbols()` | Arquivo criado e compila |
| 2.2 | `scanner/symbol.go` | Implementar `SearchSymbols()` que filtra `[]FileAnalysis` | Retorna matches filtrados |
| 2.3 | `mcp/main.go` | Adicionar `SymbolInput` struct | Struct definido |
| 2.4 | `mcp/main.go` | Implementar `handleGetSymbol()` | Handler funcional |
| 2.5 | `mcp/main.go` | Registrar tool `get_symbol` no servidor MCP | Tool aparece em `status` |

**Formato de Saída `get_symbol`:**
```
=== Symbol Search: "Config" ===

Found 3 matches:

  scanner/types.go:18
  ├─ type Config struct
  └─ Fields: Root, Mode, Files

  scanner/grammar.go:45
  ├─ func NewConfig(path string) *Config
  └─ Signature: NewConfig(path string) *Config

  mcp/main.go:120
  ├─ func (c *Config) Validate() error
  └─ Receiver: *Config

───────────────────────────────────
Matches: 3 (1 type, 2 functions)
```

---

### Phase 3: MCP Enhancements (P1)

**Objetivo:** Expor modo API e centralizar validação.

| Task | Arquivo | Mudança | Critério de Conclusão |
|------|---------|---------|----------------------|
| 3.1 | `mcp/main.go` | Adicionar `Mode string` em `DepsInput` | Struct atualizado |
| 3.2 | `mcp/main.go` | Em `handleGetDependencies`, usar `render.APIView` quando `mode="api"` | Modo API funcional |
| 3.3 | `mcp/main.go` | Criar `validatePath(path string) (string, error)` | Helper definido |
| 3.4 | `mcp/main.go` | Refatorar handlers para usar `validatePath` | Zero duplicação de código |

**Implementação `validatePath`:**
```go
func validatePath(path string) (string, error) {
    if path == "" {
        return "", fmt.Errorf("path is required")
    }
    absPath, err := filepath.Abs(path)
    if err != nil {
        return "", fmt.Errorf("invalid path: %w", err)
    }
    if _, err := os.Stat(absPath); os.IsNotExist(err) {
        return "", fmt.Errorf("path does not exist: %s", absPath)
    }
    return absPath, nil
}
```

---

## 5. Dependency Graph

```
Phase 0 (Line Capture)
    │
    ├──────────────────────┐
    ▼                      ▼
Phase 1 (Tokens)     Phase 2 (get_symbol)
    │                      │
    └──────────┬───────────┘
               ▼
         Phase 3 (MCP)
```

**Nota:** Phases 1 e 2 podem ser desenvolvidas em paralelo após Phase 0.

---

## 6. Risk Mitigation

| Risco | Probabilidade | Impacto | Mitigação |
|-------|---------------|---------|-----------|
| R1: Captura de linha quebra parsing existente | Baixa | Alto | Testes manuais em múltiplas linguagens antes de merge |
| R2: Token ratio impreciso | Alta | Baixo | Usar `~` (aproximação) e focar no warning > 8k |
| R3: `SearchSymbols` lento em projetos grandes | Média | Médio | Filtrar por arquivo primeiro se `query.File` especificado |
| R4: Breaking change em JSON output | Média | Alto | Campos novos são `omitempty`, não quebra consumers existentes |

---

## 7. Validation Criteria

### Phase 0
- [ ] `./codemap --deps .` exibe funções/tipos com linha no JSON (`--json`)
- [ ] Linha é 1-indexed e corresponde à definição real

### Phase 1
- [ ] `./codemap .` exibe `(~Xk tokens)` após cada arquivo
- [ ] Arquivos > 8k tokens mostram `⚠`
- [ ] Header mostra total de tokens do projeto

### Phase 2
- [ ] `codemap-mcp` lista `get_symbol` em `status`
- [ ] `get_symbol(path=".", name="Scan")` retorna todas funções/tipos com "Scan"
- [ ] Output inclui `file:line` para cada match

### Phase 3
- [ ] `get_dependencies(path=".", mode="api")` retorna output idêntico a `render.APIView`
- [ ] Nenhum handler em `mcp/main.go` tem `filepath.Abs` duplicado

---

## 8. Questões Resolvidas

| Questão Original | Resolução |
|------------------|-----------|
| `get_symbol` como função separada ou modo em `ScanForDeps`? | **Função separada** em `scanner/symbol.go` que consome output de `ScanForDeps` |
| Onde extrair linha de definição? | Em `handleFuncCapture`/`handleTypeCapture` via `node.StartPosition().Row + 1` |
| Test Mapping (P2): nome de arquivo ou conteúdo? | **Apenas nome de arquivo** (removido do escopo atual - P2 postergado) |
| Token ratio por linguagem ou fixo? | **Fixo (3.5)** - Simplificação justificada por baixa variação em tokenizers BPE |

---

## 9. Out of Scope (P2+)

Removido do escopo atual para manter foco:

- Test Mapping (`TestPattern`, `TestMapping`)
- JSON output format para MCP (`--format=json`)
- CLI `--format=json` para tree mode
- Cross-file reference tracking (`ImportedBy`)

Estes itens podem ser implementados em iteração futura.
</file>
<file path="development-docs/0002-token-heuristics-symbol-search.md">
# TASKS.md - Token Heuristics, `get_symbol` Tool & MCP Improvements

> **Feature:** Token estimation, semantic symbol search, and MCP enhancements
> **Created:** 2025-12-03
> **Status:** Completed

---

## Project Briefing

This implementation adds three key capabilities to codemap for better LLM support:

1. **Token Estimation**: Display estimated token counts per file with warnings for large files (>8k tokens)
2. **Symbol Search (`get_symbol`)**: New MCP tool for precise function/type lookup by name
3. **MCP Enhancements**: Add API mode to `get_dependencies` and refactor path validation

### Key Technical Changes

| Component | Current | After |
|-----------|---------|-------|
| `FileInfo` | No token count | `Tokens int` field |
| `FuncInfo`/`TypeInfo` | No line numbers | `Line int` field |
| `funcCapture`/`typeCapture` | No line tracking | `line int` field |
| MCP handlers | 7 tools | 8 tools (`get_symbol`) |

---

## Phase 0: Line Capture Fix (BLOCKER)

> **Objective:** Enable line number capture for symbols - prerequisite for `get_symbol`

### Task 0.1: Add `line` field to `funcCapture` struct
- [x] **File:** `scanner/grammar.go:256-261`
- [x] Add `line int` field to `funcCapture` struct
- [x] Verify struct compiles

### Task 0.2: Add `line` field to `typeCapture` struct
- [x] **File:** `scanner/grammar.go:301-305`
- [x] Add `line int` field to `typeCapture` struct
- [x] Verify struct compiles

### Task 0.3: Add `Line` field to `FuncInfo` struct
- [x] **File:** `scanner/types.go:38-43`
- [x] Add `Line int json:"line,omitempty"` field
- [x] Verify struct compiles

### Task 0.4: Add `Line` field to `TypeInfo` struct
- [x] **File:** `scanner/types.go:87-93`
- [x] Add `Line int json:"line,omitempty"` field
- [x] Verify struct compiles

### Task 0.5: Modify `handleFuncCapture` to capture line numbers
- [x] **File:** `scanner/grammar.go:282-298`
- [x] Add `line int` parameter to `handleFuncCapture`
- [x] Set `fc.line` when capturing `func.name` (first significant capture)
- [x] Handle line in the switch statement

### Task 0.6: Modify `handleTypeCapture` to capture line numbers
- [x] **File:** `scanner/grammar.go:323-351`
- [x] Add `line int` parameter to `handleTypeCapture`
- [x] Set `tc.line` when capturing `type.name` (first significant capture)
- [x] Handle line in the switch statement

### Task 0.7: Update `AnalyzeFile` to pass line numbers
- [x] **File:** `scanner/grammar.go:183-253`
- [x] Extract line from `capture.Node.StartPosition().Row + 1` (1-indexed)
- [x] Pass line to `handleFuncCapture` calls
- [x] Pass line to `handleTypeCapture` calls

### Task 0.8: Update `funcCapture.Build` to include Line
- [x] **File:** `scanner/grammar.go:264-279`
- [x] Set `info.Line = fc.line` in Build method
- [x] Verify FuncInfo includes line in output

### Task 0.9: Update `typeCapture.Build` to include Line
- [x] **File:** `scanner/grammar.go:308-320`
- [x] Set `info.Line = tc.line` in Build method
- [x] Verify TypeInfo includes line in output

### Task 0.10: Validate Phase 0
- [x] Run `go build -o codemap .`
- [x] Run `./codemap --deps --json . | head -50` and verify lines appear
- [x] Verify line numbers are 1-indexed and correct

---

## Phase 1: Token Estimation (P0)

> **Objective:** Add token count visibility to help LLMs manage context windows

### Task 1.1: Add token estimation constants and helper
- [x] **File:** `scanner/types.go`
- [x] Add `const CharsPerToken = 3.5`
- [x] Add `const LargeFileTokens = 8000`
- [x] Add `func EstimateTokens(size int64) int`

### Task 1.2: Add `Tokens` field to `FileInfo`
- [x] **File:** `scanner/types.go:18-25`
- [x] Add `Tokens int json:"tokens,omitempty"` field

### Task 1.3: Calculate tokens in `ScanFiles`
- [x] **File:** `scanner/walker.go`
- [x] In `ScanFiles`, set `file.Tokens = EstimateTokens(file.Size)` for each file

### Task 1.4: Update `Tree` to display tokens per file
- [x] **File:** `render/tree.go`
- [x] Modify `printTreeNode` to show `[!]` warning for files > 8k tokens
- [x] Add warning indicator `[!]` for files > 8k tokens

### Task 1.5: Update header to show total tokens
- [x] **File:** `render/tree.go:106-195`
- [x] Calculate total tokens across all files
- [x] Add `Tokens: ~Xk` to stats line in header

### Task 1.6: Validate Phase 1
- [x] Run `go build -o codemap .`
- [x] Run `./codemap .` and verify tokens appear in output
- [x] Verify warning indicator appears for large files
- [x] Verify header shows total tokens

---

## Phase 2: Symbol Search - `get_symbol` (P0)

> **Objective:** Enable precise semantic search for functions and types

### Task 2.1: Create `scanner/symbol.go` with types
- [x] Create new file `scanner/symbol.go`
- [x] Define `SymbolQuery` struct with `Name`, `Kind`, `File` fields
- [x] Define `SymbolMatch` struct with `Name`, `Kind`, `Signature`, `TypeKind`, `File`, `Line`, `Exported` fields

### Task 2.2: Implement `SearchSymbols` function
- [x] **File:** `scanner/symbol.go`
- [x] Implement search logic that filters `[]FileAnalysis`
- [x] Support case-insensitive substring matching on Name
- [x] Support filtering by Kind ("function", "type", "all")
- [x] Support filtering by File (optional)

### Task 2.3: Add `SymbolInput` struct to MCP
- [x] **File:** `mcp/main.go`
- [x] Add `SymbolInput` struct with `Path`, `Name`, `Kind`, `File` fields
- [x] Add JSON schema annotations

### Task 2.4: Implement `handleGetSymbol` handler
- [x] **File:** `mcp/main.go`
- [x] Validate path using existing pattern
- [x] Call `ScanForDeps` with appropriate detail level
- [x] Call `SearchSymbols` with query parameters
- [x] Format output as ASCII table with file:line references

### Task 2.5: Register `get_symbol` tool in MCP server
- [x] **File:** `mcp/main.go`
- [x] Add tool registration with description and schema
- [x] Update tool count comment

### Task 2.6: Validate Phase 2
- [x] Run `go build -o codemap-mcp ./mcp/`
- [x] Test `get_symbol` tool with various queries
- [x] Verify file:line format in output

---

## Phase 3: MCP Enhancements (P1)

> **Objective:** Add API mode and centralize path validation

### Task 3.1: Add `Mode` field to `DepsInput`
- [x] **File:** `mcp/main.go`
- [x] Add `Mode string json:"mode,omitempty"` to `DepsInput`
- [x] Document valid values: "deps" (default), "api"

### Task 3.2: Implement API mode in `handleGetDependencies`
- [x] **File:** `mcp/main.go`
- [x] Check if `input.Mode == "api"`
- [x] Call `render.APIView` instead of `render.Depgraph` when API mode
- [x] Ensure proper output capture

### Task 3.3: Create `validatePath` helper function
- [x] **File:** `mcp/main.go`
- [x] Create function: `func validatePath(path string) (string, error)`
- [x] Handle empty path, filepath.Abs, and os.Stat checks
- [x] Return absolute path or error

### Task 3.4: Refactor handlers to use `validatePath`
- [x] **File:** `mcp/main.go`
- [x] Update `handleGetStructure` to use `validatePath`
- [x] Update `handleGetDependencies` to use `validatePath`
- [x] Update `handleGetDiff` to use `validatePath`
- [x] Update `handleFindFile` to use `validatePath`
- [x] Update `handleGetImporters` to use `validatePath`
- [x] Update `handleListProjects` to use `validatePath`
- [x] Verify no duplicate `filepath.Abs` calls remain

### Task 3.5: Validate Phase 3
- [x] Run `go build -o codemap-mcp ./mcp/`
- [x] Test `get_dependencies` with `mode=api`
- [x] Verify path validation works correctly

---

## Final Validation & Testing

### Integration Tests
- [x] `./codemap .` - Verify tree with tokens
- [x] `./codemap --deps .` - Verify functions/types have line numbers
- [x] `./codemap --deps --json .` - Verify JSON includes `line` and `tokens` fields
- [x] MCP: `get_symbol(path=".", name="Scan")` - Verify results
- [x] MCP: `get_dependencies(path=".", mode="api")` - Verify API output

### Manual Verification Checklist
- [x] Line numbers are 1-indexed and match actual file lines
- [x] Token estimates use `~` prefix for approximation
- [x] Warning indicator `[!]` appears for files > 8k tokens
- [x] Header shows aggregated token count
- [x] `get_symbol` returns results with `file:line` format
- [x] API mode produces same output as `render.APIView`
- [x] No duplicate path validation code in MCP handlers

---

## Completion Notes

### Summary
- [x] All phases completed
- [x] All validation criteria passed

**Implementation completed on 2025-12-03**

### Files Modified
- `scanner/types.go` - Added `Tokens`, `Line` fields, token estimation constants and helper
- `scanner/grammar.go` - Added line capture in `funcCapture`, `typeCapture`, handlers, and Build methods
- `scanner/walker.go` - Added token calculation in `ScanFiles`
- `scanner/symbol.go` - New file with `SearchSymbols` function
- `render/tree.go` - Added token display in header and `[!]` warning for large files
- `mcp/main.go` - Added `get_symbol` tool, `validatePath` helper, API mode support

### Deviations from Plan
- Token display format: Changed from `(~Xk tokens)` after each file to `[!]` warning indicator only for files > 8k tokens (simpler, less cluttered output)
- The `validatePath` helper also handles `~/` expansion (bonus feature)

### Follow-up Items
- Consider adding token display per-file in verbose mode
- Test `get_symbol` with various languages to ensure line numbers are accurate
- Consider adding sorting options to `get_symbol` results
</file>
<file path="mcp/main.go">
// MCP Server for codemap - provides codebase analysis tools to LLMs
package main

import (
	"bytes"
	"context"
	"fmt"
	"log"
	"os"
	"path/filepath"
	"regexp"
	"strings"

	"codemap/render"
	"codemap/scanner"

	"github.com/modelcontextprotocol/go-sdk/mcp"
)

// Input types for tools
type PathInput struct {
	Path string `json:"path" jsonschema:"Path to the project directory to analyze"`
}

type DepsInput struct {
	Path   string `json:"path" jsonschema:"Path to the project directory to analyze"`
	Detail int    `json:"detail,omitempty" jsonschema:"Detail level: 0=names only (default), 1=signatures, 2=full (with type fields)"`
	Mode   string `json:"mode,omitempty" jsonschema:"Output mode: deps (default) shows dependency flow, api shows API surface (exported functions/types)"`
}

type DiffInput struct {
	Path string `json:"path" jsonschema:"Path to the project directory to analyze"`
	Ref  string `json:"ref,omitempty" jsonschema:"Git branch/ref to compare against (default: main)"`
}

type FindInput struct {
	Path    string `json:"path" jsonschema:"Path to the project directory to search"`
	Pattern string `json:"pattern" jsonschema:"Filename pattern to search for (case-insensitive substring match)"`
}

type ImportersInput struct {
	Path string `json:"path" jsonschema:"Path to the project directory"`
	File string `json:"file" jsonschema:"Relative path to the file to check (e.g. src/utils.ts)"`
}

type ListProjectsInput struct {
	Path    string `json:"path" jsonschema:"Parent directory containing projects (e.g. /Users/name/Code or ~/Code)"`
	Pattern string `json:"pattern,omitempty" jsonschema:"Optional filter to match project names (case-insensitive substring)"`
}

type SymbolInput struct {
	Path string `json:"path" jsonschema:"Path to the project directory"`
	Name string `json:"name" jsonschema:"Symbol name to search (substring match, case-insensitive)"`
	Kind string `json:"kind,omitempty" jsonschema:"Filter by symbol type: function, type, or all (default: all)"`
	File string `json:"file,omitempty" jsonschema:"Filter to specific file path (substring match)"`
}

func main() {
	server := mcp.NewServer(&mcp.Implementation{
		Name:    "codemap",
		Version: "2.0.0",
	}, nil)

	// Tool: get_structure - Get project tree view
	mcp.AddTool(server, &mcp.Tool{
		Name:        "get_structure",
		Description: "Get the project structure as a tree view. Shows files organized by directory with language detection, file sizes, and highlights the top 5 largest source files. Use this to understand how a codebase is organized.",
	}, handleGetStructure)

	// Tool: get_dependencies - Get dependency graph
	mcp.AddTool(server, &mcp.Tool{
		Name:        "get_dependencies",
		Description: "Get the dependency flow of a project. Shows external dependencies by language, internal import chains between files, hub files (most-imported), and function counts. Use detail=1 for function signatures, detail=2 for full type information.",
	}, handleGetDependencies)

	// Tool: get_diff - Get changed files with impact analysis
	mcp.AddTool(server, &mcp.Tool{
		Name:        "get_diff",
		Description: "Get files changed compared to a git branch, with line counts and impact analysis showing which changed files are imported by others. Use this to understand what work has been done and what might break.",
	}, handleGetDiff)

	// Tool: find_file - Find files by pattern
	mcp.AddTool(server, &mcp.Tool{
		Name:        "find_file",
		Description: "Find files in a project matching a name pattern. Returns file paths with their sizes and languages.",
	}, handleFindFile)

	// Tool: get_importers - Find what imports a file
	mcp.AddTool(server, &mcp.Tool{
		Name:        "get_importers",
		Description: "Find all files that import/depend on a specific file. Use this to understand the impact of changing a file.",
	}, handleGetImporters)

	// Tool: status - Verify MCP connection
	mcp.AddTool(server, &mcp.Tool{
		Name:        "status",
		Description: "Check codemap MCP server status. Returns version and confirms local filesystem access is available.",
	}, handleStatus)

	// Tool: list_projects - Discover projects in a directory
	mcp.AddTool(server, &mcp.Tool{
		Name:        "list_projects",
		Description: "List project directories under a parent path. Use this to discover projects when you only know the general location (e.g., ~/Code) but not the exact folder name. Optionally filter by pattern to find specific projects. Returns directory names with file counts and primary language.",
	}, handleListProjects)

	// Tool: get_symbol - Search for symbols by name
	mcp.AddTool(server, &mcp.Tool{
		Name:        "get_symbol",
		Description: "Search for functions and types by name. Returns matching symbols with file location (path:line). Use this to find specific code elements without browsing files. Supports filtering by kind (function/type) and file path.",
	}, handleGetSymbol)

	// Run server on stdio
	if err := server.Run(context.Background(), &mcp.StdioTransport{}); err != nil {
		log.Printf("Server error: %v", err)
	}
}

// validatePath validates and returns the absolute path
func validatePath(path string) (string, error) {
	if path == "" {
		return "", fmt.Errorf("path is required")
	}

	// Expand ~ to home directory
	if strings.HasPrefix(path, "~/") {
		home := os.Getenv("HOME")
		path = filepath.Join(home, path[2:])
	}

	absPath, err := filepath.Abs(path)
	if err != nil {
		return "", fmt.Errorf("invalid path: %w", err)
	}

	if _, err := os.Stat(absPath); os.IsNotExist(err) {
		return "", fmt.Errorf("path does not exist: %s", absPath)
	}

	return absPath, nil
}

func textResult(text string) *mcp.CallToolResult {
	return &mcp.CallToolResult{
		Content: []mcp.Content{
			&mcp.TextContent{Text: text},
		},
	}
}

func errorResult(text string) *mcp.CallToolResult {
	return &mcp.CallToolResult{
		Content: []mcp.Content{
			&mcp.TextContent{Text: text},
		},
		IsError: true,
	}
}

func handleGetStructure(ctx context.Context, req *mcp.CallToolRequest, input PathInput) (*mcp.CallToolResult, any, error) {
	absRoot, err := validatePath(input.Path)
	if err != nil {
		return errorResult(err.Error()), nil, nil
	}

	gitignore := scanner.LoadGitignore(absRoot)
	files, err := scanner.ScanFiles(absRoot, gitignore)
	if err != nil {
		return errorResult("Scan error: " + err.Error()), nil, nil
	}

	project := scanner.Project{
		Root:  absRoot,
		Mode:  "tree",
		Files: files,
	}

	output := captureOutput(func() {
		render.Tree(project)
	})

	return textResult(output), nil, nil
}

func handleGetDependencies(ctx context.Context, req *mcp.CallToolRequest, input DepsInput) (*mcp.CallToolResult, any, error) {
	absRoot, err := validatePath(input.Path)
	if err != nil {
		return errorResult(err.Error()), nil, nil
	}

	gitignore := scanner.LoadGitignore(absRoot)
	loader := scanner.NewGrammarLoader()

	// Use the detail level from input (default 0 = names only)
	detailLevel := scanner.DetailLevel(input.Detail)
	analyses, err := scanner.ScanForDeps(absRoot, gitignore, loader, detailLevel)
	if err != nil {
		return errorResult("Scan error: " + err.Error()), nil, nil
	}

	depsProject := scanner.DepsProject{
		Root:         absRoot,
		Mode:         "deps",
		Files:        analyses,
		ExternalDeps: scanner.ReadExternalDeps(absRoot),
		DetailLevel:  input.Detail,
	}

	// Use API mode if requested
	var output string
	if input.Mode == "api" {
		output = captureOutput(func() {
			render.APIView(depsProject)
		})
	} else {
		output = captureOutput(func() {
			render.Depgraph(depsProject)
		})
	}

	return textResult(output), nil, nil
}

func handleGetDiff(ctx context.Context, req *mcp.CallToolRequest, input DiffInput) (*mcp.CallToolResult, any, error) {
	ref := input.Ref
	if ref == "" {
		ref = "main"
	}

	absRoot, err := validatePath(input.Path)
	if err != nil {
		return errorResult(err.Error()), nil, nil
	}

	diffInfo, err := scanner.GitDiffInfo(absRoot, ref)
	if err != nil {
		return errorResult("Git diff error: " + err.Error() + "\nMake sure '" + ref + "' is a valid branch/ref"), nil, nil
	}

	if len(diffInfo.Changed) == 0 {
		return textResult("No files changed vs " + ref), nil, nil
	}

	gitignore := scanner.LoadGitignore(absRoot)
	files, err := scanner.ScanFiles(absRoot, gitignore)
	if err != nil {
		return errorResult("Scan error: " + err.Error()), nil, nil
	}

	files = scanner.FilterToChangedWithInfo(files, diffInfo)
	impact := scanner.AnalyzeImpact(absRoot, files)

	project := scanner.Project{
		Root:    absRoot,
		Mode:    "tree",
		Files:   files,
		DiffRef: ref,
		Impact:  impact,
	}

	output := captureOutput(func() {
		render.Tree(project)
	})

	return textResult(output), nil, nil
}

func handleFindFile(ctx context.Context, req *mcp.CallToolRequest, input FindInput) (*mcp.CallToolResult, any, error) {
	absRoot, err := validatePath(input.Path)
	if err != nil {
		return errorResult(err.Error()), nil, nil
	}

	gitignore := scanner.LoadGitignore(absRoot)
	files, err := scanner.ScanFiles(absRoot, gitignore)
	if err != nil {
		return errorResult("Scan error: " + err.Error()), nil, nil
	}

	// Filter files matching pattern (case-insensitive)
	var matches []string
	pattern := strings.ToLower(input.Pattern)
	for _, f := range files {
		if strings.Contains(strings.ToLower(f.Path), pattern) {
			matches = append(matches, f.Path)
		}
	}

	if len(matches) == 0 {
		return textResult("No files found matching '" + input.Pattern + "'"), nil, nil
	}

	return textResult(fmt.Sprintf("Found %d files:\n%s", len(matches), strings.Join(matches, "\n"))), nil, nil
}

// EmptyInput for tools that don't need parameters
type EmptyInput struct{}

func handleStatus(ctx context.Context, req *mcp.CallToolRequest, input EmptyInput) (*mcp.CallToolResult, any, error) {
	cwd, _ := os.Getwd()
	home := os.Getenv("HOME")

	return textResult(fmt.Sprintf(`codemap MCP server v2.0.0
Status: connected
Local filesystem access: enabled
Working directory: %s
Home directory: %s

Available tools:
  list_projects    - Discover projects in a directory
  get_structure    - Project tree view
  get_dependencies - Import/function analysis
  get_diff         - Changed files vs branch
  find_file        - Search by filename
  get_importers    - Find what imports a file
  get_symbol       - Search for functions/types by name`, cwd, home)), nil, nil
}

func handleListProjects(ctx context.Context, req *mcp.CallToolRequest, input ListProjectsInput) (*mcp.CallToolResult, any, error) {
	absPath, err := validatePath(input.Path)
	if err != nil {
		return errorResult(err.Error()), nil, nil
	}

	entries, err := os.ReadDir(absPath)
	if err != nil {
		return errorResult("Cannot read directory: " + err.Error()), nil, nil
	}

	pattern := strings.ToLower(input.Pattern)
	var projects []string

	for _, entry := range entries {
		if !entry.IsDir() {
			continue
		}
		name := entry.Name()

		// Skip hidden directories and common non-project dirs
		if strings.HasPrefix(name, ".") {
			continue
		}

		// Filter by pattern if provided
		if pattern != "" && !strings.Contains(strings.ToLower(name), pattern) {
			continue
		}

		// Get project stats
		projectPath := filepath.Join(absPath, name)
		stats := getProjectStats(projectPath)

		projects = append(projects, fmt.Sprintf("%-30s %s", name+"/", stats))
	}

	if len(projects) == 0 {
		if pattern != "" {
			return textResult(fmt.Sprintf("No projects matching '%s' in %s", input.Pattern, absPath)), nil, nil
		}
		return textResult("No project directories found in " + absPath), nil, nil
	}

	header := fmt.Sprintf("Projects in %s", absPath)
	if pattern != "" {
		header = fmt.Sprintf("Projects matching '%s' in %s", input.Pattern, absPath)
	}

	return textResult(fmt.Sprintf("%s:\n\n%s", header, strings.Join(projects, "\n"))), nil, nil
}

// getProjectStats returns a brief summary of a project directory
// Uses the same scanner logic as the main codemap command (respects .gitignore)
func getProjectStats(path string) string {
	gitignore := scanner.LoadGitignore(path)
	files, err := scanner.ScanFiles(path, gitignore)
	if err != nil {
		return "(error scanning)"
	}

	// Count files by language
	langCounts := make(map[string]int)
	for _, f := range files {
		lang := scanner.DetectLanguage(f.Path)
		if lang != "" {
			langCounts[lang]++
		}
	}

	// Find primary language
	var primaryLang string
	var maxCount int
	for lang, count := range langCounts {
		if count > maxCount {
			maxCount = count
			primaryLang = lang
		}
	}

	// Check if it's a git repo
	isGit := ""
	if _, err := os.Stat(filepath.Join(path, ".git")); err == nil {
		isGit = " [git]"
	}

	if info, ok := scanner.LangDisplay[primaryLang]; ok {
		return fmt.Sprintf("(%d files, %s%s)", len(files), info.Full, isGit)
	}
	return fmt.Sprintf("(%d files%s)", len(files), isGit)
}

func handleGetImporters(ctx context.Context, req *mcp.CallToolRequest, input ImportersInput) (*mcp.CallToolResult, any, error) {
	absRoot, err := validatePath(input.Path)
	if err != nil {
		return errorResult(err.Error()), nil, nil
	}

	gitignore := scanner.LoadGitignore(absRoot)
	loader := scanner.NewGrammarLoader()

	// For importers, we only need basic info (imports)
	analyses, err := scanner.ScanForDeps(absRoot, gitignore, loader, scanner.DetailNone)
	if err != nil {
		return errorResult("Scan error: " + err.Error()), nil, nil
	}

	targetBase := filepath.Base(input.File)
	targetNoExt := strings.TrimSuffix(targetBase, filepath.Ext(targetBase))
	targetDir := filepath.Dir(input.File)

	var importers []string
	for _, a := range analyses {
		// Skip files in the same directory (same package in Go)
		if filepath.Dir(a.Path) == targetDir {
			continue
		}
		for _, imp := range a.Imports {
			impBase := filepath.Base(imp)
			impNoExt := strings.TrimSuffix(impBase, filepath.Ext(impBase))
			// Match by filename, name without ext, full path, or package/directory
			if impBase == targetBase || impNoExt == targetNoExt ||
				strings.HasSuffix(imp, input.File) ||
				strings.HasSuffix(imp, targetDir) || imp == targetDir {
				importers = append(importers, a.Path)
				break
			}
		}
	}

	if len(importers) == 0 {
		return textResult("No files import '" + input.File + "'"), nil, nil
	}

	return textResult(fmt.Sprintf("%d files import '%s':\n%s", len(importers), input.File, strings.Join(importers, "\n"))), nil, nil
}

func handleGetSymbol(ctx context.Context, req *mcp.CallToolRequest, input SymbolInput) (*mcp.CallToolResult, any, error) {
	absRoot, err := validatePath(input.Path)
	if err != nil {
		return errorResult(err.Error()), nil, nil
	}

	gitignore := scanner.LoadGitignore(absRoot)
	loader := scanner.NewGrammarLoader()

	// Use signature detail level to get function signatures
	analyses, err := scanner.ScanForDeps(absRoot, gitignore, loader, scanner.DetailSignature)
	if err != nil {
		return errorResult("Scan error: " + err.Error()), nil, nil
	}

	// Build query
	query := scanner.SymbolQuery{
		Name: input.Name,
		Kind: input.Kind,
		File: input.File,
	}

	matches := scanner.SearchSymbols(analyses, query)

	if len(matches) == 0 {
		msg := fmt.Sprintf("No symbols found matching '%s'", input.Name)
		if input.Kind != "" && input.Kind != "all" {
			msg += fmt.Sprintf(" (kind: %s)", input.Kind)
		}
		if input.File != "" {
			msg += fmt.Sprintf(" in file '%s'", input.File)
		}
		return textResult(msg), nil, nil
	}

	// Format output
	var sb strings.Builder
	sb.WriteString(fmt.Sprintf("=== Symbol Search: \"%s\" ===\n", input.Name))
	sb.WriteString(fmt.Sprintf("Path: %s\n\n", absRoot))
	sb.WriteString(fmt.Sprintf("Found %d matches:\n\n", len(matches)))

	funcCount := 0
	typeCount := 0

	for _, m := range matches {
		if m.Kind == "function" {
			funcCount++
		} else {
			typeCount++
		}

		sb.WriteString(fmt.Sprintf("  %s:%d\n", m.File, m.Line))

		if m.Kind == "function" {
			if m.Signature != "" {
				sb.WriteString(fmt.Sprintf("  ├─ %s\n", m.Signature))
			} else {
				sb.WriteString(fmt.Sprintf("  ├─ func %s\n", m.Name))
			}
		} else {
			sb.WriteString(fmt.Sprintf("  ├─ %s %s\n", m.TypeKind, m.Name))
		}

		if m.Exported {
			sb.WriteString("  └─ exported\n")
		} else {
			sb.WriteString("  └─ private\n")
		}
		sb.WriteString("\n")
	}

	sb.WriteString("───────────────────────────────────\n")
	sb.WriteString(fmt.Sprintf("Matches: %d", len(matches)))
	if funcCount > 0 && typeCount > 0 {
		sb.WriteString(fmt.Sprintf(" (%d functions, %d types)", funcCount, typeCount))
	} else if funcCount > 0 {
		funcWord := "functions"
		if funcCount == 1 {
			funcWord = "function"
		}
		sb.WriteString(fmt.Sprintf(" (%d %s)", funcCount, funcWord))
	} else if typeCount > 0 {
		typeWord := "types"
		if typeCount == 1 {
			typeWord = "type"
		}
		sb.WriteString(fmt.Sprintf(" (%d %s)", typeCount, typeWord))
	}
	sb.WriteString("\n")

	return textResult(sb.String()), nil, nil
}

// ANSI escape code pattern
var ansiRegex = regexp.MustCompile(`\x1b\[[0-9;]*m`)

// stripANSI removes ANSI color codes from a string
func stripANSI(s string) string {
	return ansiRegex.ReplaceAllString(s, "")
}

// captureOutput captures stdout from a function and strips ANSI codes
func captureOutput(f func()) string {
	old := os.Stdout
	r, w, _ := os.Pipe()
	os.Stdout = w

	f()

	w.Close()
	os.Stdout = old

	var buf bytes.Buffer
	buf.ReadFrom(r)
	return stripANSI(buf.String())
}
</file>
<file path="render/api.go">
package render

import (
	"fmt"
	"path/filepath"
	"sort"
	"strings"

	"codemap/scanner"
)

// APIView renders a compact public API surface view
func APIView(project scanner.DepsProject) {
	files := project.Files
	projectName := filepath.Base(project.Root)

	if len(files) == 0 {
		fmt.Println("  No source files found.")
		return
	}

	fmt.Println()
	fmt.Printf("=== API Surface: %s ===\n", projectName)
	fmt.Println()

	// Group by directory
	packages := make(map[string][]scanner.FileAnalysis)
	for _, f := range files {
		dir := filepath.Dir(f.Path)
		if dir == "." {
			dir = projectName
		}
		packages[dir] = append(packages[dir], f)
	}

	// Sort package names
	var pkgNames []string
	for name := range packages {
		pkgNames = append(pkgNames, name)
	}
	sort.Strings(pkgNames)

	for _, pkg := range pkgNames {
		pkgFiles := packages[pkg]

		// Collect all exported types and functions
		var exportedTypes []scanner.TypeInfo
		var exportedFuncs []scanner.FuncInfo

		for _, f := range pkgFiles {
			for _, t := range f.Types {
				if t.IsExported {
					exportedTypes = append(exportedTypes, t)
				}
			}
			for _, fn := range f.Functions {
				if fn.IsExported {
					exportedFuncs = append(exportedFuncs, fn)
				}
			}
		}

		// Skip packages with no exports
		if len(exportedTypes) == 0 && len(exportedFuncs) == 0 {
			continue
		}

		fmt.Printf("%s/\n", pkg)

		// Group methods by receiver type
		methodsByType := make(map[string][]scanner.FuncInfo)
		var standaloneFuncs []scanner.FuncInfo

		for _, fn := range exportedFuncs {
			if fn.Receiver != "" {
				// Extract type name from receiver
				typeName := extractTypeName(fn.Receiver)
				methodsByType[typeName] = append(methodsByType[typeName], fn)
			} else {
				standaloneFuncs = append(standaloneFuncs, fn)
			}
		}

		// Print types with their methods
		for _, t := range exportedTypes {
			icon := typeIcon(t.Kind)

			if len(t.Fields) > 0 {
				fmt.Printf("  %s %s {%s}\n", icon, t.Name, strings.Join(t.Fields, ", "))
			} else {
				fmt.Printf("  %s %s\n", icon, t.Name)
			}

			// Print methods for this type
			if methods, ok := methodsByType[t.Name]; ok {
				for _, m := range methods {
					if m.Signature != "" {
						fmt.Printf("    + %s\n", m.Signature)
					} else {
						fmt.Printf("    + (%s) %s()\n", m.Receiver, m.Name)
					}
				}
			}
		}

		// Print standalone functions
		if len(standaloneFuncs) > 0 {
			for _, fn := range standaloneFuncs {
				if fn.Signature != "" {
					fmt.Printf("  + %s\n", fn.Signature)
				} else {
					fmt.Printf("  + %s()\n", fn.Name)
				}
			}
		}

		fmt.Println()
	}

	// Summary
	totalTypes := 0
	totalFuncs := 0
	for _, f := range files {
		for _, t := range f.Types {
			if t.IsExported {
				totalTypes++
			}
		}
		for _, fn := range f.Functions {
			if fn.IsExported {
				totalFuncs++
			}
		}
	}

	fmt.Printf("─────────────────────────────────────────────────────────────\n")
	fmt.Printf("Exported: %d types · %d functions\n", totalTypes, totalFuncs)
	fmt.Println()
}

// typeIcon returns an ASCII icon for the type kind
func typeIcon(kind scanner.TypeKind) string {
	switch kind {
	case scanner.KindStruct:
		return "[S]"
	case scanner.KindClass:
		return "[C]"
	case scanner.KindInterface:
		return "[I]"
	case scanner.KindTrait:
		return "[T]"
	case scanner.KindEnum:
		return "[E]"
	case scanner.KindTypeAlias:
		return "[A]"
	case scanner.KindProtocol:
		return "[P]"
	default:
		return "[?]"
	}
}

// extractTypeName extracts type name from receiver like "(l *GrammarLoader)"
func extractTypeName(receiver string) string {
	// Remove parentheses
	r := strings.Trim(receiver, "()")

	// Split by space, take last part (the type)
	parts := strings.Fields(r)
	if len(parts) == 0 {
		return ""
	}

	typePart := parts[len(parts)-1]
	// Remove pointer asterisk
	return strings.TrimPrefix(typePart, "*")
}
</file>
<file path="render/colors.go">
package render

import (
	"os"
	"strings"

	"golang.org/x/term"
)

// ANSI color codes
const (
	Reset     = "\033[0m"
	Bold      = "\033[1m"
	Dim       = "\033[2m"
	White     = "\033[37m"
	Cyan      = "\033[36m"
	Yellow    = "\033[33m"
	Magenta   = "\033[35m"
	Green     = "\033[32m"
	Red       = "\033[31m"
	Blue      = "\033[34m"
	BoldWhite = "\033[1;37m"
	BoldRed   = "\033[1;31m"
	BoldBlue  = "\033[1;34m"
	DimWhite  = "\033[2;37m"
	BoldGreen = "\033[1;32m"
)

// Asset extensions to exclude from "top large files"
var assetExtensions = map[string]bool{
	".png": true, ".jpg": true, ".jpeg": true, ".gif": true, ".svg": true, ".ico": true, ".webp": true,
	".ttf": true, ".otf": true, ".woff": true, ".woff2": true, ".eot": true,
	".mp3": true, ".wav": true, ".mp4": true, ".mov": true,
	".zip": true, ".tar": true, ".gz": true, ".7z": true, ".rar": true,
	".pdf": true, ".doc": true, ".docx": true, ".xls": true, ".xlsx": true,
	".exe": true, ".dll": true, ".so": true, ".dylib": true, ".bin": true,
	".lock": true, ".resolved": true, ".sum": true,
	".map": true, ".nib": true, ".xib": true, ".storyboard": true,
}

// GetFileColor returns ANSI color code based on file extension
func GetFileColor(ext string) string {
	ext = strings.ToLower(ext)
	switch {
	case ext == ".go" || ext == ".mod" || ext == ".sum" || ext == ".dart":
		return Cyan
	case ext == ".py" || ext == ".js" || ext == ".ts" || ext == ".jsx" || ext == ".tsx" ||
		ext == ".mjs" || ext == ".cjs" || ext == ".vue" || ext == ".svelte" ||
		ext == ".pl" || ext == ".pm" || ext == ".sql" || ext == ".db" || ext == ".sqlite":
		return Yellow
	case ext == ".html" || ext == ".css" || ext == ".scss" || ext == ".sass" ||
		ext == ".less" || ext == ".php" || ext == ".hs" || ext == ".tf" || ext == ".hcl":
		return Magenta
	case ext == ".md" || ext == ".txt" || ext == ".rst" || ext == ".adoc":
		return Green
	case ext == ".json" || ext == ".yaml" || ext == ".yml" || ext == ".toml" ||
		ext == ".xml" || ext == ".csv" || ext == ".ini" || ext == ".conf" ||
		ext == ".env" || ext == ".rb" || ext == ".erb" || ext == ".gemspec":
		return Red
	case ext == ".sh" || ext == ".bat" || ext == ".ps1" ||
		strings.ToLower(ext) == "makefile" || strings.ToLower(ext) == "dockerfile":
		return BoldWhite
	case ext == ".swift" || ext == ".kt" || ext == ".java" || ext == ".scala" ||
		ext == ".groovy" || ext == ".rs" || ext == ".rlib":
		return BoldRed
	case ext == ".c" || ext == ".cpp" || ext == ".h" || ext == ".hpp" ||
		ext == ".cc" || ext == ".m" || ext == ".mm" || ext == ".cs" || ext == ".fs":
		return BoldBlue
	case ext == ".lua" || ext == ".r" || ext == ".rmd":
		return Blue
	case ext == ".gitignore" || ext == ".dockerignore" || ext == ".gitattributes":
		return DimWhite
	default:
		return White
	}
}

// GetTerminalWidth returns terminal width or default
func GetTerminalWidth() int {
	width, _, err := term.GetSize(int(os.Stdout.Fd()))
	if err != nil || width <= 0 {
		return 80
	}
	return width
}

// CenterString centers a string in the given width
func CenterString(s string, width int) string {
	if len(s) >= width {
		return s
	}
	leftPad := (width - len(s)) / 2
	rightPad := width - len(s) - leftPad
	return strings.Repeat(" ", leftPad) + s + strings.Repeat(" ", rightPad)
}

// IsAssetExtension returns true if the extension is an asset
func IsAssetExtension(ext string) bool {
	return assetExtensions[strings.ToLower(ext)]
}
</file>
<file path="render/depgraph.go">
package render

import (
	"fmt"
	"path/filepath"
	"regexp"
	"sort"
	"strings"

	"codemap/scanner"
)

// Language compatibility groups
var langGroups = map[string]string{
	"python":     "python",
	"go":         "go",
	"javascript": "js",
	"typescript": "js",
	"rust":       "rust",
	"ruby":       "ruby",
	"c":          "c",
	"cpp":        "c",
	"java":       "java",
	"swift":      "swift",
	"bash":       "bash",
	"kotlin":     "kotlin",
	"c_sharp":    "c_sharp",
	"php":        "php",
	"dart":       "dart",
	"r":          "r",
}

// Standard library names to filter out
var stdlibNames = map[string]bool{
	// Go stdlib
	"errors": true, "fmt": true, "io": true, "os": true, "path": true, "sync": true, "time": true, "context": true, "http": true,
	"net": true, "bytes": true, "strings": true, "strconv": true, "sort": true, "flag": true, "log": true, "bufio": true,
	"encoding": true, "testing": true, "runtime": true, "unsafe": true, "reflect": true, "regexp": true,
	// Python stdlib
	"logging": true, "typing": true, "collections": true, "datetime": true, "json": true, "sys": true, "re": true,
	"pathlib": true, "hashlib": true, "base64": true, "asyncio": true, "enum": true, "functools": true, "random": true,
	"math": true, "copy": true, "itertools": true, "contextlib": true,
	// JS/TS common
	"fs": true, "util": true, "events": true, "stream": true, "crypto": true, "https": true,
	"react": true, "filepath": true, "embed": true,
}

// normalizeImport normalizes an import string
func normalizeImport(imp, lang string) string {
	imp = strings.Trim(imp, "\"'")
	if strings.Contains(imp, "/") {
		parts := strings.Split(imp, "/")
		imp = parts[len(parts)-1]
	}
	if strings.Contains(imp, ".") && !strings.HasPrefix(imp, ".") {
		parts := strings.Split(imp, ".")
		imp = parts[len(parts)-1]
	}
	// Remove file extensions
	extPattern := regexp.MustCompile(`\.(py|go|js|ts|jsx|tsx|rb|rs|c|h|cpp|hpp|java|swift)$`)
	imp = extPattern.ReplaceAllString(imp, "")
	return strings.ToLower(imp)
}

// findInternalDeps finds which files import which other files
func findInternalDeps(files []scanner.FileAnalysis) map[string][]string {
	// Build lookup: name -> list of (path, language_group)
	type fileInfo struct {
		path      string
		langGroup string
	}
	nameToInfos := make(map[string][]fileInfo)

	for _, f := range files {
		langGroup := langGroups[f.Language]
		if langGroup == "" {
			langGroup = f.Language
		}
		basename := filepath.Base(f.Path)
		extPattern := regexp.MustCompile(`\.[^.]+$`)
		name := strings.ToLower(extPattern.ReplaceAllString(basename, ""))
		nameToInfos[name] = append(nameToInfos[name], fileInfo{f.Path, langGroup})
	}

	deps := make(map[string][]string)

	for _, f := range files {
		srcLang := f.Language
		srcGroup := langGroups[srcLang]
		if srcGroup == "" {
			srcGroup = srcLang
		}

		for _, imp := range f.Imports {
			// Skip stdlib-looking imports
			if !strings.Contains(imp, "/") && !strings.Contains(imp, ".") {
				if stdlibNames[strings.ToLower(imp)] {
					continue
				}
			}

			norm := normalizeImport(imp, srcLang)
			if stdlibNames[norm] {
				continue
			}

			if infos, ok := nameToInfos[norm]; ok {
				srcBasename := filepath.Base(f.Path)
				for _, info := range infos {
					if info.path == f.Path {
						continue // Skip self
					}
					if srcGroup != info.langGroup {
						continue // Skip cross-language
					}
					targetName := filepath.Base(info.path)
					if targetName == srcBasename {
						continue // Skip same-basename
					}
					// Check if already added
					found := false
					for _, d := range deps[f.Path] {
						if d == targetName {
							found = true
							break
						}
					}
					if !found {
						deps[f.Path] = append(deps[f.Path], targetName)
					}
				}
			}
		}
	}

	return deps
}

// getSystemName infers a system/component name from directory path
func getSystemName(dirPath string) string {
	parts := strings.Split(strings.ReplaceAll(dirPath, "\\", "/"), "/")
	skip := map[string]bool{"src": true, "lib": true, "app": true, "internal": true, "pkg": true, ".": true, "": true}

	var meaningful []string
	for _, p := range parts {
		if !skip[strings.ToLower(p)] {
			meaningful = append(meaningful, p)
		}
	}

	if len(meaningful) > 0 {
		name := meaningful[0]
		name = strings.ReplaceAll(name, "_", " ")
		name = strings.ReplaceAll(name, "-", " ")
		return strings.Title(name)
	}

	if len(parts) > 0 {
		return strings.Title(parts[len(parts)-1])
	}
	return "Root"
}

// Depgraph renders the dependency flow visualization
func Depgraph(project scanner.DepsProject) {
	files := project.Files
	externalDeps := project.ExternalDeps
	projectName := filepath.Base(project.Root)

	if len(files) == 0 {
		fmt.Println("  No source files found.")
		return
	}

	// Build internal names lookup
	internalNames := make(map[string]bool)
	extPattern := regexp.MustCompile(`\.[^.]+$`)
	for _, f := range files {
		basename := filepath.Base(f.Path)
		name := strings.ToLower(extPattern.ReplaceAllString(basename, ""))
		internalNames[name] = true
	}

	internalDeps := findInternalDeps(files)

	// Count dependencies on each file
	depCounts := make(map[string]int)
	for _, targets := range internalDeps {
		for _, target := range targets {
			depCounts[target]++
		}
	}

	// Group by top-level system
	systems := make(map[string][]scanner.FileAnalysis)
	for _, f := range files {
		parts := strings.Split(strings.ReplaceAll(f.Path, "\\", "/"), "/")
		system := "."
		if len(parts) > 1 {
			system = parts[0]
		}
		systems[system] = append(systems[system], f)
	}

	fmt.Println()

	// Build external deps by language
	extByLang := make(map[string][]string)
	versionPattern := regexp.MustCompile(`^v\d+$`)

	for lang, deps := range externalDeps {
		if len(deps) == 0 {
			continue
		}
		seen := make(map[string]bool)
		var names []string
		for _, d := range deps {
			parts := strings.Split(d, "/")
			name := parts[len(parts)-1]
			if versionPattern.MatchString(name) && len(parts) > 1 {
				name = parts[len(parts)-2]
			}
			if !versionPattern.MatchString(name) && len(name) > 1 && !seen[name] {
				seen[name] = true
				names = append(names, name)
			}
		}
		if len(names) > 0 {
			extByLang[lang] = names
		}
	}

	// Calculate box width
	title := fmt.Sprintf("%s - Dependency Flow", projectName)
	maxWidth := len(title) + 6

	// Format dep lines
	var depLines []string
	langOrder := []string{"go", "javascript", "python", "swift", "rust", "ruby", "bash", "kotlin", "c_sharp", "php", "dart", "r"}

	for _, lang := range langOrder {
		if names, ok := extByLang[lang]; ok {
			label := scanner.LangDisplay[lang].Short
			if label == "" {
				label = strings.Title(lang)
			}
			line := fmt.Sprintf("%s: %s", label, strings.Join(names, ", "))
			depLines = append(depLines, line)
			if len(line)+4 > maxWidth {
				maxWidth = len(line) + 4
			}
		}
	}

	// Cap at 80
	if maxWidth > 80 {
		maxWidth = 80
	}
	innerWidth := maxWidth - 2

	// Print header box
	fmt.Printf("╭%s╮\n", strings.Repeat("─", innerWidth))
	titlePadded := CenterString(title, innerWidth)
	fmt.Printf("│%s│\n", titlePadded)

	if len(depLines) > 0 {
		fmt.Printf("├%s┤\n", strings.Repeat("─", innerWidth))
		contentWidth := innerWidth - 2

		for _, line := range depLines {
			for len(line) > contentWidth {
				breakAt := strings.LastIndex(line[:contentWidth], ", ")
				if breakAt == -1 {
					breakAt = contentWidth - 1
				} else {
					breakAt++
				}
				fmt.Printf("│ %-*s │\n", contentWidth, line[:breakAt])
				line = "    " + strings.TrimLeft(line[breakAt:], " ")
			}
			fmt.Printf("│ %-*s │\n", contentWidth, line)
		}
	}

	fmt.Printf("╰%s╯\n", strings.Repeat("─", innerWidth))
	fmt.Println()

	// Sort systems
	var systemNames []string
	for name := range systems {
		systemNames = append(systemNames, name)
	}
	sort.Strings(systemNames)

	// Render each system
	for _, system := range systemNames {
		sysFiles := systems[system]
		systemName := getSystemName(system)

		// Check if system has content
		hasContent := false
		for _, f := range sysFiles {
			if len(internalDeps[f.Path]) > 0 || len(f.Functions) > 0 {
				hasContent = true
				break
			}
		}
		if !hasContent {
			continue
		}

		// Section header
		headerLen := 60 - len(systemName) - 1
		if headerLen < 1 {
			headerLen = 1
		}
		fmt.Printf("%s %s\n", systemName, strings.Repeat("═", headerLen))

		rendered := make(map[string]bool)

		for _, f := range sysFiles {
			basename := filepath.Base(f.Path)
			nameNoExt := extPattern.ReplaceAllString(basename, "")

			if rendered[basename] {
				continue
			}

			targets := internalDeps[f.Path]
			if len(targets) == 0 {
				continue
			}

			if len(targets) == 1 {
				t := targets[0]
				tName := extPattern.ReplaceAllString(t, "")

				// Check for sub-deps
				var tPath string
				for _, ff := range files {
					if filepath.Base(ff.Path) == t {
						tPath = ff.Path
						break
					}
				}

				subTargets := internalDeps[tPath]
				if len(subTargets) > 0 {
					var subNames []string
					for i, s := range subTargets {
						if i >= 3 {
							break
						}
						subNames = append(subNames, extPattern.ReplaceAllString(s, ""))
					}
					chain := fmt.Sprintf("%s ───▶ %s ───▶ %s", nameNoExt, tName, strings.Join(subNames, ", "))
					if len(subTargets) > 3 {
						chain += fmt.Sprintf(" +%d", len(subTargets)-3)
					}
					fmt.Printf("  %s\n", chain)
				} else {
					fmt.Printf("  %s ───▶ %s\n", nameNoExt, tName)
				}
			} else {
				var targetStrs []string
				for _, t := range targets {
					targetStrs = append(targetStrs, extPattern.ReplaceAllString(t, ""))
				}

				if len(targets) <= 4 {
					fmt.Printf("  %s ───▶ %s\n", nameNoExt, strings.Join(targetStrs, ", "))
				} else {
					fmt.Printf("  %s ──┬──▶ %s\n", nameNoExt, targetStrs[0])
					for _, t := range targetStrs[1 : len(targetStrs)-1] {
						fmt.Printf("  %s   ├──▶ %s\n", strings.Repeat(" ", len(nameNoExt)), t)
					}
					fmt.Printf("  %s   └──▶ %s\n", strings.Repeat(" ", len(nameNoExt)), targetStrs[len(targetStrs)-1])
				}
			}

			rendered[basename] = true
		}

		// Count standalone files
		standaloneCount := 0
		for _, f := range sysFiles {
			basename := filepath.Base(f.Path)
			if !rendered[basename] && len(f.Functions) > 0 {
				standaloneCount++
			}
		}

		if standaloneCount > 0 {
			fmt.Printf("  +%d standalone files\n", standaloneCount)
		}

		fmt.Println()
	}

	// HUBS section
	if len(depCounts) > 0 {
		type hub struct {
			name  string
			count int
		}
		var hubs []hub
		for name, count := range depCounts {
			if count >= 2 {
				hubs = append(hubs, hub{name, count})
			}
		}
		sort.Slice(hubs, func(i, j int) bool {
			return hubs[i].count > hubs[j].count
		})
		if len(hubs) > 6 {
			hubs = hubs[:6]
		}

		if len(hubs) > 0 {
			fmt.Println(strings.Repeat("─", 61))
			var hubStrs []string
			for _, h := range hubs {
				hubStrs = append(hubStrs, fmt.Sprintf("%s (%d←)", extPattern.ReplaceAllString(h.name, ""), h.count))
			}
			fmt.Printf("HUBS: %s\n", strings.Join(hubStrs, ", "))
		}
	}

	// Summary
	totalFuncs := 0
	totalTypes := 0
	for _, f := range files {
		totalFuncs += len(f.Functions)
		totalTypes += len(f.Types)
	}
	internalCount := 0
	for _, targets := range internalDeps {
		internalCount += len(targets)
	}
	if totalTypes > 0 {
		fmt.Printf("%d files · %d functions · %d types · %d deps\n", len(files), totalFuncs, totalTypes, internalCount)
	} else {
		fmt.Printf("%d files · %d functions · %d deps\n", len(files), totalFuncs, internalCount)
	}
	fmt.Println()
}
</file>
<file path="render/skyline.go">
package render

import (
	"fmt"
	"math"
	"math/rand"
	"os"
	"path/filepath"
	"sort"
	"strings"
	"time"

	"codemap/scanner"

	tea "github.com/charmbracelet/bubbletea"
	"golang.org/x/term"
)

// Code extensions for skyline (what counts as "source code")
var codeExtensions = map[string]bool{
	".py": true, ".js": true, ".ts": true, ".jsx": true, ".tsx": true, ".go": true, ".rs": true, ".rb": true, ".java": true,
	".swift": true, ".kt": true, ".scala": true, ".c": true, ".cpp": true, ".h": true, ".hpp": true, ".cs": true, ".fs": true,
	".php": true, ".lua": true, ".r": true, ".dart": true, ".vue": true, ".svelte": true, ".elm": true, ".ex": true, ".exs": true,
	".hs": true, ".ml": true, ".clj": true, ".erl": true, ".sh": true, ".bash": true, ".zsh": true, ".fish": true, ".ps1": true,
	".html": true, ".css": true, ".scss": true, ".sass": true, ".less": true,
	".sql": true, ".graphql": true, ".proto": true,
}

var codeFilenames = map[string]bool{
	"Makefile": true, "Dockerfile": true, "Rakefile": true, "Gemfile": true, "Procfile": true,
	"Vagrantfile": true, "Jenkinsfile": true, "Fastfile": true,
}

// Building dimensions
const (
	buildingWidth = 7
	maxHeight     = 12
	minHeight     = 2
	skyHeight     = 6
)

// Building colors
var buildingColors = []string{
	"\033[36m", // cyan
	"\033[33m", // yellow
	"\033[35m", // magenta
	"\033[31m", // red
	"\033[32m", // green
	"\033[34m", // blue
	"\033[96m", // bright cyan
	"\033[93m", // bright yellow
	"\033[95m", // bright magenta
	"\033[91m", // bright red
	"\033[92m", // bright green
	"\033[94m", // bright blue
}

// Building data
type building struct {
	height   int
	char     rune
	color    string
	ext      string
	extLabel string
	count    int
	size     int64
	gap      int
}

// Aggregated extension data
type extAgg struct {
	ext   string
	size  int64
	count int
}

// filterCodeFiles returns only source code files
func filterCodeFiles(files []scanner.FileInfo) []scanner.FileInfo {
	var result []scanner.FileInfo
	for _, f := range files {
		if codeExtensions[strings.ToLower(f.Ext)] || codeFilenames[filepath.Base(f.Path)] {
			result = append(result, f)
		}
	}
	if len(result) == 0 {
		return files
	}
	return result
}

// aggregateByExtension groups files by extension
func aggregateByExtension(files []scanner.FileInfo) []extAgg {
	groups := make(map[string]*extAgg)
	for _, f := range files {
		ext := strings.ToLower(f.Ext)
		if ext == "" {
			ext = filepath.Base(f.Path)
		}
		if groups[ext] == nil {
			groups[ext] = &extAgg{ext: ext}
		}
		groups[ext].size += f.Size
		groups[ext].count++
	}

	var result []extAgg
	for _, agg := range groups {
		result = append(result, *agg)
	}
	sort.Slice(result, func(i, j int) bool {
		return result[i].size > result[j].size
	})
	return result
}

// getBuildingChar returns building texture character
func getBuildingChar(ext string) rune {
	ext = strings.ToLower(ext)
	switch {
	case ext == ".go" || ext == ".dart":
		return '▓'
	case ext == ".py" || ext == ".js" || ext == ".ts" || ext == ".jsx" || ext == ".tsx":
		return '░'
	case ext == ".rb" || ext == ".erb":
		return '▒'
	case ext == ".sh" || ext == "makefile" || ext == "dockerfile":
		return '█'
	default:
		return '▓'
	}
}

// createBuildings creates building data from aggregated files
func createBuildings(sorted []extAgg, width int) []building {
	if len(sorted) == 0 {
		return nil
	}

	// Find size range
	var minSize, maxSize int64 = sorted[len(sorted)-1].size, sorted[0].size
	sizeRange := maxSize - minSize
	if sizeRange == 0 {
		sizeRange = 1
	}

	getHeight := func(size int64) int {
		ratio := float64(size-minSize) / float64(sizeRange)
		ratio = math.Sqrt(ratio)
		return minHeight + int(ratio*float64(maxHeight-minHeight))
	}

	rand.Seed(42)
	var buildings []building

	for idx, agg := range sorted {
		extLabel := agg.ext
		if strings.HasPrefix(extLabel, ".") && len(extLabel) > 5 {
			extLabel = extLabel[:5]
		}

		buildings = append(buildings, building{
			height:   getHeight(agg.size),
			char:     getBuildingChar(agg.ext),
			color:    buildingColors[idx%len(buildingColors)],
			ext:      agg.ext,
			extLabel: extLabel,
			count:    agg.count,
			size:     agg.size,
			gap:      []int{1, 2, 2, 3}[rand.Intn(4)],
		})
	}

	// Arrange: tallest in middle
	sort.Slice(buildings, func(i, j int) bool {
		return buildings[i].height > buildings[j].height
	})

	var arranged []building
	for i, b := range buildings {
		if i%2 == 0 {
			arranged = append(arranged, b)
		} else {
			arranged = append([]building{b}, arranged...)
		}
	}

	// Limit to fit width
	totalWidth := 0
	for _, b := range arranged {
		totalWidth += buildingWidth + b.gap
	}
	for totalWidth > width-8 && len(arranged) > 0 {
		if len(arranged)%2 == 0 {
			arranged = arranged[1:]
		} else {
			arranged = arranged[:len(arranged)-1]
		}
		totalWidth = 0
		for _, b := range arranged {
			totalWidth += buildingWidth + b.gap
		}
	}

	return arranged
}

// Skyline renders the city skyline visualization
func Skyline(project scanner.Project, animate bool) {
	files := project.Files
	projectName := filepath.Base(project.Root)

	width, _, err := term.GetSize(int(os.Stdout.Fd()))
	if err != nil || width <= 0 {
		width = 80
	}

	codeFiles := filterCodeFiles(files)
	sorted := aggregateByExtension(codeFiles)
	arranged := createBuildings(sorted, width)

	if len(arranged) == 0 {
		fmt.Println(Dim + "No source files to display" + Reset)
		return
	}

	// Calculate layout
	totalWidth := 0
	for _, b := range arranged {
		totalWidth += buildingWidth + b.gap
	}
	leftMargin := (width - totalWidth) / 2
	scenePadding := 4
	sceneLeft := max(0, leftMargin-scenePadding)
	sceneRight := min(width, leftMargin+totalWidth+scenePadding)
	sceneWidth := sceneRight - sceneLeft

	if animate {
		renderAnimated(arranged, width, leftMargin, sceneLeft, sceneRight, sceneWidth, codeFiles, projectName, sorted)
	} else {
		renderStatic(arranged, width, leftMargin, sceneLeft, sceneRight, sceneWidth, codeFiles, projectName, sorted)
	}
}

// renderStatic renders static skyline
func renderStatic(arranged []building, width, leftMargin, sceneLeft, sceneRight, sceneWidth int,
	codeFiles []scanner.FileInfo, projectName string, sorted []extAgg) {

	rand.Seed(42)

	// Build grid
	grid := make([][]rune, skyHeight+maxHeight+1)
	for i := range grid {
		grid[i] = make([]rune, width)
		for j := range grid[i] {
			grid[i][j] = ' '
		}
	}

	// Render sky
	for row := 0; row < skyHeight; row++ {
		for i := 0; i < sceneWidth/10; i++ {
			col := rand.Intn(sceneRight-sceneLeft) + sceneLeft
			if col >= 0 && col < width {
				stars := []rune{'·', '·', '·', '✦', '*', '·'}
				grid[row][col] = stars[rand.Intn(len(stars))]
			}
		}
	}

	// Moon
	moonCol := sceneRight - 3
	if moonCol >= 0 && moonCol < width {
		grid[1][moonCol] = '◐'
	}

	// Render buildings
	col := leftMargin
	for _, b := range arranged {
		buildingTop := skyHeight + maxHeight - b.height

		// Rooftop cap
		if buildingTop > skyHeight {
			for j := 0; j < buildingWidth; j++ {
				if col+j < width {
					grid[buildingTop][col+j] = '▄'
				}
			}
		}

		// Building body
		buildingHeight := skyHeight + maxHeight + 1 - buildingTop - 1
		centerRow := buildingTop + 1 + buildingHeight/2

		for row := buildingTop + 1; row < skyHeight+maxHeight+1; row++ {
			for j := 0; j < buildingWidth; j++ {
				if col+j < width {
					if row == centerRow && buildingHeight >= 3 {
						extStart := (buildingWidth - len(b.extLabel)) / 2
						extEnd := extStart + len(b.extLabel)
						if j >= extStart && j < extEnd {
							grid[row][col+j] = rune(b.extLabel[j-extStart])
						} else {
							grid[row][col+j] = b.char
						}
					} else {
						grid[row][col+j] = b.char
					}
				}
			}
		}
		col += buildingWidth + b.gap
	}

	fmt.Println()

	// Print with colors
	colPositions := make([][3]interface{}, 0) // start, end, color
	col = leftMargin
	for _, b := range arranged {
		colPositions = append(colPositions, [3]interface{}{col, col + buildingWidth, b.color})
		col += buildingWidth + b.gap
	}

	// Sky rows
	for row := 0; row < skyHeight; row++ {
		for c := 0; c < width; c++ {
			ch := grid[row][c]
			switch ch {
			case '◐':
				fmt.Print(Bold + Yellow + string(ch) + Reset)
			case '·', '✦', '*':
				fmt.Print(DimWhite + string(ch) + Reset)
			default:
				fmt.Print(" ")
			}
		}
		fmt.Println()
	}

	// Building rows
	for row := skyHeight; row < len(grid); row++ {
		for c := 0; c < width; c++ {
			ch := grid[row][c]
			if ch == ' ' {
				fmt.Print(" ")
			} else if ch == '▄' {
				color := White
				for _, pos := range colPositions {
					if c >= pos[0].(int) && c < pos[1].(int) {
						color = pos[2].(string)
						break
					}
				}
				fmt.Print(color + string(ch) + Reset)
			} else if ch == '.' || (ch >= 'a' && ch <= 'z') {
				fmt.Print(DimWhite + string(ch) + Reset)
			} else if (ch >= 'A' && ch <= 'Z') || (ch >= '0' && ch <= '9') || ch == '_' || ch == '-' {
				fmt.Print(BoldWhite + string(ch) + Reset)
			} else {
				color := White
				for _, pos := range colPositions {
					if c >= pos[0].(int) && c < pos[1].(int) {
						color = pos[2].(string)
						break
					}
				}
				fmt.Print(color + string(ch) + Reset)
			}
		}
		fmt.Println()
	}

	// Ground
	ground := strings.Repeat(" ", max(0, sceneLeft)) + strings.Repeat("▀", sceneWidth)
	fmt.Println(DimWhite + ground + Reset)

	// Stats
	fmt.Println()
	title := fmt.Sprintf("─── %s ───", projectName)
	fmt.Printf("%s%s%s\n", BoldWhite, CenterString(title, width), Reset)

	var codeSize int64
	for _, f := range codeFiles {
		codeSize += f.Size
	}
	stats := fmt.Sprintf("%d languages · %d files · %s", len(sorted), len(codeFiles), formatSize(codeSize))
	fmt.Printf("%s%s%s\n", Cyan, CenterString(stats, width), Reset)
	fmt.Println()
}

// animationModel holds state for bubbletea animation
type animationModel struct {
	arranged           []building
	width              int
	leftMargin         int
	sceneLeft          int
	sceneRight         int
	sceneWidth         int
	codeFiles          []scanner.FileInfo
	projectName        string
	sorted             []extAgg
	starPositions      [][2]int
	moonCol            int
	maxBuildingHeight  int
	phase              int // 1 = rising, 2 = twinkling
	frame              int
	visibleRows        int
	shootingStarRow    int
	shootingStarCol    int
	shootingStarActive bool
	done               bool
}

type tickMsg time.Time

func tickCmd() tea.Cmd {
	return tea.Tick(60*time.Millisecond, func(t time.Time) tea.Msg {
		return tickMsg(t)
	})
}

func (m animationModel) Init() tea.Cmd {
	return tickCmd()
}

func (m animationModel) Update(msg tea.Msg) (tea.Model, tea.Cmd) {
	switch msg.(type) {
	case tea.KeyMsg:
		// Any key exits
		m.done = true
		return m, tea.Quit
	case tickMsg:
		if m.phase == 1 {
			m.visibleRows++
			if m.visibleRows > m.maxBuildingHeight+2 {
				m.phase = 2
				m.frame = 0
			}
		} else {
			m.frame++
			// Shooting star logic
			if m.shootingStarActive {
				m.shootingStarCol += 3
				if m.shootingStarCol > m.sceneRight {
					m.shootingStarActive = false
				}
			} else if m.frame == 10 || m.frame == 28 {
				m.shootingStarActive = true
				m.shootingStarRow = rand.Intn(3)
				m.shootingStarCol = m.sceneLeft
			}
			if m.frame >= 40 {
				m.done = true
				return m, tea.Quit
			}
		}
		return m, tickCmd()
	}
	return m, nil
}

func (m animationModel) View() string {
	var sb strings.Builder

	// Draw sky
	for row := 0; row < skyHeight; row++ {
		line := make([]rune, m.width)
		for i := range line {
			line[i] = ' '
		}

		// Stars (random twinkling)
		for _, pos := range m.starPositions {
			if pos[0] == row && rand.Float32() > 0.25 {
				stars := []rune{'·', '·', '✦', '*'}
				line[pos[1]] = stars[rand.Intn(len(stars))]
			}
		}

		// Moon
		if row == 1 && m.moonCol >= 0 && m.moonCol < m.width {
			line[m.moonCol] = '◐'
		}

		// Render sky row
		for c, ch := range line {
			// Shooting star in phase 2
			if m.phase == 2 && m.shootingStarActive && row == m.shootingStarRow {
				if c >= m.shootingStarCol && c < m.shootingStarCol+3 {
					trail := []rune{'─', '─', '★'}
					sb.WriteString(Bold + Yellow + string(trail[c-m.shootingStarCol]) + Reset)
					continue
				}
			}
			switch ch {
			case '◐':
				sb.WriteString(Bold + Yellow + string(ch) + Reset)
			case '·', '✦', '*':
				sb.WriteString(DimWhite + string(ch) + Reset)
			default:
				sb.WriteString(" ")
			}
		}
		sb.WriteString("\n")
	}

	// Build column positions for coloring
	colPositions := make([][3]interface{}, 0)
	col := m.leftMargin
	for _, b := range m.arranged {
		colPositions = append(colPositions, [3]interface{}{col, col + buildingWidth, b.color})
		col += buildingWidth + b.gap
	}

	// Draw buildings
	for row := 0; row <= maxHeight; row++ {
		visibleTop := maxHeight + 1 - m.visibleRows
		if m.phase == 2 {
			visibleTop = 0 // Full buildings in phase 2
		}

		col := m.leftMargin
		line := make([]rune, m.width)
		for i := range line {
			line[i] = ' '
		}

		for _, b := range m.arranged {
			buildingTop := maxHeight - b.height
			buildingHeight := maxHeight + 1 - buildingTop - 1
			centerRow := buildingTop + 1 + buildingHeight/2

			if row >= max(buildingTop, visibleTop) && row <= maxHeight {
				if row == buildingTop && buildingTop > 0 && row >= visibleTop {
					for j := 0; j < buildingWidth; j++ {
						if col+j < m.width {
							line[col+j] = '▄'
						}
					}
				} else if row > buildingTop {
					for j := 0; j < buildingWidth; j++ {
						if col+j < m.width {
							if row == centerRow && buildingHeight >= 3 {
								extStart := (buildingWidth - len(b.extLabel)) / 2
								extEnd := extStart + len(b.extLabel)
								if j >= extStart && j < extEnd {
									line[col+j] = rune(b.extLabel[j-extStart])
								} else {
									line[col+j] = b.char
								}
							} else {
								line[col+j] = b.char
							}
						}
					}
				}
			}
			col += buildingWidth + b.gap
		}

		// Render building row
		for c, ch := range line {
			if ch == ' ' {
				sb.WriteString(" ")
			} else if ch == '▄' {
				color := White
				for _, pos := range colPositions {
					if c >= pos[0].(int) && c < pos[1].(int) {
						color = pos[2].(string)
						break
					}
				}
				sb.WriteString(color + string(ch) + Reset)
			} else if ch == '.' || (ch >= 'a' && ch <= 'z') {
				sb.WriteString(DimWhite + string(ch) + Reset)
			} else if (ch >= 'A' && ch <= 'Z') || (ch >= '0' && ch <= '9') {
				sb.WriteString(BoldWhite + string(ch) + Reset)
			} else {
				color := White
				for _, pos := range colPositions {
					if c >= pos[0].(int) && c < pos[1].(int) {
						color = pos[2].(string)
						break
					}
				}
				sb.WriteString(color + string(ch) + Reset)
			}
		}
		sb.WriteString("\n")
	}

	// Ground
	ground := strings.Repeat(" ", max(0, m.sceneLeft)) + strings.Repeat("▀", m.sceneWidth)
	sb.WriteString(DimWhite + ground + Reset + "\n")

	return sb.String()
}

// renderAnimated renders animated skyline using bubbletea
func renderAnimated(arranged []building, width, leftMargin, sceneLeft, sceneRight, sceneWidth int,
	codeFiles []scanner.FileInfo, projectName string, sorted []extAgg) {

	rand.Seed(42)

	// Generate star positions
	var starPositions [][2]int
	for row := 0; row < skyHeight; row++ {
		for i := 0; i < sceneWidth/8; i++ {
			col := rand.Intn(sceneRight-sceneLeft) + sceneLeft
			if col >= 0 && col < width {
				starPositions = append(starPositions, [2]int{row, col})
			}
		}
	}

	moonCol := sceneRight - 3
	maxBuildingHeight := 0
	for _, b := range arranged {
		if b.height > maxBuildingHeight {
			maxBuildingHeight = b.height
		}
	}

	m := animationModel{
		arranged:          arranged,
		width:             width,
		leftMargin:        leftMargin,
		sceneLeft:         sceneLeft,
		sceneRight:        sceneRight,
		sceneWidth:        sceneWidth,
		codeFiles:         codeFiles,
		projectName:       projectName,
		sorted:            sorted,
		starPositions:     starPositions,
		moonCol:           moonCol,
		maxBuildingHeight: maxBuildingHeight,
		phase:             1,
		visibleRows:       1,
	}

	p := tea.NewProgram(m, tea.WithAltScreen())
	p.Run()

	// After animation, print static final frame to main screen
	renderStatic(arranged, width, leftMargin, sceneLeft, sceneRight, sceneWidth, codeFiles, projectName, sorted)
}

func max(a, b int) int {
	if a > b {
		return a
	}
	return b
}

func min(a, b int) int {
	if a < b {
		return a
	}
	return b
}
</file>
<file path="render/tree.go">
package render

import (
	"fmt"
	"os"
	"path/filepath"
	"sort"
	"strings"

	"codemap/scanner"
)

// treeNode represents a node in the file tree
type treeNode struct {
	name     string
	isFile   bool
	file     *scanner.FileInfo
	children map[string]*treeNode
}

// getTopLargeFiles returns paths of top 5 largest source code files
func getTopLargeFiles(files []scanner.FileInfo) map[string]bool {
	// Filter out assets and binaries (no extension = likely binary)
	var sourceFiles []scanner.FileInfo
	for _, f := range files {
		ext := strings.ToLower(f.Ext)
		// Skip if no extension (likely binary) or if it's an asset
		if ext == "" || IsAssetExtension(ext) {
			continue
		}
		sourceFiles = append(sourceFiles, f)
	}

	// Sort by size descending
	sort.Slice(sourceFiles, func(i, j int) bool {
		return sourceFiles[i].Size > sourceFiles[j].Size
	})

	// Return top 5 as set
	result := make(map[string]bool)
	for i := 0; i < len(sourceFiles) && i < 5; i++ {
		result[sourceFiles[i].Path] = true
	}
	return result
}

// getDirStats recursively calculates file count and total size
func getDirStats(node *treeNode) (int, int64) {
	if node.isFile {
		return 1, node.file.Size
	}
	count := 0
	var size int64 = 0
	for _, child := range node.children {
		c, s := getDirStats(child)
		count += c
		size += s
	}
	return count, size
}

// buildTreeStructure builds a nested tree from flat file list
func buildTreeStructure(files []scanner.FileInfo) *treeNode {
	root := &treeNode{children: make(map[string]*treeNode)}

	for _, f := range files {
		parts := strings.Split(f.Path, string(os.PathSeparator))
		current := root
		for i, part := range parts {
			if i == len(parts)-1 {
				// File
				fileCopy := f
				current.children[part] = &treeNode{
					name:   part,
					isFile: true,
					file:   &fileCopy,
				}
			} else {
				// Directory
				if current.children[part] == nil {
					current.children[part] = &treeNode{
						name:     part,
						children: make(map[string]*treeNode),
					}
				}
				current = current.children[part]
			}
		}
	}
	return root
}

// formatSize converts bytes to human readable format
func formatSize(size int64) string {
	units := []string{"B", "KB", "MB", "GB", "TB"}
	fsize := float64(size)
	for _, unit := range units[:len(units)-1] {
		if fsize < 1024 {
			return fmt.Sprintf("%.1f%s", fsize, unit)
		}
		fsize /= 1024
	}
	return fmt.Sprintf("%.1f%s", fsize, units[len(units)-1])
}

// formatTokens converts token count to human readable format (e.g., "12.5k")
func formatTokens(tokens int) string {
	if tokens < 1000 {
		return fmt.Sprintf("%d", tokens)
	}
	return fmt.Sprintf("%.1fk", float64(tokens)/1000)
}

// Tree renders the file tree to stdout
func Tree(project scanner.Project) {
	files := project.Files
	projectName := filepath.Base(project.Root)
	isDiffMode := project.DiffRef != ""

	// Calculate stats
	totalFiles := len(files)
	var totalSize int64 = 0
	var totalTokens int = 0
	var totalAdded, totalRemoved int = 0, 0
	extCount := make(map[string]int)
	for _, f := range files {
		totalSize += f.Size
		totalTokens += f.Tokens
		totalAdded += f.Added
		totalRemoved += f.Removed
		if f.Ext != "" {
			extCount[f.Ext]++
		}
	}

	// Get top extensions
	type extEntry struct {
		ext   string
		count int
	}
	var exts []extEntry
	for ext, count := range extCount {
		exts = append(exts, extEntry{ext, count})
	}
	sort.Slice(exts, func(i, j int) bool {
		return exts[i].count > exts[j].count
	})
	if len(exts) > 5 {
		exts = exts[:5]
	}

	// Get top large files
	topLarge := getTopLargeFiles(files)

	// Build stats line - different for diff mode
	var statsLine string
	if isDiffMode {
		if totalRemoved > 0 {
			statsLine = fmt.Sprintf("Changed: %d files | +%d -%d lines vs %s", totalFiles, totalAdded, totalRemoved, project.DiffRef)
		} else {
			statsLine = fmt.Sprintf("Changed: %d files | +%d lines vs %s", totalFiles, totalAdded, project.DiffRef)
		}
	} else {
		statsLine = fmt.Sprintf("Files: %d | Size: %s | Tokens: ~%s", totalFiles, formatSize(totalSize), formatTokens(totalTokens))
	}

	// Build extensions line
	var extLine string
	if len(exts) > 0 {
		extParts := make([]string, len(exts))
		for i, e := range exts {
			extParts[i] = fmt.Sprintf("%s (%d)", e.ext, e.count)
		}
		extLine = "Top Extensions: " + strings.Join(extParts, ", ")
	}

	// Calculate dynamic width based on content (minimum 64, or fit longest line)
	titleLine := fmt.Sprintf(" %s ", projectName)
	innerWidth := 64
	if len(statsLine)+4 > innerWidth {
		innerWidth = len(statsLine) + 4
	}
	if len(extLine)+4 > innerWidth {
		innerWidth = len(extLine) + 4
	}

	// Print header box
	padding := innerWidth - len(titleLine)
	leftPad := padding / 2
	rightPad := padding - leftPad
	fmt.Printf("╭%s%s%s╮\n", strings.Repeat("─", leftPad), titleLine, strings.Repeat("─", rightPad))
	fmt.Printf("│ %-*s │\n", innerWidth-2, statsLine)
	if extLine != "" {
		fmt.Printf("│ %-*s │\n", innerWidth-2, extLine)
	}
	fmt.Printf("╰%s╯\n", strings.Repeat("─", innerWidth))

	// Build and render tree
	root := buildTreeStructure(files)
	fmt.Printf("%s%s%s\n", Bold, projectName, Reset)
	printTreeNode(root, "", true, topLarge)

	// Print impact footer for diff mode
	if isDiffMode && len(project.Impact) > 0 {
		fmt.Println()
		for _, imp := range project.Impact {
			files := "files"
			if imp.UsedBy == 1 {
				files = "file"
			}
			fmt.Printf("%s⚠ %s is used by %d other %s%s\n", Yellow, imp.File, imp.UsedBy, files, Reset)
		}
	}
}

// printTreeNode recursively prints tree nodes
func printTreeNode(node *treeNode, prefix string, isLast bool, topLarge map[string]bool) {
	// Separate dirs and files
	var dirs, fileNodes []*treeNode
	for _, child := range node.children {
		if child.isFile {
			fileNodes = append(fileNodes, child)
		} else {
			dirs = append(dirs, child)
		}
	}

	// Sort
	sort.Slice(dirs, func(i, j int) bool { return dirs[i].name < dirs[j].name })
	sort.Slice(fileNodes, func(i, j int) bool { return fileNodes[i].name < fileNodes[j].name })

	// Print directories first
	for i, dir := range dirs {
		isLastDir := i == len(dirs)-1 && len(fileNodes) == 0

		// Flatten single-child directories
		mergedName := dir.name
		current := dir
		for len(current.children) == 1 {
			var onlyChild *treeNode
			for _, c := range current.children {
				onlyChild = c
			}
			if onlyChild.isFile {
				break
			}
			mergedName = mergedName + "/" + onlyChild.name
			current = onlyChild
		}

		// Get stats
		fileCount, totalSize := getDirStats(current)

		// Check for homogeneous extensions
		var commonExt string
		immediateFiles := make([]*scanner.FileInfo, 0)
		for _, c := range current.children {
			if c.isFile {
				immediateFiles = append(immediateFiles, c.file)
			}
		}
		if len(immediateFiles) > 1 {
			extSet := make(map[string]bool)
			for _, f := range immediateFiles {
				extSet[f.Ext] = true
			}
			if len(extSet) == 1 {
				for ext := range extSet {
					commonExt = ext
				}
			}
		}

		// Format stats
		var statsParts []string
		if fileCount == 1 {
			statsParts = append(statsParts, formatSize(totalSize))
		} else {
			statsParts = append(statsParts, fmt.Sprintf("%d files", fileCount))
			statsParts = append(statsParts, formatSize(totalSize))
		}
		if commonExt != "" {
			statsParts = append(statsParts, fmt.Sprintf("all %s", commonExt))
		}

		connector := "├── "
		if isLastDir {
			connector = "└── "
		}

		fmt.Printf("%s%s%s  %s/%s %s(%s)%s\n",
			prefix, connector, BoldBlue, mergedName, Reset, Dim, strings.Join(statsParts, ", "), Reset)

		newPrefix := prefix + "│   "
		if isLastDir {
			newPrefix = prefix + "    "
		}
		printTreeNode(current, newPrefix, isLastDir, topLarge)
	}

	// Print files as a grid (multi-column layout like Python)
	if len(fileNodes) > 0 {
		connector := "└── "
		termWidth := GetTerminalWidth()
		availableWidth := termWidth - len(prefix) - len(connector)
		if availableWidth < 40 {
			availableWidth = 40
		}

		// Check if all files have the same extension (strip if so, like Python)
		stripExt := ""
		if len(fileNodes) > 1 {
			extSet := make(map[string]bool)
			for _, f := range fileNodes {
				extSet[f.file.Ext] = true
			}
			if len(extSet) == 1 {
				for ext := range extSet {
					stripExt = ext
				}
			}
		}

		// Build file entries with colors
		type fileEntry struct {
			display string
			colored string
			width   int
		}
		var entries []fileEntry
		for _, f := range fileNodes {
			color := GetFileColor(f.file.Ext)
			displayName := f.name
			// Strip extension if all files have same extension
			if stripExt != "" {
				displayName = strings.TrimSuffix(displayName, stripExt)
				if displayName == "" {
					displayName = f.name // Keep original if stripping leaves empty
				}
			}

			// Prefix: diff status indicator OR star for large files
			prefix := ""
			prefixWidth := 0
			if f.file.IsNew {
				prefix = "(new) "
				prefixWidth = 6
				color = Bold + Green
			} else if f.file.Added > 0 || f.file.Removed > 0 {
				prefix = "✎ "
				prefixWidth = 3
				color = Bold + Yellow
			} else if topLarge[f.file.Path] {
				prefix = "⭐️ "
				prefixWidth = 3
				color = Bold + color
			}

			// Warning for large files (>8k tokens)
			tokenWarning := ""
			tokenWarningWidth := 0
			if f.file.Tokens >= scanner.LargeFileTokens {
				tokenWarning = " [!]"
				tokenWarningWidth = 4
			}

			// Suffix: diff stats
			suffix := ""
			suffixWidth := 0
			if f.file.IsNew && f.file.Added > 0 {
				// New file: just show total lines
				suffix = fmt.Sprintf(" (+%d)", f.file.Added)
				suffixWidth = len(suffix)
			} else if f.file.Added > 0 || f.file.Removed > 0 {
				// Modified file: show +/-
				if f.file.Removed > 0 {
					suffix = fmt.Sprintf(" (+%d -%d)", f.file.Added, f.file.Removed)
				} else {
					suffix = fmt.Sprintf(" (+%d)", f.file.Added)
				}
				suffixWidth = len(suffix)
			}

			display := prefix + displayName + suffix + tokenWarning
			colored := fmt.Sprintf("%s%s%s%s%s%s%s%s", color, prefix, displayName, Reset, Dim, suffix, Reset+Red+tokenWarning+Reset, "")
			width := prefixWidth + len(displayName) + suffixWidth + tokenWarningWidth
			entries = append(entries, fileEntry{display, colored, width})
		}

		// Calculate columns - find max width and fit columns
		maxWidth := 0
		for _, e := range entries {
			if e.width > maxWidth {
				maxWidth = e.width
			}
		}
		colWidth := maxWidth + 1
		numCols := availableWidth / colWidth
		if numCols < 1 {
			numCols = 1
		}
		if numCols > len(entries) {
			numCols = len(entries)
		}

		// Calculate number of rows
		numRows := (len(entries) + numCols - 1) / numCols

		// Print in column-major order (like Python)
		for row := 0; row < numRows; row++ {
			if row == 0 {
				fmt.Printf("%s%s", prefix, connector)
			} else {
				fmt.Printf("%s    ", prefix)
			}
			for col := 0; col < numCols; col++ {
				idx := col*numRows + row
				if idx < len(entries) {
					e := entries[idx]
					// Pad to column width
					padding := colWidth - e.width
					if padding < 0 {
						padding = 0
					}
					fmt.Printf("%s%s", e.colored, strings.Repeat(" ", padding))
				}
			}
			fmt.Println()
		}
	}
}
</file>
<file path="scanner/queries/bash.scm">
; Bash query for functions and source imports

; Function definitions
(function_definition
  name: (word) @function)

; source or . commands (imports)
(command
  name: (command_name) @_cmd
  argument: (word) @import
  (#match? @_cmd "^(source|\\.)$"))
</file>
<file path="scanner/queries/c.scm">
; C query for functions and imports

; Function definitions
(function_definition
  declarator: (function_declarator
    declarator: (identifier) @function))

; Function declarations (prototypes)
(declaration
  declarator: (function_declarator
    declarator: (identifier) @function))

; #include directives
(preproc_include
  path: (string_literal) @import)

(preproc_include
  path: (system_lib_string) @import)
</file>
<file path="scanner/queries/c_sharp.scm">
; C# query for methods, types, and using directives

; Method declarations with parameters
(method_declaration
  name: (identifier) @func.name
  parameters: (parameter_list) @func.params)

; Constructor declarations
(constructor_declaration
  name: (identifier) @func.name
  parameters: (parameter_list) @func.params)

; Class declarations
(class_declaration
  name: (identifier) @type.name) @type.class

; Interface declarations
(interface_declaration
  name: (identifier) @type.name) @type.interface

; Struct declarations
(struct_declaration
  name: (identifier) @type.name) @type.struct

; Enum declarations
(enum_declaration
  name: (identifier) @type.name) @type.enum

; Using directives
(using_directive
  (qualified_name) @import)

(using_directive
  (identifier) @import)
</file>
<file path="scanner/queries/cpp.scm">
; C++ query for functions and imports

; Function definitions
(function_definition
  declarator: (function_declarator
    declarator: (identifier) @function))

; Method definitions
(function_definition
  declarator: (function_declarator
    declarator: (qualified_identifier
      name: (identifier) @function)))

; #include directives
(preproc_include
  path: (string_literal) @import)

(preproc_include
  path: (system_lib_string) @import)
</file>
<file path="scanner/queries/dart.scm">
; Dart query for functions and imports

; Function signatures (top-level and class methods)
(function_signature
  name: (identifier) @function)

; Getter signatures
(getter_signature
  (identifier) @function)

; Setter signatures
(setter_signature
  name: (identifier) @function)

; Import statements - capture the string path
(import_specification
  (configurable_uri
    (uri
      (string_literal) @import)))

; Also try library_import structure
(library_import
  (import_specification
    (configurable_uri
      (uri
        (string_literal) @import))))
</file>
<file path="scanner/queries/go.scm">
; Go query for extracting functions, types, and imports

; Function declarations with parameters
(function_declaration
  name: (identifier) @func.name
  parameters: (parameter_list) @func.params)

; Method declarations (functions with receivers)
(method_declaration
  receiver: (parameter_list) @func.receiver
  name: (field_identifier) @func.name
  parameters: (parameter_list) @func.params)

; Struct type definitions
(type_declaration
  (type_spec
    name: (type_identifier) @type.name
    type: (struct_type))) @type.struct

; Interface type definitions
(type_declaration
  (type_spec
    name: (type_identifier) @type.name
    type: (interface_type))) @type.interface

; Import paths
(import_spec
  path: (interpreted_string_literal) @import)
</file>
<file path="scanner/queries/java.scm">
; Java query for functions, types, and imports

; Method declarations with parameters
(method_declaration
  name: (identifier) @func.name
  parameters: (formal_parameters) @func.params)

; Constructor declarations
(constructor_declaration
  name: (identifier) @func.name
  parameters: (formal_parameters) @func.params)

; Class declarations
(class_declaration
  name: (identifier) @type.name) @type.class

; Interface declarations
(interface_declaration
  name: (identifier) @type.name) @type.interface

; Enum declarations
(enum_declaration
  name: (identifier) @type.name) @type.enum

; Import declarations
(import_declaration
  (scoped_identifier) @import)
</file>
<file path="scanner/queries/javascript.scm">
; JavaScript/JSX query for functions, classes, and imports

; Function declarations with parameters
(function_declaration
  name: (identifier) @func.name
  parameters: (formal_parameters) @func.params)

; Arrow functions assigned to variables
(variable_declarator
  name: (identifier) @func.name
  value: (arrow_function
    parameters: (formal_parameters) @func.params))

; Method definitions in classes/objects
(method_definition
  name: (property_identifier) @func.name
  parameters: (formal_parameters) @func.params)

; Class declarations
(class_declaration
  name: (identifier) @type.name) @type.class

; ES6 imports: import x from 'y'
(import_statement
  source: (string) @import)

; CommonJS: require('x')
(call_expression
  function: (identifier) @_req (#eq? @_req "require")
  arguments: (arguments (string) @import))
</file>
<file path="scanner/queries/kotlin.scm">
; Kotlin query for functions and imports

; Function declarations
(function_declaration
  (simple_identifier) @function)

; Import statements
(import_header
  (identifier) @import)
</file>
<file path="scanner/queries/php.scm">
; PHP query for functions and imports

; Function definitions
(function_definition
  name: (name) @function)

; Method declarations
(method_declaration
  name: (name) @function)

; Use statements (imports)
(namespace_use_clause
  (qualified_name) @import)

; Require/include statements
(include_expression
  (string) @import)

(include_once_expression
  (string) @import)

(require_expression
  (string) @import)

(require_once_expression
  (string) @import)
</file>
<file path="scanner/queries/python.scm">
; Python query for extracting functions, classes, and imports

; Function definitions with parameters
(function_definition
  name: (identifier) @func.name
  parameters: (parameters) @func.params)

; Class definitions
(class_definition
  name: (identifier) @type.name) @type.class

; import x, import x.y.z
(import_statement
  name: (dotted_name) @import)

; from x import y
(import_from_statement
  module_name: (dotted_name) @import)

; from x import y, z (the module part)
(import_from_statement
  module_name: (relative_import) @import)
</file>
<file path="scanner/queries/r.scm">
; R query for functions and imports

; Function definitions using <- assignment
(binary_operator
  lhs: (identifier) @function
  operator: "<-"
  rhs: (function_definition))

; Function definitions using = assignment
(binary_operator
  lhs: (identifier) @function
  operator: "="
  rhs: (function_definition))

; library() calls
(call
  function: (identifier) @_fn
  arguments: (arguments
    (argument
      value: (identifier) @import))
  (#eq? @_fn "library"))

; require() calls
(call
  function: (identifier) @_fn
  arguments: (arguments
    (argument
      value: (identifier) @import))
  (#eq? @_fn "require"))

; source() calls for file imports
(call
  function: (identifier) @_fn
  arguments: (arguments
    (argument
      value: (string) @import))
  (#eq? @_fn "source"))
</file>
<file path="scanner/queries/ruby.scm">
; Ruby query for functions and imports

; Method definitions
(method
  name: (identifier) @function)

; Singleton method definitions
(singleton_method
  name: (identifier) @function)

; require 'x'
(call
  method: (identifier) @_req (#match? @_req "^require")
  arguments: (argument_list (string) @import))

; require_relative 'x'
(call
  method: (identifier) @_req (#match? @_req "^require_relative")
  arguments: (argument_list (string) @import))
</file>
<file path="scanner/queries/rust.scm">
; Rust query for functions, types, and imports

; Function definitions with parameters
(function_item
  name: (identifier) @func.name
  parameters: (parameters) @func.params)

; Struct definitions
(struct_item
  name: (type_identifier) @type.name) @type.struct

; Enum definitions
(enum_item
  name: (type_identifier) @type.name) @type.enum

; Trait definitions
(trait_item
  name: (type_identifier) @type.name) @type.trait

; use statements
(use_declaration
  argument: (scoped_identifier) @import)

(use_declaration
  argument: (identifier) @import)

; mod declarations (internal modules)
(mod_item
  name: (identifier) @module)
</file>
<file path="scanner/queries/swift.scm">
; Swift query for functions and imports

; Function declarations - capture the name
(function_declaration
  name: (simple_identifier) @function)

; Init declarations - no name field, so we skip them
; (they show as "init" which isn't very useful)

; Import statements - capture the identifier
(import_declaration
  (identifier
    (simple_identifier) @import))
</file>
<file path="scanner/queries/typescript.scm">
; TypeScript/TSX query for functions, types, and imports

; Function declarations with parameters
(function_declaration
  name: (identifier) @func.name
  parameters: (formal_parameters) @func.params)

; Arrow functions assigned to variables
(variable_declarator
  name: (identifier) @func.name
  value: (arrow_function
    parameters: (formal_parameters) @func.params))

; Method definitions
(method_definition
  name: (property_identifier) @func.name
  parameters: (formal_parameters) @func.params)

; Interface declarations
(interface_declaration
  name: (type_identifier) @type.name) @type.interface

; Class declarations
(class_declaration
  name: (type_identifier) @type.name) @type.class

; Type aliases
(type_alias_declaration
  name: (type_identifier) @type.name) @type.alias

; Enum declarations
(enum_declaration
  name: (identifier) @type.name) @type.enum

; ES6 imports
(import_statement
  source: (string) @import)
</file>
<file path="scanner/build-grammars.sh">
#!/usr/bin/env bash
set -e

# Build tree-sitter grammar shared libraries for codemap --deps mode
# Requires: git, cc (clang/gcc)

SCRIPT_DIR="$(cd "$(dirname "$0")" && pwd)"
GRAMMAR_DIR="$SCRIPT_DIR/grammars"
BUILD_DIR="$SCRIPT_DIR/.grammar-build"

# Detect OS for library extension
if [[ "$OSTYPE" == "darwin"* ]]; then
    LIB_EXT=".dylib"
    CC_FLAGS="-dynamiclib"
elif [[ "$OSTYPE" == "msys"* ]] || [[ "$OSTYPE" == "cygwin"* ]]; then
    LIB_EXT=".dll"
    CC_FLAGS="-shared"
else
    LIB_EXT=".so"
    CC_FLAGS="-shared -fPIC"
fi

mkdir -p "$GRAMMAR_DIR"
mkdir -p "$BUILD_DIR"

build_grammar() {
    local lang=$1
    local repo=$2
    local src_subdir=${3:-src}
    local output="$GRAMMAR_DIR/libtree-sitter-${lang}${LIB_EXT}"

    if [[ -f "$output" ]]; then
        echo "✓ $lang (already built)"
        return 0
    fi

    echo "Building $lang..."

    local clone_dir="$BUILD_DIR/tree-sitter-$lang"

    # Clone if needed
    if [[ ! -d "$clone_dir" ]]; then
        git clone --depth 1 "$repo" "$clone_dir" 2>/dev/null || {
            echo "✗ $lang (clone failed)"
            return 1
        }
    fi

    local src_dir="$clone_dir/$src_subdir"

    # Compile parser.c (and scanner.c if exists)
    local sources="$src_dir/parser.c"
    if [[ -f "$src_dir/scanner.c" ]]; then
        sources="$sources $src_dir/scanner.c"
    elif [[ -f "$src_dir/scanner.cc" ]]; then
        # C++ scanner
        c++ -c -fPIC "$src_dir/scanner.cc" -o "$BUILD_DIR/scanner_${lang}.o" -I "$src_dir" 2>/dev/null || {
            echo "✗ $lang (c++ compile failed)"
            return 1
        }
        cc $CC_FLAGS -o "$output" $sources "$BUILD_DIR/scanner_${lang}.o" -I "$src_dir" 2>/dev/null || {
            echo "✗ $lang (link failed)"
            return 1
        }
        echo "✓ $lang"
        return 0
    fi

    cc $CC_FLAGS -o "$output" $sources -I "$src_dir" 2>/dev/null || {
        echo "✗ $lang (compile failed)"
        return 1
    }
    echo "✓ $lang"
}

echo "Building tree-sitter grammars..."
echo "Output: $GRAMMAR_DIR"
echo ""

# Build each grammar (lang, repo, src_subdir)
build_grammar "go" "https://github.com/tree-sitter/tree-sitter-go" "src"
build_grammar "python" "https://github.com/tree-sitter/tree-sitter-python" "src"
build_grammar "javascript" "https://github.com/tree-sitter/tree-sitter-javascript" "src"
build_grammar "typescript" "https://github.com/tree-sitter/tree-sitter-typescript" "typescript/src"
build_grammar "rust" "https://github.com/tree-sitter/tree-sitter-rust" "src"
build_grammar "ruby" "https://github.com/tree-sitter/tree-sitter-ruby" "src"
build_grammar "c" "https://github.com/tree-sitter/tree-sitter-c" "src"
build_grammar "cpp" "https://github.com/tree-sitter/tree-sitter-cpp" "src"
build_grammar "java" "https://github.com/tree-sitter/tree-sitter-java" "src"
build_grammar "swift" "https://github.com/tree-sitter/tree-sitter-swift" "src"
build_grammar "bash" "https://github.com/tree-sitter/tree-sitter-bash" "src"
build_grammar "kotlin" "https://github.com/fwcd/tree-sitter-kotlin" "src"
build_grammar "c_sharp" "https://github.com/tree-sitter/tree-sitter-c-sharp" "src"
build_grammar "php" "https://github.com/tree-sitter/tree-sitter-php" "php/src"
build_grammar "dart" "https://github.com/UserNobody14/tree-sitter-dart" "src"
build_grammar "r" "https://github.com/r-lib/tree-sitter-r" "src"

echo ""
echo "Done. Built grammars:"
ls -1 "$GRAMMAR_DIR"/*.dylib "$GRAMMAR_DIR"/*.so "$GRAMMAR_DIR"/*.dll 2>/dev/null || echo "(none)"
</file>
<file path="scanner/deps.go">
package scanner

import (
	"os"
	"path/filepath"
	"strings"
)

// ReadExternalDeps reads manifest files (go.mod, requirements.txt, package.json)
func ReadExternalDeps(root string) map[string][]string {
	deps := make(map[string][]string)

	// Walk tree to find all manifest files
	filepath.Walk(root, func(path string, info os.FileInfo, _ error) error {
		if info == nil {
			return nil
		}
		if info.IsDir() {
			if IgnoredDirs[info.Name()] {
				return filepath.SkipDir
			}
			return nil
		}
		switch info.Name() {
		case "go.mod":
			if c, err := os.ReadFile(path); err == nil {
				deps["go"] = append(deps["go"], parseGoMod(string(c))...)
			}
		case "requirements.txt":
			if c, err := os.ReadFile(path); err == nil {
				deps["python"] = append(deps["python"], parseRequirements(string(c))...)
			}
		case "package.json":
			if c, err := os.ReadFile(path); err == nil {
				deps["javascript"] = append(deps["javascript"], parsePackageJson(string(c))...)
			}
		case "Podfile":
			if c, err := os.ReadFile(path); err == nil {
				deps["swift"] = append(deps["swift"], parsePodfile(string(c))...)
			}
		case "Package.swift":
			if c, err := os.ReadFile(path); err == nil {
				deps["swift"] = append(deps["swift"], parsePackageSwift(string(c))...)
			}
		}
		return nil
	})

	for k, v := range deps {
		deps[k] = dedupe(v)
	}
	return deps
}

func parseGoMod(c string) (deps []string) {
	inReq := false
	for _, line := range strings.Split(c, "\n") {
		line = strings.TrimSpace(line)
		if strings.HasPrefix(line, "require (") {
			inReq = true
		} else if inReq && line == ")" {
			inReq = false
		} else if inReq && line != "" && !strings.HasPrefix(line, "//") {
			if parts := strings.Fields(line); len(parts) >= 1 {
				deps = append(deps, parts[0])
			}
		}
	}
	return
}

func parseRequirements(c string) (deps []string) {
	for _, line := range strings.Split(c, "\n") {
		line = strings.TrimSpace(line)
		if line == "" || strings.HasPrefix(line, "#") {
			continue
		}
		for _, sep := range []string{"==", ">=", "<=", "~=", "<", ">", "[", ";", "#"} {
			if i := strings.Index(line, sep); i != -1 {
				line = line[:i]
			}
		}
		if line != "" {
			deps = append(deps, line)
		}
	}
	return
}

func parsePackageJson(c string) (deps []string) {
	inDeps := false
	for _, line := range strings.Split(c, "\n") {
		if strings.Contains(line, `"dependencies"`) || strings.Contains(line, `"devDependencies"`) {
			inDeps = true
		} else if inDeps && strings.Contains(line, "}") {
			inDeps = false
		} else if inDeps && strings.Contains(line, ":") {
			parts := strings.SplitN(line, ":", 2)
			name := strings.Trim(strings.TrimSpace(parts[0]), `"`)
			if name != "" {
				deps = append(deps, name)
			}
		}
	}
	return
}

func parsePodfile(c string) (deps []string) {
	// Parse Podfile: pod 'Name' or pod 'Name', '~> 1.0'
	for _, line := range strings.Split(c, "\n") {
		line = strings.TrimSpace(line)
		if strings.HasPrefix(line, "pod ") {
			// Extract pod name from: pod 'Name' or pod 'Name', ...
			line = strings.TrimPrefix(line, "pod ")
			line = strings.Trim(line, "'\"")
			if i := strings.Index(line, "'"); i != -1 {
				line = line[:i]
			}
			if i := strings.Index(line, "\""); i != -1 {
				line = line[:i]
			}
			if i := strings.Index(line, ","); i != -1 {
				line = line[:i]
			}
			line = strings.Trim(line, "'\" ")
			if line != "" {
				deps = append(deps, line)
			}
		}
	}
	return
}

func parsePackageSwift(c string) (deps []string) {
	// Parse Package.swift: .package(url: "...", ...) or .package(name: "Name", ...)
	// Look for package names in .product(name: "Name", package: "Package")
	for _, line := range strings.Split(c, "\n") {
		// Match .package(url: "https://github.com/user/repo", ...)
		if strings.Contains(line, ".package(") && strings.Contains(line, "url:") {
			// Extract repo name from URL
			if i := strings.Index(line, "url:"); i != -1 {
				rest := line[i+4:]
				rest = strings.Trim(rest, " \"'")
				if j := strings.Index(rest, "\""); j != -1 {
					url := rest[:j]
					// Get repo name from URL
					parts := strings.Split(url, "/")
					if len(parts) > 0 {
						name := parts[len(parts)-1]
						name = strings.TrimSuffix(name, ".git")
						if name != "" {
							deps = append(deps, name)
						}
					}
				}
			}
		}
	}
	return
}
</file>
<file path="scanner/git.go">
package scanner

import (
	"fmt"
	"os"
	"os/exec"
	"path/filepath"
	"sort"
	"strings"
)

// DiffInfo holds all diff-related data for changed files
type DiffInfo struct {
	Changed   map[string]bool     // all changed files (modified + untracked)
	Untracked map[string]bool     // new/untracked files only
	Stats     map[string]DiffStat // +/- line counts
}

// GitDiffInfo returns comprehensive diff information for the repo
func GitDiffInfo(root, ref string) (*DiffInfo, error) {
	info := &DiffInfo{
		Changed:   make(map[string]bool),
		Untracked: make(map[string]bool),
		Stats:     make(map[string]DiffStat),
	}

	// Get modified files vs ref with stats
	cmd := exec.Command("git", "diff", "--numstat", ref)
	cmd.Dir = root
	output, err := cmd.Output()
	if err != nil {
		return nil, err
	}

	for _, line := range strings.Split(strings.TrimSpace(string(output)), "\n") {
		if line == "" {
			continue
		}
		parts := strings.Fields(line)
		if len(parts) >= 3 {
			var added, removed int
			if parts[0] != "-" {
				fmt.Sscanf(parts[0], "%d", &added)
			}
			if parts[1] != "-" {
				fmt.Sscanf(parts[1], "%d", &removed)
			}
			filename := strings.Join(parts[2:], " ")
			info.Changed[filename] = true
			info.Stats[filename] = DiffStat{Added: added, Removed: removed}
		}
	}

	// Get untracked files (new files)
	cmd2 := exec.Command("git", "ls-files", "--others", "--exclude-standard")
	cmd2.Dir = root
	output2, _ := cmd2.Output()
	for _, line := range strings.Split(strings.TrimSpace(string(output2)), "\n") {
		if line != "" {
			info.Changed[line] = true
			info.Untracked[line] = true
		}
	}

	return info, nil
}

// GitDiffFiles returns files changed between current HEAD and the given branch/ref
// Also includes untracked files (new files not yet committed)
func GitDiffFiles(root, ref string) (map[string]bool, error) {
	info, err := GitDiffInfo(root, ref)
	if err != nil {
		return nil, err
	}
	return info.Changed, nil
}

// GitDiffStats returns +/- line counts for changed files
type DiffStat struct {
	Added   int
	Removed int
}

func GitDiffStats(root, ref string) (map[string]DiffStat, error) {
	cmd := exec.Command("git", "diff", "--numstat", ref)
	cmd.Dir = root
	output, err := cmd.Output()
	if err != nil {
		return nil, err
	}

	stats := make(map[string]DiffStat)
	for _, line := range strings.Split(strings.TrimSpace(string(output)), "\n") {
		if line == "" {
			continue
		}
		parts := strings.Fields(line)
		if len(parts) >= 3 {
			var added, removed int
			if parts[0] != "-" {
				fmt.Sscanf(parts[0], "%d", &added)
			}
			if parts[1] != "-" {
				fmt.Sscanf(parts[1], "%d", &removed)
			}
			// parts[2] is the filename, but could have spaces - rejoin
			filename := strings.Join(parts[2:], " ")
			stats[filename] = DiffStat{Added: added, Removed: removed}
		}
	}
	return stats, nil
}

// FilterToChanged filters a slice of FileInfo to only include changed files
func FilterToChanged(files []FileInfo, changed map[string]bool) []FileInfo {
	var result []FileInfo
	for _, f := range files {
		if changed[f.Path] || changed[filepath.ToSlash(f.Path)] {
			result = append(result, f)
		}
	}
	return result
}

// FilterToChangedWithInfo filters and annotates files with diff info
func FilterToChangedWithInfo(files []FileInfo, info *DiffInfo) []FileInfo {
	var result []FileInfo
	for _, f := range files {
		path := f.Path
		slashPath := filepath.ToSlash(f.Path)
		if info.Changed[path] || info.Changed[slashPath] {
			// Annotate with diff info
			f.IsNew = info.Untracked[path] || info.Untracked[slashPath]
			if stat, ok := info.Stats[path]; ok {
				f.Added = stat.Added
				f.Removed = stat.Removed
			} else if stat, ok := info.Stats[slashPath]; ok {
				f.Added = stat.Added
				f.Removed = stat.Removed
			}
			result = append(result, f)
		}
	}
	return result
}

// FilterAnalysisToChanged filters FileAnalysis slice to only changed files
func FilterAnalysisToChanged(files []FileAnalysis, changed map[string]bool) []FileAnalysis {
	var result []FileAnalysis
	for _, f := range files {
		if changed[f.Path] || changed[filepath.ToSlash(f.Path)] {
			result = append(result, f)
		}
	}
	return result
}

// ImpactInfo describes which changed files are used by other files
type ImpactInfo struct {
	File   string // the file that changed
	UsedBy int    // number of other files that import/use this file
}

// AnalyzeImpact checks which changed files are imported by other files
// Uses tree-sitter to extract actual imports for accuracy
func AnalyzeImpact(root string, changedFiles []FileInfo) []ImpactInfo {
	if len(changedFiles) == 0 {
		return nil
	}

	// Build set of changed file base names and directories
	changedBases := make(map[string]string) // base name -> full path
	changedDirs := make(map[string]string)  // dir name -> representative file
	for _, f := range changedFiles {
		base := strings.TrimSuffix(filepath.Base(f.Path), filepath.Ext(f.Path))
		changedBases[base] = f.Path

		// Also track directories for Go-style package imports
		dir := filepath.Dir(f.Path)
		if dir != "." && dir != "" {
			dirBase := filepath.Base(dir)
			if _, exists := changedDirs[dirBase]; !exists {
				changedDirs[dirBase] = f.Path
			}
		}
	}

	// Scan all files to get their imports using tree-sitter
	loader := NewGrammarLoader()
	usageCounts := make(map[string]int)

	filepath.Walk(root, func(path string, info os.FileInfo, err error) error {
		if err != nil {
			return nil
		}

		// Skip ignored directories
		if info.IsDir() {
			if IgnoredDirs[info.Name()] {
				return filepath.SkipDir
			}
			return nil
		}

		// Analyze file imports (only need basic info for impact analysis)
		analysis, err := loader.AnalyzeFile(path, DetailNone)
		if err != nil || analysis == nil {
			return nil
		}

		relPath, _ := filepath.Rel(root, path)

		// Check each import to see if it references a changed file
		for _, imp := range analysis.Imports {
			// Extract the last component of the import path
			// e.g., "./components/Header" -> "Header"
			// e.g., "codemap/scanner" -> "scanner"
			impBase := filepath.Base(imp)
			impBase = strings.TrimSuffix(impBase, filepath.Ext(impBase))

			// Check if this import matches a changed file (by filename)
			if changedPath, ok := changedBases[impBase]; ok {
				if relPath != changedPath {
					usageCounts[changedPath]++
				}
			}

			// Also check if import matches a changed directory (Go packages)
			if changedPath, ok := changedDirs[impBase]; ok {
				changedDir := filepath.Dir(changedPath)
				// Don't count imports from same directory
				if filepath.Dir(relPath) != changedDir {
					usageCounts[changedDir+"/"]++
				}
			}
		}
		return nil
	})

	// Build impact info
	var impacts []ImpactInfo
	for file, count := range usageCounts {
		if count > 0 {
			impacts = append(impacts, ImpactInfo{
				File:   filepath.Base(file),
				UsedBy: count,
			})
		}
	}

	// Sort by usage count descending
	sort.Slice(impacts, func(i, j int) bool {
		return impacts[i].UsedBy > impacts[j].UsedBy
	})

	return impacts
}
</file>
<file path="scanner/grammar.go">
package scanner

import (
	"embed"
	"fmt"
	"os"
	"path/filepath"
	"runtime"
	"strings"

	tree_sitter "github.com/tree-sitter/go-tree-sitter"
)

//go:embed queries/*.scm
var queryFiles embed.FS

// LanguageConfig holds dynamically loaded parser and query
type LanguageConfig struct {
	Language *tree_sitter.Language
	Query    *tree_sitter.Query
}

// GrammarLoader handles dynamic loading of tree-sitter grammars
type GrammarLoader struct {
	configs    map[string]*LanguageConfig
	grammarDir string
}

// LangInfo holds display names for a language
type LangInfo struct {
	Short string // Compact label: "JS", "Py"
	Full  string // Full name: "JavaScript", "Python"
}

// LangDisplay maps internal language names to display names
var LangDisplay = map[string]LangInfo{
	"go":         {"Go", "Go"},
	"python":     {"Py", "Python"},
	"javascript": {"JS", "JavaScript"},
	"typescript": {"TS", "TypeScript"},
	"rust":       {"Rs", "Rust"},
	"ruby":       {"Rb", "Ruby"},
	"c":          {"C", "C"},
	"cpp":        {"C++", "C++"},
	"java":       {"Java", "Java"},
	"swift":      {"Swift", "Swift"},
	"bash":       {"Sh", "Bash"},
	"kotlin":     {"Kt", "Kotlin"},
	"c_sharp":    {"C#", "C#"},
	"php":        {"PHP", "PHP"},
	"dart":       {"Dart", "Dart"},
	"r":          {"R", "R"},
}

// Extension to language mapping
var extToLang = map[string]string{
	".go":    "go",
	".py":    "python",
	".js":    "javascript",
	".jsx":   "javascript",
	".mjs":   "javascript",
	".ts":    "typescript",
	".tsx":   "typescript",
	".rs":    "rust",
	".rb":    "ruby",
	".c":     "c",
	".h":     "c",
	".cpp":   "cpp",
	".hpp":   "cpp",
	".cc":    "cpp",
	".java":  "java",
	".swift": "swift",
	".sh":    "bash",
	".bash":  "bash",
	".kt":    "kotlin",
	".kts":   "kotlin",
	".cs":    "c_sharp",
	".php":   "php",
	".dart":  "dart",
	".r":     "r",
	".R":     "r",
}

// NewGrammarLoader creates a loader that searches for grammars
func NewGrammarLoader() *GrammarLoader {
	loader := &GrammarLoader{
		configs: make(map[string]*LanguageConfig),
	}

	// Find grammar directory - check env var first (for Homebrew install)
	possibleDirs := []string{}
	if envDir := os.Getenv("CODEMAP_GRAMMAR_DIR"); envDir != "" {
		possibleDirs = append(possibleDirs, envDir)
	}
	possibleDirs = append(possibleDirs,
		filepath.Join(getExecutableDir(), "grammars"),
		filepath.Join(getExecutableDir(), "..", "lib", "grammars"),
		"/opt/homebrew/opt/codemap/libexec/grammars", // Homebrew Apple Silicon
		"/usr/local/opt/codemap/libexec/grammars",    // Homebrew Intel Mac
		"/usr/local/lib/codemap/grammars",
		filepath.Join(os.Getenv("HOME"), ".codemap", "grammars"),
		"./grammars",         // For development
		"./scanner/grammars", // For development from root
	)

	for _, dir := range possibleDirs {
		if info, err := os.Stat(dir); err == nil && info.IsDir() {
			loader.grammarDir = dir
			break
		}
	}

	return loader
}

// HasGrammars returns true if grammar directory was found
func (l *GrammarLoader) HasGrammars() bool {
	return l.grammarDir != ""
}

// GrammarDir returns the grammar directory path (for diagnostics)
func (l *GrammarLoader) GrammarDir() string {
	return l.grammarDir
}

// LoadLanguage dynamically loads a grammar from .so/.dylib
func (l *GrammarLoader) LoadLanguage(lang string) error {
	if _, exists := l.configs[lang]; exists {
		return nil // Already loaded
	}

	if l.grammarDir == "" {
		return fmt.Errorf("no grammar directory found")
	}

	// OS-specific library extension
	var libExt string
	switch runtime.GOOS {
	case "darwin":
		libExt = ".dylib"
	case "windows":
		libExt = ".dll"
	default:
		libExt = ".so"
	}

	// Load shared library
	libPath := filepath.Join(l.grammarDir, fmt.Sprintf("libtree-sitter-%s%s", lang, libExt))
	lib, err := loadLibrary(libPath)
	if err != nil {
		return fmt.Errorf("load %s: %w", libPath, err)
	}

	// Get language function
	langFunc, err := getLanguageFunc(lib, lang)
	if err != nil {
		return fmt.Errorf("get func for %s: %w", lang, err)
	}
	language := tree_sitter.NewLanguage(langFunc())

	// Load query
	queryBytes, err := queryFiles.ReadFile(fmt.Sprintf("queries/%s.scm", lang))
	if err != nil {
		return fmt.Errorf("no query for %s", lang)
	}

	query, qerr := tree_sitter.NewQuery(language, string(queryBytes))
	if qerr != nil {
		return fmt.Errorf("bad query for %s: %v", lang, qerr)
	}

	l.configs[lang] = &LanguageConfig{Language: language, Query: query}
	return nil
}

// DetectLanguage returns the language name for a file path
func DetectLanguage(filePath string) string {
	ext := strings.ToLower(filepath.Ext(filePath))
	return extToLang[ext]
}

// AnalyzeFile extracts functions and imports
// detailLevel controls depth of extraction (0=names, 1=signatures, 2=full)
func (l *GrammarLoader) AnalyzeFile(filePath string, detailLevel DetailLevel) (*FileAnalysis, error) {
	lang := DetectLanguage(filePath)
	if lang == "" {
		return nil, nil
	}

	if err := l.LoadLanguage(lang); err != nil {
		return nil, nil // Skip if grammar unavailable
	}

	config := l.configs[lang]
	content, err := os.ReadFile(filePath)
	if err != nil {
		return nil, err
	}

	parser := tree_sitter.NewParser()
	defer parser.Close()
	parser.SetLanguage(config.Language)

	tree := parser.Parse(content, nil)
	defer tree.Close()

	cursor := tree_sitter.NewQueryCursor()
	defer cursor.Close()

	analysis := &FileAnalysis{Path: filePath, Language: lang}

	// Temporary storage for building composite captures
	funcBuilder := make(map[uint]*funcCapture)
	typeBuilder := make(map[uint]*typeCapture)

	// Use Matches() API - iterate over query matches
	matches := cursor.Matches(config.Query, tree.RootNode(), content)
	for match := matches.Next(); match != nil; match = matches.Next() {
		for _, capture := range match.Captures {
			captureName := config.Query.CaptureNames()[capture.Index]
			text := strings.Trim(capture.Node.Utf8Text(content), `"'`)
			// Extract line number (1-indexed)
			line := int(capture.Node.StartPosition().Row) + 1

			// Route to appropriate handler based on capture name prefix
			switch {
			case strings.HasPrefix(captureName, "func."):
				handleFuncCapture(funcBuilder, match.Id(), captureName, text, line)
			case strings.HasPrefix(captureName, "type."):
				handleTypeCapture(typeBuilder, match.Id(), captureName, text, line, detailLevel)
			case captureName == "import" || captureName == "module":
				analysis.Imports = append(analysis.Imports, text)
			// Legacy support: plain @function/@method capture (current queries)
			case captureName == "function" || captureName == "method":
				analysis.Functions = append(analysis.Functions, FuncInfo{Name: text, Line: line})
			}
		}
	}

	// Build final function list from captured components
	for _, fc := range funcBuilder {
		funcInfo := fc.Build(detailLevel, lang)
		analysis.Functions = append(analysis.Functions, funcInfo)
	}

	// Build final type list
	for _, tc := range typeBuilder {
		typeInfo := tc.Build(detailLevel, lang)
		analysis.Types = append(analysis.Types, typeInfo)
	}

	analysis.Functions = dedupeFuncs(analysis.Functions)
	analysis.Types = dedupeTypes(analysis.Types)
	analysis.Imports = dedupe(analysis.Imports)
	return analysis, nil
}

// funcCapture collects components of a function signature
type funcCapture struct {
	name     string
	params   string
	result   string
	receiver string
	line     int
}

// Build constructs FuncInfo from captured components
func (fc *funcCapture) Build(detail DetailLevel, lang string) FuncInfo {
	info := FuncInfo{
		Name:       fc.name,
		IsExported: IsExportedName(fc.name, lang),
		Line:       fc.line,
	}

	if detail >= DetailSignature && fc.params != "" {
		info.Signature = buildSignature(fc, lang)
	}

	if fc.receiver != "" {
		info.Receiver = fc.receiver
	}

	return info
}

// handleFuncCapture routes function-related captures to builder
func handleFuncCapture(builders map[uint]*funcCapture, matchID uint, name, text string, line int) {
	if builders[matchID] == nil {
		builders[matchID] = &funcCapture{}
	}
	fc := builders[matchID]

	switch name {
	case "func.name":
		fc.name = text
		fc.line = line // Capture line on name (primary identifier)
	case "func.params":
		fc.params = text
	case "func.result":
		fc.result = text
	case "func.receiver":
		fc.receiver = text
	}
}

// typeCapture collects components of a type definition
type typeCapture struct {
	name   string
	kind   TypeKind
	fields string
	line   int
}

// Build constructs TypeInfo from captured components
func (tc *typeCapture) Build(detail DetailLevel, lang string) TypeInfo {
	info := TypeInfo{
		Name:       tc.name,
		Kind:       tc.kind,
		IsExported: IsExportedName(tc.name, lang),
		Line:       tc.line,
	}

	if detail >= DetailFull && tc.fields != "" {
		info.Fields = parseFieldNames(tc.fields)
	}

	return info
}

// handleTypeCapture routes type-related captures to builder
func handleTypeCapture(builders map[uint]*typeCapture, matchID uint, name, text string, line int, detail DetailLevel) {
	if builders[matchID] == nil {
		builders[matchID] = &typeCapture{}
	}
	tc := builders[matchID]

	switch name {
	case "type.name":
		tc.name = text
		tc.line = line // Capture line on name (primary identifier)
	case "type.fields", "type.methods":
		if detail >= DetailFull {
			tc.fields = text
		}
	case "type.struct":
		tc.kind = KindStruct
	case "type.class":
		tc.kind = KindClass
	case "type.interface":
		tc.kind = KindInterface
	case "type.trait":
		tc.kind = KindTrait
	case "type.enum":
		tc.kind = KindEnum
	case "type.alias":
		tc.kind = KindTypeAlias
	case "type.protocol":
		tc.kind = KindProtocol
	}
}

// buildSignature reconstructs function signature from components
func buildSignature(fc *funcCapture, lang string) string {
	var sig strings.Builder

	switch lang {
	case "go":
		sig.WriteString("func ")
		if fc.receiver != "" {
			sig.WriteString(fc.receiver)
			sig.WriteString(" ")
		}
		sig.WriteString(fc.name)
		sig.WriteString(fc.params)
		if fc.result != "" {
			sig.WriteString(" ")
			sig.WriteString(fc.result)
		}

	case "python":
		sig.WriteString("def ")
		sig.WriteString(fc.name)
		sig.WriteString(fc.params)
		if fc.result != "" {
			sig.WriteString(" -> ")
			sig.WriteString(fc.result)
		}

	case "typescript", "javascript":
		sig.WriteString("function ")
		sig.WriteString(fc.name)
		sig.WriteString(fc.params)
		if fc.result != "" {
			sig.WriteString(": ")
			sig.WriteString(fc.result)
		}

	case "rust":
		sig.WriteString("fn ")
		sig.WriteString(fc.name)
		sig.WriteString(fc.params)
		if fc.result != "" {
			sig.WriteString(" -> ")
			sig.WriteString(fc.result)
		}

	case "java", "c_sharp":
		if fc.result != "" {
			sig.WriteString(fc.result)
			sig.WriteString(" ")
		}
		sig.WriteString(fc.name)
		sig.WriteString(fc.params)

	default:
		sig.WriteString(fc.name)
		sig.WriteString(fc.params)
	}

	return sig.String()
}

// parseFieldNames extracts field/member names from raw block text
func parseFieldNames(fieldsText string) []string {
	var fields []string
	lines := strings.Split(fieldsText, "\n")

	for _, line := range lines {
		line = strings.TrimSpace(line)
		if line == "" || line == "{" || line == "}" {
			continue
		}

		// Extract first identifier (field name)
		parts := strings.Fields(line)
		if len(parts) > 0 {
			name := strings.TrimSuffix(parts[0], ":")
			name = strings.TrimSuffix(name, ",")
			if name != "" && !strings.HasPrefix(name, "//") && !strings.HasPrefix(name, "#") {
				fields = append(fields, name)
			}
		}
	}

	return fields
}

// dedupeFuncs removes duplicate functions by name
func dedupeFuncs(funcs []FuncInfo) []FuncInfo {
	seen := make(map[string]bool)
	var out []FuncInfo
	for _, f := range funcs {
		if !seen[f.Name] {
			seen[f.Name] = true
			out = append(out, f)
		}
	}
	return out
}

// dedupeTypes removes duplicate types by name
func dedupeTypes(types []TypeInfo) []TypeInfo {
	seen := make(map[string]bool)
	var out []TypeInfo
	for _, t := range types {
		if !seen[t.Name] {
			seen[t.Name] = true
			out = append(out, t)
		}
	}
	return out
}

func getExecutableDir() string {
	if exe, err := os.Executable(); err == nil {
		return filepath.Dir(exe)
	}
	return "."
}

func dedupe(s []string) []string {
	seen := make(map[string]bool)
	var out []string
	for _, v := range s {
		if !seen[v] {
			seen[v] = true
			out = append(out, v)
		}
	}
	return out
}
</file>
<file path="scanner/grammar_unix.go">
//go:build !windows

package scanner

import (
	"fmt"
	"unsafe"

	"github.com/ebitengine/purego"
)

// loadLibrary loads a shared library on Unix systems
func loadLibrary(path string) (uintptr, error) {
	lib, err := purego.Dlopen(path, purego.RTLD_NOW|purego.RTLD_GLOBAL)
	if err != nil {
		return 0, err
	}
	return lib, nil
}

// getLanguageFunc gets the tree_sitter_<lang> function from the library
func getLanguageFunc(lib uintptr, lang string) (func() unsafe.Pointer, error) {
	var langFunc func() unsafe.Pointer
	purego.RegisterLibFunc(&langFunc, lib, fmt.Sprintf("tree_sitter_%s", lang))
	return langFunc, nil
}
</file>
<file path="scanner/grammar_windows.go">
//go:build windows

package scanner

import (
	"fmt"
	"syscall"
	"unsafe"
)

// loadLibrary loads a DLL on Windows
func loadLibrary(path string) (uintptr, error) {
	handle, err := syscall.LoadLibrary(path)
	if err != nil {
		return 0, err
	}
	return uintptr(handle), nil
}

// getLanguageFunc gets the tree_sitter_<lang> function from the DLL
func getLanguageFunc(lib uintptr, lang string) (func() unsafe.Pointer, error) {
	procName := fmt.Sprintf("tree_sitter_%s", lang)
	proc, err := syscall.GetProcAddress(syscall.Handle(lib), procName)
	if err != nil {
		return nil, fmt.Errorf("GetProcAddress %s: %w", procName, err)
	}

	// Create a wrapper function that calls the proc
	fn := func() unsafe.Pointer {
		ret, _, _ := syscall.SyscallN(proc)
		return unsafe.Pointer(ret)
	}
	return fn, nil
}
</file>
<file path="scanner/symbol.go">
package scanner

import (
	"strings"
)

// SymbolQuery represents the filters for symbol search
type SymbolQuery struct {
	Name string // Substring match (case-insensitive)
	Kind string // "function", "type", "all"
	File string // Filter by specific file (optional)
}

// SymbolMatch represents a found symbol
type SymbolMatch struct {
	Name      string `json:"name"`
	Kind      string `json:"kind"`      // "function" or "type"
	Signature string `json:"signature"` // For functions
	TypeKind  string `json:"type_kind"` // For types (struct, class, etc.)
	File      string `json:"file"`
	Line      int    `json:"line"`
	Exported  bool   `json:"exported"`
}

// SearchSymbols searches for symbols in the analyzed files
func SearchSymbols(analyses []FileAnalysis, query SymbolQuery) []SymbolMatch {
	var matches []SymbolMatch
	searchName := strings.ToLower(query.Name)

	for _, analysis := range analyses {
		// Skip if file filter is set and doesn't match
		if query.File != "" && !strings.Contains(analysis.Path, query.File) {
			continue
		}

		// Search functions
		if query.Kind == "" || query.Kind == "all" || query.Kind == "function" {
			for _, fn := range analysis.Functions {
				if searchName == "" || strings.Contains(strings.ToLower(fn.Name), searchName) {
					matches = append(matches, SymbolMatch{
						Name:      fn.Name,
						Kind:      "function",
						Signature: fn.Signature,
						File:      analysis.Path,
						Line:      fn.Line,
						Exported:  fn.IsExported,
					})
				}
			}
		}

		// Search types
		if query.Kind == "" || query.Kind == "all" || query.Kind == "type" {
			for _, t := range analysis.Types {
				if searchName == "" || strings.Contains(strings.ToLower(t.Name), searchName) {
					matches = append(matches, SymbolMatch{
						Name:     t.Name,
						Kind:     "type",
						TypeKind: string(t.Kind),
						File:     analysis.Path,
						Line:     t.Line,
						Exported: t.IsExported,
					})
				}
			}
		}
	}

	return matches
}
</file>
<file path="scanner/types.go">
package scanner

import (
	"encoding/json"
	"strings"
	"unicode"
)

// DetailLevel controls how much information is extracted
type DetailLevel int

const (
	DetailNone      DetailLevel = 0 // Only names (current behavior)
	DetailSignature DetailLevel = 1 // Names + signatures
	DetailFull      DetailLevel = 2 // Signatures + type fields
)

// Token estimation constants
const (
	CharsPerToken   = 3.5  // Conservative estimate for BPE tokenizers
	LargeFileTokens = 8000 // Threshold for warning indicator
)

// EstimateTokens estimates the number of tokens for a given file size
func EstimateTokens(size int64) int {
	return int(float64(size) / CharsPerToken)
}

// FileInfo represents a single file in the codebase.
type FileInfo struct {
	Path    string `json:"path"`
	Size    int64  `json:"size"`
	Ext     string `json:"ext"`
	Tokens  int    `json:"tokens,omitempty"` // Estimated token count
	IsNew   bool   `json:"is_new,omitempty"`
	Added   int    `json:"added,omitempty"`
	Removed int    `json:"removed,omitempty"`
}

// Project represents the root of the codebase for tree/skyline mode.
type Project struct {
	Root    string       `json:"root"`
	Mode    string       `json:"mode"`
	Animate bool         `json:"animate"`
	Files   []FileInfo   `json:"files"`
	DiffRef string       `json:"diff_ref,omitempty"`
	Impact  []ImpactInfo `json:"impact,omitempty"`
}

// FuncInfo represents a function/method with optional detail
type FuncInfo struct {
	Name       string `json:"name"`
	Signature  string `json:"signature,omitempty"` // Full signature when detail >= 1
	Receiver   string `json:"receiver,omitempty"`  // For methods (Go, Rust, etc.)
	IsExported bool   `json:"exported,omitempty"`  // Public visibility
	Line       int    `json:"line,omitempty"`      // Line number of definition (1-indexed)
}

// MarshalJSON customizes JSON output for backward compatibility
// When no extended info is present, serialize as plain string
func (f FuncInfo) MarshalJSON() ([]byte, error) {
	if f.Signature == "" && f.Receiver == "" && !f.IsExported && f.Line == 0 {
		return json.Marshal(f.Name)
	}
	type Alias FuncInfo
	return json.Marshal(Alias(f))
}

// UnmarshalJSON handles both string and object formats
func (f *FuncInfo) UnmarshalJSON(data []byte) error {
	// Try string first
	var name string
	if err := json.Unmarshal(data, &name); err == nil {
		f.Name = name
		return nil
	}
	// Fall back to object
	type Alias FuncInfo
	var alias Alias
	if err := json.Unmarshal(data, &alias); err != nil {
		return err
	}
	*f = FuncInfo(alias)
	return nil
}

// TypeKind represents normalized type categories across languages
type TypeKind string

const (
	KindStruct    TypeKind = "struct"    // Go struct, C struct, Rust struct
	KindClass     TypeKind = "class"     // Python/Java/C#/TS class
	KindInterface TypeKind = "interface" // Go interface, Java/C#/TS interface
	KindTrait     TypeKind = "trait"     // Rust trait
	KindEnum      TypeKind = "enum"      // All languages
	KindTypeAlias TypeKind = "alias"     // Go type alias, TS type
	KindProtocol  TypeKind = "protocol"  // Swift protocol
)

// TypeInfo represents a type definition
type TypeInfo struct {
	Name       string   `json:"name"`
	Kind       TypeKind `json:"kind"`
	Fields     []string `json:"fields,omitempty"`  // Field names when detail = 2
	Methods    []string `json:"methods,omitempty"` // Method names (for classes)
	IsExported bool     `json:"exported,omitempty"`
	Line       int      `json:"line,omitempty"` // Line number of definition (1-indexed)
}

// FileAnalysis holds extracted info about a single file for deps mode.
type FileAnalysis struct {
	Path      string     `json:"path"`
	Language  string     `json:"language"`
	Functions []FuncInfo `json:"functions"`
	Types     []TypeInfo `json:"types,omitempty"`
	Imports   []string   `json:"imports"`
}

// DepsProject is the JSON output for --deps mode.
type DepsProject struct {
	Root         string              `json:"root"`
	Mode         string              `json:"mode"`
	Files        []FileAnalysis      `json:"files"`
	ExternalDeps map[string][]string `json:"external_deps"`
	DiffRef      string              `json:"diff_ref,omitempty"`
	DetailLevel  int                 `json:"detail_level,omitempty"`
}

// IsExportedName checks if a symbol name is exported based on language conventions
func IsExportedName(name, lang string) bool {
	if name == "" {
		return false
	}

	switch lang {
	case "go":
		// Go: exported if starts with uppercase
		r := []rune(name)
		return unicode.IsUpper(r[0])

	case "python":
		// Python: exported if doesn't start with _
		return !strings.HasPrefix(name, "_")

	case "rust":
		// Rust: would need `pub` keyword analysis
		// For now, assume all are potentially public
		return true

	default:
		// Most languages: assume public unless private keyword
		return true
	}
}
</file>
<file path="scanner/walker.go">
package scanner

import (
	"os"
	"path/filepath"

	ignore "github.com/sabhiram/go-gitignore"
)

// IgnoredDirs are directories to skip during scanning
var IgnoredDirs = map[string]bool{
	".git":           true,
	"node_modules":   true,
	"vendor":         true,
	"Pods":           true,
	"build":          true,
	"DerivedData":    true,
	".idea":          true,
	".vscode":        true,
	"__pycache__":    true,
	".DS_Store":      true,
	"venv":           true,
	".venv":          true,
	".env":           true,
	".pytest_cache":  true,
	".mypy_cache":    true,
	".ruff_cache":    true,
	".coverage":      true,
	"htmlcov":        true,
	".tox":           true,
	"dist":           true,
	".next":          true,
	".nuxt":          true,
	"target":         true,
	".gradle":        true,
	".cargo":         true,
	".grammar-build": true,
	"grammars":       true,
}

// LoadGitignore loads .gitignore from root if it exists
func LoadGitignore(root string) *ignore.GitIgnore {
	gitignorePath := filepath.Join(root, ".gitignore")

	if _, err := os.Stat(gitignorePath); err == nil {
		if gitignore, err := ignore.CompileIgnoreFile(gitignorePath); err == nil {
			return gitignore
		}
	}

	return nil
}

// ScanFiles walks the directory tree and returns all files
func ScanFiles(root string, gitignore *ignore.GitIgnore) ([]FileInfo, error) {
	var files []FileInfo

	err := filepath.Walk(root, func(path string, info os.FileInfo, err error) error {
		if err != nil {
			return err
		}

		relPath, err := filepath.Rel(root, path)
		if err != nil {
			return err
		}

		// Skip if matched by common ignore patterns
		if info.IsDir() {
			if IgnoredDirs[info.Name()] {
				return filepath.SkipDir
			}
		} else {
			if IgnoredDirs[info.Name()] {
				return nil
			}
		}

		// Skip if matched by .gitignore
		if gitignore != nil && gitignore.MatchesPath(relPath) {
			if info.IsDir() {
				return filepath.SkipDir
			}
			return nil
		}

		// Skip directories (we only want files in the output)
		if info.IsDir() {
			return nil
		}

		files = append(files, FileInfo{
			Path:   relPath,
			Size:   info.Size(),
			Ext:    filepath.Ext(path),
			Tokens: EstimateTokens(info.Size()),
		})

		return nil
	})

	return files, err
}

// ScanForDeps walks the directory tree and analyzes files for dependencies
// detailLevel controls the depth of extraction (0=names, 1=signatures, 2=full)
func ScanForDeps(root string, gitignore *ignore.GitIgnore, loader *GrammarLoader, detailLevel DetailLevel) ([]FileAnalysis, error) {
	var analyses []FileAnalysis

	err := filepath.Walk(root, func(path string, info os.FileInfo, err error) error {
		if err != nil {
			return err
		}

		relPath, _ := filepath.Rel(root, path)

		// Skip ignored dirs
		if info.IsDir() {
			if IgnoredDirs[info.Name()] {
				return filepath.SkipDir
			}
			return nil
		}

		if IgnoredDirs[info.Name()] {
			return nil
		}

		// Skip if matched by .gitignore
		if gitignore != nil && gitignore.MatchesPath(relPath) {
			return nil
		}

		// Only analyze supported languages
		if DetectLanguage(path) == "" {
			return nil
		}

		// Analyze file with the specified detail level
		analysis, err := loader.AnalyzeFile(path, detailLevel)
		if err != nil || analysis == nil {
			return nil
		}

		// Use relative path in output
		analysis.Path = relPath
		analyses = append(analyses, *analysis)

		return nil
	})

	return analyses, err
}
</file>
<file path="CLAUDE.md">
# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Build & Run Commands

```bash
# Build CLI
go build -o codemap .

# Build MCP server
go build -o codemap-mcp ./mcp/

# Run with make
make run                          # Default tree view
make run DIR=/path DEPS=1         # Dependency mode
make run SKYLINE=1 ANIMATE=1      # Animated skyline

# Build tree-sitter grammars (one-time setup for --deps mode)
make grammars

# Development
go fmt ./...                      # Format code
go vet ./...                      # Lint code
make clean                        # Remove artifacts
make install                      # Install to ~/.local/bin
```

## Architecture

codemap is a Go CLI that generates token-efficient codebase visualizations for LLMs.

**Core Pipeline:**
1. **scanner/** - File system traversal and dependency analysis
   - `walker.go` - `ScanFiles()` walks directories respecting .gitignore, `ScanForDeps()` for dependency mode
   - `deps.go` - Tree-sitter based import/function extraction for 16 languages
   - `grammar.go` + `grammar_unix.go`/`grammar_windows.go` - Platform-specific tree-sitter loading
   - `queries/` - Tree-sitter query files (.scm) for each supported language

2. **render/** - Output visualization
   - `tree.go` - `Tree()` generates main file tree view
   - `depgraph.go` - `Depgraph()` generates dependency flow visualization
   - `skyline.go` - ASCII cityscape visualization with optional animation
   - `colors.go` - Terminal color handling per language

3. **main.go** - CLI entry point with flag parsing (`--deps`, `--diff`, `--skyline`, `--animate`, `--ref`)

4. **mcp/** - MCP server exposing 7 tools: `status`, `list_projects`, `get_structure`, `get_dependencies`, `get_diff`, `find_file`, `get_importers`

**Key Dependencies:**
- `tree-sitter/go-tree-sitter` - AST parsing for dependency analysis
- `ebitengine/purego` - Dynamic loading of tree-sitter grammars
- `charmbracelet/bubbletea` - Terminal animation for skyline mode

**Grammar Location:** Tree-sitter `.so`/`.dylib` files must exist in `scanner/grammars/` or be specified via `CODEMAP_GRAMMAR_DIR` env var.

**Testing:**
There are no automated tests. Changes must be verified manually by running `codemap` against real projects:
- `./codemap .` (Basic tree)
- `./codemap --deps .` (Dependency mode)
- `./codemap --diff` (Diff mode)
</file>
<file path="CODE_OF_CONDUCT.md">
# Contributor Covenant Code of Conduct

## Our Pledge

We as members, contributors, and leaders pledge to make participation in our
community a harassment-free experience for everyone, regardless of age, body
size, visible or invisible disability, ethnicity, sex characteristics, gender
identity and expression, level of experience, education, socio-economic status,
nationality, personal appearance, race, religion, or sexual identity
and orientation.

We pledge to act and interact in ways that contribute to an open, welcoming,
diverse, inclusive, and healthy community.

## Our Standards

Examples of behavior that contributes to a positive environment for our
community include:

* Demonstrating empathy and kindness toward other people
* Being respectful of differing opinions, viewpoints, and experiences
* Giving and gracefully accepting constructive feedback
* Accepting responsibility and apologizing to those affected by our mistakes,
  and learning from the experience
* Focusing on what is best not just for us as individuals, but for the
  overall community

Examples of unacceptable behavior include:

* The use of sexualized language or imagery, and sexual attention or
  advances of any kind
* Trolling, insulting or derogatory comments, and personal or political attacks
* Public or private harassment
* Publishing others' private information, such as a physical or email
  address, without their explicit permission
* Other conduct which could reasonably be considered inappropriate in a
  professional setting

## Enforcement Responsibilities

Community leaders are responsible for clarifying and enforcing our standards of
acceptable behavior and will take appropriate and fair corrective action in
response to any behavior that they deem inappropriate, threatening, offensive,
or harmful.

Community leaders have the right and responsibility to remove, edit, or reject
comments, commits, code, wiki edits, issues, and other contributions that are
not aligned to this Code of Conduct, and will communicate reasons for moderation
decisions when appropriate.

## Scope

This Code of Conduct applies within all community spaces, and also applies when
an individual is officially representing the community in public spaces.
Examples of representing our community include using an official e-mail address,
posting via an official social media account, or acting as an appointed
representative at an online or offline event.

## Enforcement

Instances of abusive, harassing, or otherwise unacceptable behavior may be
reported to the community leaders responsible for enforcement at
jordancoinjackson@gmail.com.
All complaints will be reviewed and investigated promptly and fairly.

All community leaders are obligated to respect the privacy and security of the
reporter of any incident.

## Enforcement Guidelines

Community leaders will follow these Community Impact Guidelines in determining
the consequences for any action they deem in violation of this Code of Conduct:

### 1. Correction

**Community Impact**: Use of inappropriate language or other behavior deemed
unprofessional or unwelcome in the community.

**Consequence**: A private, written warning from community leaders, providing
clarity around the nature of the violation and an explanation of why the
behavior was inappropriate. A public apology may be requested.

### 2. Warning

**Community Impact**: A violation through a single incident or series
of actions.

**Consequence**: A warning with consequences for continued behavior. No
interaction with the people involved, including unsolicited interaction with
those enforcing the Code of Conduct, for a specified period of time. This
includes avoiding interactions in community spaces as well as external channels
like social media. Violating these terms may lead to a temporary or
permanent ban.

### 3. Temporary Ban

**Community Impact**: A serious violation of community standards, including
sustained inappropriate behavior.

**Consequence**: A temporary ban from any sort of interaction or public
communication with the community for a specified period of time. No public or
private interaction with the people involved, including unsolicited interaction
with those enforcing the Code of Conduct, is allowed during this period.
Violating these terms may lead to a permanent ban.

### 4. Permanent Ban

**Community Impact**: Demonstrating a pattern of violation of community
standards, including sustained inappropriate behavior,  harassment of an
individual, or aggression toward or disparagement of classes of individuals.

**Consequence**: A permanent ban from any sort of public interaction within
the community.

## Attribution

This Code of Conduct is adapted from the [Contributor Covenant][homepage],
version 2.0, available at
https://www.contributor-covenant.org/version/2/0/code_of_conduct.html.

Community Impact Guidelines were inspired by [Mozilla's code of conduct
enforcement ladder](https://github.com/mozilla/diversity).

[homepage]: https://www.contributor-covenant.org

For answers to common questions about this code of conduct, see the FAQ at
https://www.contributor-covenant.org/faq. Translations are available at
https://www.contributor-covenant.org/translations.
</file>
<file path="codemap.rb">
class Codemap < Formula
  desc "Generate a brain map of your codebase for LLM context"
  homepage "https://github.com/JordanCoin/codemap"
  url "https://github.com/JordanCoin/codemap/archive/refs/tags/v2.7.tar.gz"
  sha256 "6fe179db056c02bfcb398962bb06a5512cf5b41dc19614c66fbf08bf53a1c776"
  license "MIT"

  depends_on "go" => :build

  resource "tree-sitter-go" do
    url "https://github.com/tree-sitter/tree-sitter-go/archive/refs/heads/master.tar.gz"
    sha256 "1c746cac06741178f3b0b21258a8ff04599f3bef176044121b985ff17917bf25"
  end

  resource "tree-sitter-python" do
    url "https://github.com/tree-sitter/tree-sitter-python/archive/refs/heads/master.tar.gz"
    sha256 "874479d1f7058159f417fdeb706f279e4edd6b2c392bd8a642bc5d552f45e9cd"
  end

  resource "tree-sitter-javascript" do
    url "https://github.com/tree-sitter/tree-sitter-javascript/archive/refs/heads/master.tar.gz"
    sha256 "0ee41a73f53ddc31bd6567cafa5864f0678e71ebb9c9c618f6d67ca788a22455"
  end

  resource "tree-sitter-typescript" do
    url "https://github.com/tree-sitter/tree-sitter-typescript/archive/refs/heads/master.tar.gz"
    sha256 "c5bf6e925d299bce34e7ae373b46d5363f2e896e6ea282091d163fd1f831b497"
  end

  resource "tree-sitter-rust" do
    url "https://github.com/tree-sitter/tree-sitter-rust/archive/refs/heads/master.tar.gz"
    sha256 "dc93e09d9ea2b20e91c87c6202b53dc57513e0db3730231c60d154582a74dfc0"
  end

  resource "tree-sitter-ruby" do
    url "https://github.com/tree-sitter/tree-sitter-ruby/archive/refs/heads/master.tar.gz"
    sha256 "93df5566a3bee1c16f6fb7da492d58a34840d488347dc05a2327e3730e53aa20"
  end

  resource "tree-sitter-c" do
    url "https://github.com/tree-sitter/tree-sitter-c/archive/refs/heads/master.tar.gz"
    sha256 "d4e3f07154466ad60c7bb1cc9719be3bc2e8b9212d39849f6aa4a2b90cac2415"
  end

  resource "tree-sitter-cpp" do
    url "https://github.com/tree-sitter/tree-sitter-cpp/archive/refs/heads/master.tar.gz"
    sha256 "6c8f7d6bf2203b35490f5c91f81ed644a8dfb0a1e0274f15fa8e47b0b17f0d9c"
  end

  resource "tree-sitter-java" do
    url "https://github.com/tree-sitter/tree-sitter-java/archive/refs/heads/master.tar.gz"
    sha256 "a41ad5bd64ed71a026b001434319e7bcdc7e44ca1e28c39a87ab9e7ea1b1c575"
  end

  resource "tree-sitter-swift" do
    url "https://github.com/tree-sitter/tree-sitter-swift/archive/refs/heads/master.tar.gz"
    sha256 "2576f1f8da5ffa199a5b4bf1a21564106fa1f94fec19e4a375796d2286ac96bd"
  end

  resource "tree-sitter-bash" do
    url "https://github.com/tree-sitter/tree-sitter-bash/archive/refs/heads/master.tar.gz"
    sha256 "86ffaeafc9d3a01a3da828b0fab5ef1b9d765d245764b066794577daee512f23"
  end

  resource "tree-sitter-kotlin" do
    url "https://github.com/fwcd/tree-sitter-kotlin/archive/refs/heads/main.tar.gz"
    sha256 "4c63bab70f70bb884d97446a14ff78037944ff7c389f0482b5f49e4a32fe24c4"
  end

  resource "tree-sitter-c-sharp" do
    url "https://github.com/tree-sitter/tree-sitter-c-sharp/archive/refs/heads/master.tar.gz"
    sha256 "81d4d39508dad98a56969acb76e979945f1eb8c9bf3e5921a4b66bd634dc1266"
  end

  resource "tree-sitter-php" do
    url "https://github.com/tree-sitter/tree-sitter-php/archive/refs/heads/master.tar.gz"
    sha256 "df40197bb1bee56f96e52dc301ddd7e2ef0b33284dcd50de0a2bc53bd140e9a1"
  end

  resource "tree-sitter-dart" do
    url "https://github.com/UserNobody14/tree-sitter-dart/archive/refs/heads/master.tar.gz"
    sha256 "a38f682088b39813ed271eae942a3ad3c42c3c6c0086bd3484e8cdea26e04e0c"
  end

  resource "tree-sitter-r" do
    url "https://github.com/r-lib/tree-sitter-r/archive/refs/heads/main.tar.gz"
    sha256 "b6e0df92204cbd956790b20165adf13f2a9879cda5e86b70949d918302634e0f"
  end

  def install
    # Build the main Go binary
    system "go", "build", "-o", libexec/"codemap", "."

    # Create grammars directory
    (libexec/"grammars").mkpath

    # Build and install each grammar resource
    resources.each do |r|
      r.stage do
        lang = r.name.sub("tree-sitter-", "").tr("-", "_")

        # Handle special source directories
        src_subdir = "src"
        src_subdir = "typescript/src" if lang == "typescript"
        src_subdir = "php/src" if lang == "php"

        src_dir = Pathname.pwd/src_subdir

        # Determine library extension and flags
        lib_ext = OS.mac? ? "dylib" : "so"
        cflags = OS.mac? ? %w[-dynamiclib -fPIC] : %w[-shared -fPIC]

        output_lib = libexec/"grammars/libtree-sitter-#{lang}.#{lib_ext}"

        # Prepare sources
        sources = [src_dir/"parser.c"]

        if (src_dir/"scanner.c").exist?
          sources << (src_dir/"scanner.c")
        elsif (src_dir/"scanner.cc").exist?
          # Compile C++ scanner first
          system ENV.cxx, "-c", "-fPIC", src_dir/"scanner.cc", "-o", "scanner.o", "-I#{src_dir}"
          sources << "scanner.o"
        end

        # Compile and link
        system ENV.cc, *cflags, "-o", output_lib, *sources, "-I#{src_dir}"
      end
    end

    # Create wrapper script
    (bin/"codemap").write <<~EOS
      #!/bin/bash
      export CODEMAP_GRAMMAR_DIR="#{libexec}/grammars"
      export CODEMAP_QUERY_DIR="#{libexec}/queries"
      exec "#{libexec}/codemap" "$@"
    EOS
  end

  test do
    system bin/"codemap", "."
  end
end
</file>
<file path="CONTRIBUTING.md">
# Contributing to codemap

Thanks for your interest in contributing! Here's how to get involved.

## Quick Contributions

- **Bug reports**: Open an issue with reproduction steps
- **Feature ideas**: Open an issue to discuss first
- **Documentation**: PRs welcome for README, examples, etc.

## Adding a New Language

Want to add support for a language like Clojure, Elixir, Scala, etc.? Here's what's needed:

### 1. Add grammar to `release.yml`

In `.github/workflows/release.yml`, add a line to the `GRAMMARS` env var:

```yaml
env:
  GRAMMARS: |
    go:tree-sitter/tree-sitter-go:master:src
    # ... existing grammars ...
    clojure:sogaiu/tree-sitter-clojure:main:src   # <- add yours
```

Format: `name:github_org/repo:branch:src_dir`

Most grammars use `src` as the source directory, but check the repo structure.

### 2. Create a query file

Create `scanner/queries/<lang>.scm` to define what to capture:

```scm
; Functions - capture function/method definitions
(function_definition
  name: (identifier) @function)

; Imports - capture import/require statements
(import_clause
  (identifier) @import)
```

**Finding the right node types:**
- Use [tree-sitter playground](https://tree-sitter.github.io/tree-sitter/7-playground.html)
- Check the grammar repo's `grammar.js` for node names
- Look at existing queries in `scanner/queries/` for examples

### 3. Add extension mapping

In `scanner/grammar.go`, add to the `extToLang` map:

```go
var extToLang = map[string]string{
    // ... existing mappings ...
    ".clj":  "clojure",
    ".cljs": "clojure",
    ".cljc": "clojure",
}
```

### 4. Open a PR

That's it from your side! Open a PR with these 3 changes.

**What happens next:**
- Maintainer reviews the PR
- Maintainer updates the Homebrew formula (`codemap.rb`) with the new grammar
- On next release, all platforms get the new language automatically

## Development Setup

```bash
git clone https://github.com/JordanCoin/codemap.git
cd codemap

# Build the binary
go build -o codemap .

# Build grammars for --deps mode (requires clang/gcc)
make deps

# Test it
./codemap .
./codemap --deps .
```

## Code Style

- Keep it simple - this is a CLI tool, not a framework
- Run `go fmt` before committing
- Test your changes with `./codemap` on a real project

## Questions?

Open an issue or reach out. We're happy to help!
</file>
<file path="go.mod">
module codemap

go 1.24.0

require (
	github.com/charmbracelet/bubbletea v1.3.10
	github.com/ebitengine/purego v0.9.1
	github.com/sabhiram/go-gitignore v0.0.0-20210923224102-525f6e181f06
	github.com/tree-sitter/go-tree-sitter v0.25.0
	golang.org/x/term v0.37.0
)

require (
	github.com/aymanbagabas/go-osc52/v2 v2.0.1 // indirect
	github.com/charmbracelet/colorprofile v0.2.3-0.20250311203215-f60798e515dc // indirect
	github.com/charmbracelet/lipgloss v1.1.0 // indirect
	github.com/charmbracelet/x/ansi v0.10.1 // indirect
	github.com/charmbracelet/x/cellbuf v0.0.13-0.20250311204145-2c3ea96c31dd // indirect
	github.com/charmbracelet/x/term v0.2.1 // indirect
	github.com/erikgeiser/coninput v0.0.0-20211004153227-1c3628e74d0f // indirect
	github.com/google/jsonschema-go v0.3.0 // indirect
	github.com/lucasb-eyer/go-colorful v1.2.0 // indirect
	github.com/mattn/go-isatty v0.0.20 // indirect
	github.com/mattn/go-localereader v0.0.1 // indirect
	github.com/mattn/go-pointer v0.0.1 // indirect
	github.com/mattn/go-runewidth v0.0.16 // indirect
	github.com/modelcontextprotocol/go-sdk v1.1.0 // indirect
	github.com/muesli/ansi v0.0.0-20230316100256-276c6243b2f6 // indirect
	github.com/muesli/cancelreader v0.2.2 // indirect
	github.com/muesli/termenv v0.16.0 // indirect
	github.com/rivo/uniseg v0.4.7 // indirect
	github.com/xo/terminfo v0.0.0-20220910002029-abceb7e1c41e // indirect
	github.com/yosida95/uritemplate/v3 v3.0.2 // indirect
	golang.org/x/oauth2 v0.30.0 // indirect
	golang.org/x/sys v0.38.0 // indirect
	golang.org/x/text v0.3.8 // indirect
)
</file>
<file path="go.sum">
github.com/aymanbagabas/go-osc52/v2 v2.0.1 h1:HwpRHbFMcZLEVr42D4p7XBqjyuxQH5SMiErDT4WkJ2k=
github.com/aymanbagabas/go-osc52/v2 v2.0.1/go.mod h1:uYgXzlJ7ZpABp8OJ+exZzJJhRNQ2ASbcXHWsFqH8hp8=
github.com/charmbracelet/bubbletea v1.3.10 h1:otUDHWMMzQSB0Pkc87rm691KZ3SWa4KUlvF9nRvCICw=
github.com/charmbracelet/bubbletea v1.3.10/go.mod h1:ORQfo0fk8U+po9VaNvnV95UPWA1BitP1E0N6xJPlHr4=
github.com/charmbracelet/colorprofile v0.2.3-0.20250311203215-f60798e515dc h1:4pZI35227imm7yK2bGPcfpFEmuY1gc2YSTShr4iJBfs=
github.com/charmbracelet/colorprofile v0.2.3-0.20250311203215-f60798e515dc/go.mod h1:X4/0JoqgTIPSFcRA/P6INZzIuyqdFY5rm8tb41s9okk=
github.com/charmbracelet/lipgloss v1.1.0 h1:vYXsiLHVkK7fp74RkV7b2kq9+zDLoEU4MZoFqR/noCY=
github.com/charmbracelet/lipgloss v1.1.0/go.mod h1:/6Q8FR2o+kj8rz4Dq0zQc3vYf7X+B0binUUBwA0aL30=
github.com/charmbracelet/x/ansi v0.10.1 h1:rL3Koar5XvX0pHGfovN03f5cxLbCF2YvLeyz7D2jVDQ=
github.com/charmbracelet/x/ansi v0.10.1/go.mod h1:3RQDQ6lDnROptfpWuUVIUG64bD2g2BgntdxH0Ya5TeE=
github.com/charmbracelet/x/cellbuf v0.0.13-0.20250311204145-2c3ea96c31dd h1:vy0GVL4jeHEwG5YOXDmi86oYw2yuYUGqz6a8sLwg0X8=
github.com/charmbracelet/x/cellbuf v0.0.13-0.20250311204145-2c3ea96c31dd/go.mod h1:xe0nKWGd3eJgtqZRaN9RjMtK7xUYchjzPr7q6kcvCCs=
github.com/charmbracelet/x/term v0.2.1 h1:AQeHeLZ1OqSXhrAWpYUtZyX1T3zVxfpZuEQMIQaGIAQ=
github.com/charmbracelet/x/term v0.2.1/go.mod h1:oQ4enTYFV7QN4m0i9mzHrViD7TQKvNEEkHUMCmsxdUg=
github.com/davecgh/go-spew v1.1.0/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=
github.com/davecgh/go-spew v1.1.1 h1:vj9j/u1bqnvCEfJOwUhtlOARqs3+rkHYY13jYWTU97c=
github.com/davecgh/go-spew v1.1.1/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=
github.com/ebitengine/purego v0.9.1 h1:a/k2f2HQU3Pi399RPW1MOaZyhKJL9w/xFpKAg4q1s0A=
github.com/ebitengine/purego v0.9.1/go.mod h1:iIjxzd6CiRiOG0UyXP+V1+jWqUXVjPKLAI0mRfJZTmQ=
github.com/erikgeiser/coninput v0.0.0-20211004153227-1c3628e74d0f h1:Y/CXytFA4m6baUTXGLOoWe4PQhGxaX0KpnayAqC48p4=
github.com/erikgeiser/coninput v0.0.0-20211004153227-1c3628e74d0f/go.mod h1:vw97MGsxSvLiUE2X8qFplwetxpGLQrlU1Q9AUEIzCaM=
github.com/google/jsonschema-go v0.3.0 h1:6AH2TxVNtk3IlvkkhjrtbUc4S8AvO0Xii0DxIygDg+Q=
github.com/google/jsonschema-go v0.3.0/go.mod h1:r5quNTdLOYEz95Ru18zA0ydNbBuYoo9tgaYcxEYhJVE=
github.com/lucasb-eyer/go-colorful v1.2.0 h1:1nnpGOrhyZZuNyfu1QjKiUICQ74+3FNCN69Aj6K7nkY=
github.com/lucasb-eyer/go-colorful v1.2.0/go.mod h1:R4dSotOR9KMtayYi1e77YzuveK+i7ruzyGqttikkLy0=
github.com/mattn/go-isatty v0.0.20 h1:xfD0iDuEKnDkl03q4limB+vH+GxLEtL/jb4xVJSWWEY=
github.com/mattn/go-isatty v0.0.20/go.mod h1:W+V8PltTTMOvKvAeJH7IuucS94S2C6jfK/D7dTCTo3Y=
github.com/mattn/go-localereader v0.0.1 h1:ygSAOl7ZXTx4RdPYinUpg6W99U8jWvWi9Ye2JC/oIi4=
github.com/mattn/go-localereader v0.0.1/go.mod h1:8fBrzywKY7BI3czFoHkuzRoWE9C+EiG4R1k4Cjx5p88=
github.com/mattn/go-pointer v0.0.1 h1:n+XhsuGeVO6MEAp7xyEukFINEa+Quek5psIR/ylA6o0=
github.com/mattn/go-pointer v0.0.1/go.mod h1:2zXcozF6qYGgmsG+SeTZz3oAbFLdD3OWqnUbNvJZAlc=
github.com/mattn/go-runewidth v0.0.16 h1:E5ScNMtiwvlvB5paMFdw9p4kSQzbXFikJ5SQO6TULQc=
github.com/mattn/go-runewidth v0.0.16/go.mod h1:Jdepj2loyihRzMpdS35Xk/zdY8IAYHsh153qUoGf23w=
github.com/modelcontextprotocol/go-sdk v1.1.0 h1:Qjayg53dnKC4UZ+792W21e4BpwEZBzwgRW6LrjLWSwA=
github.com/modelcontextprotocol/go-sdk v1.1.0/go.mod h1:6fM3LCm3yV7pAs8isnKLn07oKtB0MP9LHd3DfAcKw10=
github.com/muesli/ansi v0.0.0-20230316100256-276c6243b2f6 h1:ZK8zHtRHOkbHy6Mmr5D264iyp3TiX5OmNcI5cIARiQI=
github.com/muesli/ansi v0.0.0-20230316100256-276c6243b2f6/go.mod h1:CJlz5H+gyd6CUWT45Oy4q24RdLyn7Md9Vj2/ldJBSIo=
github.com/muesli/cancelreader v0.2.2 h1:3I4Kt4BQjOR54NavqnDogx/MIoWBFa0StPA8ELUXHmA=
github.com/muesli/cancelreader v0.2.2/go.mod h1:3XuTXfFS2VjM+HTLZY9Ak0l6eUKfijIfMUZ4EgX0QYo=
github.com/muesli/termenv v0.16.0 h1:S5AlUN9dENB57rsbnkPyfdGuWIlkmzJjbFf0Tf5FWUc=
github.com/muesli/termenv v0.16.0/go.mod h1:ZRfOIKPFDYQoDFF4Olj7/QJbW60Ol/kL1pU3VfY/Cnk=
github.com/pmezard/go-difflib v1.0.0 h1:4DBwDE0NGyQoBHbLQYPwSUPoCMWR5BEzIk/f1lZbAQM=
github.com/pmezard/go-difflib v1.0.0/go.mod h1:iKH77koFhYxTK1pcRnkKkqfTogsbg7gZNVY4sRDYZ/4=
github.com/rivo/uniseg v0.2.0/go.mod h1:J6wj4VEh+S6ZtnVlnTBMWIodfgj8LQOQFoIToxlJtxc=
github.com/rivo/uniseg v0.4.7 h1:WUdvkW8uEhrYfLC4ZzdpI2ztxP1I582+49Oc5Mq64VQ=
github.com/rivo/uniseg v0.4.7/go.mod h1:FN3SvrM+Zdj16jyLfmOkMNblXMcoc8DfTHruCPUcx88=
github.com/sabhiram/go-gitignore v0.0.0-20210923224102-525f6e181f06 h1:OkMGxebDjyw0ULyrTYWeN0UNCCkmCWfjPnIA2W6oviI=
github.com/sabhiram/go-gitignore v0.0.0-20210923224102-525f6e181f06/go.mod h1:+ePHsJ1keEjQtpvf9HHw0f4ZeJ0TLRsxhunSI2hYJSs=
github.com/stretchr/objx v0.1.0/go.mod h1:HFkY916IF+rwdDfMAkV7OtwuqBVzrE8GR6GFx+wExME=
github.com/stretchr/testify v1.6.1/go.mod h1:6Fq8oRcR53rry900zMqJjRRixrwX3KX962/h/Wwjteg=
github.com/stretchr/testify v1.10.0 h1:Xv5erBjTwe/5IxqUQTdXv5kgmIvbHo3QQyRwhJsOfJA=
github.com/stretchr/testify v1.10.0/go.mod h1:r2ic/lqez/lEtzL7wO/rwa5dbSLXVDPFyf8C91i36aY=
github.com/tree-sitter/go-tree-sitter v0.25.0 h1:sx6kcg8raRFCvc9BnXglke6axya12krCJF5xJ2sftRU=
github.com/tree-sitter/go-tree-sitter v0.25.0/go.mod h1:r77ig7BikoZhHrrsjAnv8RqGti5rtSyvDHPzgTPsUuU=
github.com/tree-sitter/tree-sitter-c v0.23.4 h1:nBPH3FV07DzAD7p0GfNvXM+Y7pNIoPenQWBpvM++t4c=
github.com/tree-sitter/tree-sitter-c v0.23.4/go.mod h1:MkI5dOiIpeN94LNjeCp8ljXN/953JCwAby4bClMr6bw=
github.com/tree-sitter/tree-sitter-cpp v0.23.4 h1:LaWZsiqQKvR65yHgKmnaqA+uz6tlDJTJFCyFIeZU/8w=
github.com/tree-sitter/tree-sitter-cpp v0.23.4/go.mod h1:doqNW64BriC7WBCQ1klf0KmJpdEvfxyXtoEybnBo6v8=
github.com/tree-sitter/tree-sitter-embedded-template v0.23.2 h1:nFkkH6Sbe56EXLmZBqHHcamTpmz3TId97I16EnGy4rg=
github.com/tree-sitter/tree-sitter-embedded-template v0.23.2/go.mod h1:HNPOhN0qF3hWluYLdxWs5WbzP/iE4aaRVPMsdxuzIaQ=
github.com/tree-sitter/tree-sitter-go v0.23.4 h1:yt5KMGnTHS+86pJmLIAZMWxukr8W7Ae1STPvQUuNROA=
github.com/tree-sitter/tree-sitter-go v0.23.4/go.mod h1:Jrx8QqYN0v7npv1fJRH1AznddllYiCMUChtVjxPK040=
github.com/tree-sitter/tree-sitter-html v0.23.2 h1:1UYDV+Yd05GGRhVnTcbP58GkKLSHHZwVaN+lBZV11Lc=
github.com/tree-sitter/tree-sitter-html v0.23.2/go.mod h1:gpUv/dG3Xl/eebqgeYeFMt+JLOY9cgFinb/Nw08a9og=
github.com/tree-sitter/tree-sitter-java v0.23.5 h1:J9YeMGMwXYlKSP3K4Us8CitC6hjtMjqpeOf2GGo6tig=
github.com/tree-sitter/tree-sitter-java v0.23.5/go.mod h1:NRKlI8+EznxA7t1Yt3xtraPk1Wzqh3GAIC46wxvc320=
github.com/tree-sitter/tree-sitter-javascript v0.23.1 h1:1fWupaRC0ArlHJ/QJzsfQ3Ibyopw7ZfQK4xXc40Zveo=
github.com/tree-sitter/tree-sitter-javascript v0.23.1/go.mod h1:lmGD1EJdCA+v0S1u2fFgepMg/opzSg/4pgFym2FPGAs=
github.com/tree-sitter/tree-sitter-json v0.24.8 h1:tV5rMkihgtiOe14a9LHfDY5kzTl5GNUYe6carZBn0fQ=
github.com/tree-sitter/tree-sitter-json v0.24.8/go.mod h1:F351KK0KGvCaYbZ5zxwx/gWWvZhIDl0eMtn+1r+gQbo=
github.com/tree-sitter/tree-sitter-php v0.23.11 h1:iHewsLNDmznh8kgGyfWfujsZxIz1YGbSd2ZTEM0ZiP8=
github.com/tree-sitter/tree-sitter-php v0.23.11/go.mod h1:T/kbfi+UcCywQfUNAJnGTN/fMSUjnwPXA8k4yoIks74=
github.com/tree-sitter/tree-sitter-python v0.23.6 h1:qHnWFR5WhtMQpxBZRwiaU5Hk/29vGju6CVtmvu5Haas=
github.com/tree-sitter/tree-sitter-python v0.23.6/go.mod h1:cpdthSy/Yoa28aJFBscFHlGiU+cnSiSh1kuDVtI8YeM=
github.com/tree-sitter/tree-sitter-ruby v0.23.1 h1:T/NKHUA+iVbHM440hFx+lzVOzS4dV6z8Qw8ai+72bYo=
github.com/tree-sitter/tree-sitter-ruby v0.23.1/go.mod h1:kUS4kCCQloFcdX6sdpr8p6r2rogbM6ZjTox5ZOQy8cA=
github.com/tree-sitter/tree-sitter-rust v0.23.2 h1:6AtoooCW5GqNrRpfnvl0iUhxTAZEovEmLKDbyHlfw90=
github.com/tree-sitter/tree-sitter-rust v0.23.2/go.mod h1:hfeGWic9BAfgTrc7Xf6FaOAguCFJRo3RBbs7QJ6D7MI=
github.com/xo/terminfo v0.0.0-20220910002029-abceb7e1c41e h1:JVG44RsyaB9T2KIHavMF/ppJZNG9ZpyihvCd0w101no=
github.com/xo/terminfo v0.0.0-20220910002029-abceb7e1c41e/go.mod h1:RbqR21r5mrJuqunuUZ/Dhy/avygyECGrLceyNeo4LiM=
github.com/yosida95/uritemplate/v3 v3.0.2 h1:Ed3Oyj9yrmi9087+NczuL5BwkIc4wvTb5zIM+UJPGz4=
github.com/yosida95/uritemplate/v3 v3.0.2/go.mod h1:ILOh0sOhIJR3+L/8afwt/kE++YT040gmv5BQTMR2HP4=
golang.org/x/exp v0.0.0-20220909182711-5c715a9e8561 h1:MDc5xs78ZrZr3HMQugiXOAkSZtfTpbJLDr/lwfgO53E=
golang.org/x/exp v0.0.0-20220909182711-5c715a9e8561/go.mod h1:cyybsKvd6eL0RnXn6p/Grxp8F5bW7iYuBgsNCOHpMYE=
golang.org/x/oauth2 v0.30.0 h1:dnDm7JmhM45NNpd8FDDeLhK6FwqbOf4MLCM9zb1BOHI=
golang.org/x/oauth2 v0.30.0/go.mod h1:B++QgG3ZKulg6sRPGD/mqlHQs5rB3Ml9erfeDY7xKlU=
golang.org/x/sys v0.0.0-20210809222454-d867a43fc93e/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=
golang.org/x/sys v0.6.0/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=
golang.org/x/sys v0.38.0 h1:3yZWxaJjBmCWXqhN1qh02AkOnCQ1poK6oF+a7xWL6Gc=
golang.org/x/sys v0.38.0/go.mod h1:OgkHotnGiDImocRcuBABYBEXf8A9a87e/uXjp9XT3ks=
golang.org/x/term v0.37.0 h1:8EGAD0qCmHYZg6J17DvsMy9/wJ7/D/4pV/wfnld5lTU=
golang.org/x/term v0.37.0/go.mod h1:5pB4lxRNYYVZuTLmy8oR2BH8dflOR+IbTYFD8fi3254=
golang.org/x/text v0.3.8 h1:nAL+RVCQ9uMn3vJZbV+MRnydTJFPf8qqY42YiA6MrqY=
golang.org/x/text v0.3.8/go.mod h1:E6s5w1FMmriuDzIBO73fBruAKo1PCIq6d2Q6DHfQ8WQ=
gopkg.in/check.v1 v0.0.0-20161208181325-20d25e280405/go.mod h1:Co6ibVJAznAaIkqp8huTwlJQCZ016jof/cbN4VW5Yz0=
gopkg.in/yaml.v3 v3.0.0-20200313102051-9f266ea9e77c/go.mod h1:K4uyk7z7BCEPqu6E+C64Yfv1cQ7kz7rIZviUmN+EgEM=
gopkg.in/yaml.v3 v3.0.1 h1:fxVm/GzAzEWqLHuvctI91KS9hhNmmWOoWu0XTYJS7CA=
gopkg.in/yaml.v3 v3.0.1/go.mod h1:K4uyk7z7BCEPqu6E+C64Yfv1cQ7kz7rIZviUmN+EgEM=
</file>
<file path="LICENSE">
MIT License

Copyright (c) 2025 Jordan

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
</file>
<file path="main.go">
package main

import (
	"encoding/json"
	"flag"
	"fmt"
	"os"
	"path/filepath"

	"codemap/render"
	"codemap/scanner"

	ignore "github.com/sabhiram/go-gitignore"
)

func main() {
	skylineMode := flag.Bool("skyline", false, "Enable skyline visualization mode")
	animateMode := flag.Bool("animate", false, "Enable animation (use with --skyline)")
	depsMode := flag.Bool("deps", false, "Enable dependency graph mode (function/import analysis)")
	diffMode := flag.Bool("diff", false, "Only show files changed vs main (or use --ref to specify branch)")
	diffRef := flag.String("ref", "main", "Branch/ref to compare against (use with --diff)")
	jsonMode := flag.Bool("json", false, "Output JSON (for Python renderer compatibility)")
	debugMode := flag.Bool("debug", false, "Show debug info (gitignore loading, paths, etc.)")
	helpMode := flag.Bool("help", false, "Show help")

	// New flags for enhanced analysis
	detailLevel := flag.Int("detail", 0, "Detail level: 0=names, 1=signatures, 2=full (use with --deps)")
	apiMode := flag.Bool("api", false, "Show public API surface only (compact view, use with --deps)")

	flag.Parse()

	if *helpMode {
		fmt.Println("codemap - Generate a brain map of your codebase for LLM context")
		fmt.Println()
		fmt.Println("Usage: codemap [options] [path]")
		fmt.Println()
		fmt.Println("Modes:")
		fmt.Println("  (default)          Tree view with token estimates and file sizes")
		fmt.Println("  --deps             Dependency flow map (functions, types & imports)")
		fmt.Println("  --skyline          City skyline visualization")
		fmt.Println("  --diff             Only show files changed vs a branch")
		fmt.Println()
		fmt.Println("Options:")
		fmt.Println("  --help             Show this help message")
		fmt.Println("  --json             Output JSON (for programmatic use)")
		fmt.Println()
		fmt.Println("Dependency mode (--deps):")
		fmt.Println("  --detail <level>   Detail level: 0=names, 1=signatures, 2=full")
		fmt.Println("  --api              Show public API surface only (compact view)")
		fmt.Println()
		fmt.Println("Diff mode (--diff):")
		fmt.Println("  --ref <branch>     Branch to compare against (default: main)")
		fmt.Println()
		fmt.Println("Skyline mode (--skyline):")
		fmt.Println("  --animate          Enable terminal animation")
		fmt.Println()
		fmt.Println("Examples:")
		fmt.Println("  codemap .                        # Tree with tokens (~3.5 chars/token)")
		fmt.Println("  codemap --deps .                 # Dependencies with line numbers")
		fmt.Println("  codemap --deps --detail 1 .      # With function signatures")
		fmt.Println("  codemap --deps --api .           # Public API surface only")
		fmt.Println("  codemap --diff                   # Changed files vs main")
		fmt.Println("  codemap --diff --ref develop     # Changed files vs develop")
		fmt.Println("  codemap --skyline --animate .    # Animated skyline")
		fmt.Println()
		fmt.Println("Output notes:")
		fmt.Println("  ⭐️  = Top 5 largest source files")
		fmt.Println("  [!] = Large file (>8k tokens) - may need chunking for LLMs")
		os.Exit(0)
	}

	root := flag.Arg(0)
	if root == "" {
		root = "."
	}

	absRoot, err := filepath.Abs(root)
	if err != nil {
		fmt.Fprintf(os.Stderr, "Error getting absolute path: %v\n", err)
		os.Exit(1)
	}

	// Load .gitignore if it exists
	gitignore := scanner.LoadGitignore(root)

	if *debugMode {
		fmt.Fprintf(os.Stderr, "[debug] Root path: %s\n", root)
		fmt.Fprintf(os.Stderr, "[debug] Absolute path: %s\n", absRoot)
		gitignorePath := filepath.Join(root, ".gitignore")
		if gitignore != nil {
			fmt.Fprintf(os.Stderr, "[debug] Loaded .gitignore from: %s\n", gitignorePath)
		} else {
			fmt.Fprintf(os.Stderr, "[debug] No .gitignore found at: %s\n", gitignorePath)
		}
	}

	// Get changed files if --diff is specified
	var diffInfo *scanner.DiffInfo
	if *diffMode {
		var err error
		diffInfo, err = scanner.GitDiffInfo(absRoot, *diffRef)
		if err != nil {
			fmt.Fprintf(os.Stderr, "Error getting git diff: %v\n", err)
			fmt.Fprintf(os.Stderr, "Make sure '%s' is a valid branch/ref\n", *diffRef)
			os.Exit(1)
		}
		if len(diffInfo.Changed) == 0 {
			fmt.Printf("No files changed vs %s\n", *diffRef)
			os.Exit(0)
		}
	}

	// Handle --deps mode separately
	if *depsMode {
		var changedFiles map[string]bool
		if diffInfo != nil {
			changedFiles = diffInfo.Changed
		}
		runDepsMode(absRoot, root, gitignore, *jsonMode, *diffRef, changedFiles, *detailLevel, *apiMode)
		return
	}

	mode := "tree"
	if *skylineMode {
		mode = "skyline"
	}

	// Scan files
	files, err := scanner.ScanFiles(root, gitignore)
	if err != nil {
		fmt.Fprintf(os.Stderr, "Error walking tree: %v\n", err)
		os.Exit(1)
	}

	// Filter to changed files if --diff specified (with diff info annotations)
	var impact []scanner.ImpactInfo
	var activeDiffRef string
	if diffInfo != nil {
		files = scanner.FilterToChangedWithInfo(files, diffInfo)
		impact = scanner.AnalyzeImpact(absRoot, files)
		activeDiffRef = *diffRef
	}

	project := scanner.Project{
		Root:    absRoot,
		Mode:    mode,
		Animate: *animateMode,
		Files:   files,
		DiffRef: activeDiffRef,
		Impact:  impact,
	}

	// Render or output JSON
	if *jsonMode {
		json.NewEncoder(os.Stdout).Encode(project)
	} else if *skylineMode {
		render.Skyline(project, *animateMode)
	} else {
		render.Tree(project)
	}
}

func runDepsMode(absRoot, root string, gitignore *ignore.GitIgnore, jsonMode bool, diffRef string, changedFiles map[string]bool, detailLevel int, apiMode bool) {
	loader := scanner.NewGrammarLoader()

	// Check if grammars are available
	if !loader.HasGrammars() {
		fmt.Fprintln(os.Stderr, "")
		fmt.Fprintln(os.Stderr, "⚠️  No tree-sitter grammars found for --deps mode.")
		fmt.Fprintln(os.Stderr, "")
		fmt.Fprintln(os.Stderr, "To enable dependency analysis, either:")
		fmt.Fprintln(os.Stderr, "  • Install via Homebrew: brew install JordanCoin/tap/codemap")
		fmt.Fprintln(os.Stderr, "  • Download release with grammars: https://github.com/JordanCoin/codemap/releases")
		fmt.Fprintln(os.Stderr, "  • Build from source: make deps && go build")
		fmt.Fprintln(os.Stderr, "")
		fmt.Fprintln(os.Stderr, "Or set CODEMAP_GRAMMAR_DIR to your grammars directory.")
		fmt.Fprintln(os.Stderr, "")
		os.Exit(1)
	}

	analyses, err := scanner.ScanForDeps(root, gitignore, loader, scanner.DetailLevel(detailLevel))
	if err != nil {
		fmt.Fprintf(os.Stderr, "Error scanning for deps: %v\n", err)
		os.Exit(1)
	}

	// Filter to changed files if --diff specified
	if changedFiles != nil {
		analyses = scanner.FilterAnalysisToChanged(analyses, changedFiles)
	}

	depsProject := scanner.DepsProject{
		Root:         absRoot,
		Mode:         "deps",
		Files:        analyses,
		ExternalDeps: scanner.ReadExternalDeps(absRoot),
		DiffRef:      diffRef,
		DetailLevel:  detailLevel,
	}

	// Render or output JSON
	if jsonMode {
		json.NewEncoder(os.Stdout).Encode(depsProject)
	} else if apiMode {
		render.APIView(depsProject)
	} else {
		render.Depgraph(depsProject)
	}
}
</file>
<file path="Makefile">
.PHONY: all build build-mcp run deps grammars clean install install-mcp uninstall

all: build

build:
	go build -o codemap .

build-mcp:
	go build -o codemap-mcp ./mcp/

DIR ?= .
ABS_DIR := $(shell cd "$(DIR)" && pwd)
SKYLINE_FLAG := $(if $(SKYLINE),--skyline,)
ANIMATE_FLAG := $(if $(ANIMATE),--animate,)
DEPS_FLAG := $(if $(DEPS),--deps,)

run: build
	./codemap $(SKYLINE_FLAG) $(ANIMATE_FLAG) $(DEPS_FLAG) "$(ABS_DIR)"

# Build tree-sitter grammar libraries (one-time setup for deps mode)
grammars:
	cd scanner && ./build-grammars.sh

# Dependency graph mode - shows functions and imports per file
deps: build grammars
	./codemap --deps "$(ABS_DIR)"

clean:
	rm -f codemap codemap-mcp
	rm -rf scanner/.grammar-build
	rm -rf scanner/grammars

# Installation paths
PREFIX ?= $(HOME)/.local
BINDIR ?= $(PREFIX)/bin
GRAMMAR_DIR ?= $(PREFIX)/lib/codemap/grammars

install: build
	@echo "Installing codemap to $(BINDIR)..."
	install -d $(BINDIR)
	install -m 755 codemap $(BINDIR)/codemap
	@if [ -d scanner/grammars ] && [ "$$(ls -A scanner/grammars 2>/dev/null)" ]; then \
		echo "Installing grammars to $(GRAMMAR_DIR)..."; \
		install -d $(GRAMMAR_DIR); \
		cp -r scanner/grammars/* $(GRAMMAR_DIR)/; \
	fi
	@echo "Done! Run 'codemap --help' to get started."

install-mcp: build-mcp
	@echo "Installing codemap-mcp to $(BINDIR)..."
	install -d $(BINDIR)
	install -m 755 codemap-mcp $(BINDIR)/codemap-mcp
	@echo "Done!"

uninstall:
	@echo "Removing codemap from $(BINDIR)..."
	rm -f $(BINDIR)/codemap
	rm -f $(BINDIR)/codemap-mcp
	rm -rf $(PREFIX)/lib/codemap
	@echo "Done!"
</file>
<file path="PLAN.md">
# PLAN.md - Codemap GraphRAG + LLM Integration

## Executive Summary

**What**: Evolve codemap from a structural code mapper to an intelligent code understanding system by integrating GraphRAG (Graph-based Retrieval Augmented Generation) and local LLM capabilities.

**Why**: Current codemap provides excellent structural analysis but lacks semantic understanding. Agents using codemap must interpret raw data themselves, consuming tokens and time. GraphRAG + LLM will provide pre-interpreted, contextually rich information enabling faster and more accurate code comprehension.

**How**: Three-phase implementation adding (1) Knowledge Graph infrastructure, (2) LLM integration for semantic analysis, (3) Hybrid retrieval combining structural and semantic search.

---

## Table of Contents

1. [Current State Analysis](#1-current-state-analysis)
2. [Target Architecture](#2-target-architecture)
3. [Knowledge Graph Design](#3-knowledge-graph-design)
4. [LLM Integration Design](#4-llm-integration-design)
5. [Hybrid Retrieval System](#5-hybrid-retrieval-system)
6. [New MCP Tools](#6-new-mcp-tools)
7. [CLI Enhancements](#7-cli-enhancements)
8. [Storage Strategy](#8-storage-strategy)
9. [Implementation Phases](#9-implementation-phases)
10. [Performance Considerations](#10-performance-considerations)
11. [Testing Strategy](#11-testing-strategy)
12. [Migration Path](#12-migration-path)

---

## 1. Current State Analysis

### 1.1 Existing Capabilities

```
codemap/
├── scanner/           # AST extraction via tree-sitter
│   ├── walker.go      # File system traversal
│   ├── deps.go        # Import/dependency extraction
│   ├── symbol.go      # Symbol search
│   ├── git.go         # Git diff operations
│   └── queries/       # Tree-sitter queries (16 languages)
├── render/            # Output visualization
│   ├── tree.go        # File tree view
│   ├── depgraph.go    # Dependency flow
│   ├── api.go         # API surface view
│   └── skyline.go     # ASCII visualization
└── mcp/               # MCP server (8 tools)
    └── main.go        # Tool handlers
```

### 1.2 Current Data Model

```go
// scanner/types.go - Current structures
type FileAnalysis struct {
    Path      string
    Language  string
    Functions []FuncInfo
    Types     []TypeInfo
    Imports   []string
}

type FuncInfo struct {
    Name       string
    Signature  string
    Receiver   string
    IsExported bool
    Line       int
}

type TypeInfo struct {
    Name       string
    Kind       TypeKind
    Fields     []string
    Methods    []string
    IsExported bool
    Line       int
}
```

### 1.3 Current Limitations

| Limitation | Impact | Solution |
|------------|--------|----------|
| No call graph | Can't trace execution flow | Extract CALLS edges (syntactic) |
| No semantic search | Text-only queries | Add embeddings |
| No multi-hop queries | Limited impact analysis | Graph traversal |
| No explanations | Agent interprets raw data | LLM summarization |
| No persistence | Re-scan every time | Graph database |
| No cycle detection | Miss circular deps | Graph algorithms |

### 1.4 Tree-sitter Limitations (Important)

> **Critical Design Consideration**: Tree-sitter is a **syntactic parser**, not a **semantic analyzer**.

This has important implications for the call graph:

| Limitation | Example | Impact |
|------------|---------|--------|
| **No type resolution** | Can't distinguish `user.Service` (type) vs `user.Process()` (call) | May produce false positive edges |
| **No alias tracking** | `import u "users"` then `u.Create()` loses package info | Edges may be incomplete |
| **No interface resolution** | Can't know which concrete type implements interface | Polymorphic calls not tracked |
| **No data flow** | Can't track variable assignments through code | READS/WRITES edges unreliable |

**Mitigation Strategy**:
1. Call the feature **"Syntactic Call Graph"** or **"Candidate Call Graph"** in documentation
2. Focus on **high-precision patterns** (direct `call_expression` nodes)
3. Defer **data flow edges** (`READS`, `WRITES`, `ASSIGNS`) to Phase 4+ or future LSP integration
4. Accept that call graph is **best-effort approximation**, not complete semantic analysis
5. For Go specifically, consider optional `go/types` integration in future for higher accuracy

### 1.5 Existing Strengths to Leverage

- **Tree-sitter infrastructure**: Already parsing 16 languages
- **MCP server**: Ready for new tools
- **Clean architecture**: Easy to extend scanner/render pattern
- **Detail levels**: 0/1/2 pattern can extend to graph depth

---

## 2. Target Architecture

### 2.1 High-Level Architecture

```
┌─────────────────────────────────────────────────────────────────────────┐
│                           codemap v3.0                                   │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                          │
│  ┌──────────────┐   ┌──────────────┐   ┌──────────────┐                 │
│  │   scanner/   │   │    graph/    │   │   analyze/   │                 │
│  │              │   │              │   │              │                 │
│  │ • walker     │──▶│ • builder    │──▶│ • llm        │                 │
│  │ • deps       │   │ • store      │   │ • embedder   │                 │
│  │ • calls  ◀───────│ • query      │   │ • summarizer │                 │
│  │ • symbol     │   │ • algorithms │   │ • patterns   │                 │
│  └──────────────┘   └──────────────┘   └──────────────┘                 │
│         │                  │                  │                          │
│         └────────────┬─────┴──────────────────┘                          │
│                      ▼                                                   │
│              ┌──────────────┐                                            │
│              │   render/    │                                            │
│              │              │                                            │
│              │ • tree       │                                            │
│              │ • depgraph   │                                            │
│              │ • graphviz   │  ◀── NEW                                   │
│              │ • insights   │  ◀── NEW                                   │
│              └──────────────┘                                            │
│                      │                                                   │
│         ┌────────────┴────────────┐                                      │
│         ▼                         ▼                                      │
│  ┌──────────────┐         ┌──────────────┐                              │
│  │    CLI       │         │  MCP Server  │                              │
│  │              │         │              │                              │
│  │ --index      │         │ 8 existing + │                              │
│  │ --query      │         │ 8 new tools  │                              │
│  │ --explain    │         │              │                              │
│  └──────────────┘         └──────────────┘                              │
│                                                                          │
├─────────────────────────────────────────────────────────────────────────┤
│                         Storage Layer                                    │
│  ┌──────────────┐   ┌──────────────┐   ┌──────────────┐                 │
│  │   SQLite     │   │  In-Memory   │   │    Cache     │                 │
│  │  (persist)   │   │   (fast)     │   │  (results)   │                 │
│  └──────────────┘   └──────────────┘   └──────────────┘                 │
├─────────────────────────────────────────────────────────────────────────┤
│                       External Services (Optional)                       │
│  ┌──────────────┐   ┌──────────────┐                                    │
│  │   Ollama     │   │  OpenAI/     │                                    │
│  │  (local)     │   │  Anthropic   │                                    │
│  └──────────────┘   └──────────────┘                                    │
└─────────────────────────────────────────────────────────────────────────┘
```

### 2.2 New Package Structure

```
codemap/
├── scanner/              # EXISTING - Enhanced
│   ├── walker.go
│   ├── deps.go
│   ├── calls.go          # NEW - Function call extraction
│   ├── symbol.go
│   ├── git.go
│   ├── types.go
│   └── queries/       # Consolidated queries (one per language)
│       ├── go.scm     # Go: @func, @type, @call, @import
│       ├── python.scm
│       ├── typescript.scm
│       └── ...
├── graph/                # NEW - Knowledge Graph
│   ├── types.go          # Node, Edge, Graph types
│   ├── builder.go        # Graph construction from FileAnalysis
│   ├── store.go          # Storage interface
│   ├── sqlite.go         # SQLite implementation
│   ├── memory.go         # In-memory implementation
│   ├── query.go          # Query engine (Cypher-like)
│   └── algorithms.go     # Cycles, paths, centrality
├── analyze/              # NEW - LLM Integration
│   ├── llm.go            # LLM client interface
│   ├── ollama.go         # Ollama implementation
│   ├── openai.go         # OpenAI implementation
│   ├── embedder.go       # Embedding generation
│   ├── summarizer.go     # Code summarization
│   ├── patterns.go       # Pattern detection
│   └── cache.go          # Analysis cache
├── render/               # EXISTING - Enhanced
│   ├── tree.go
│   ├── depgraph.go
│   ├── api.go
│   ├── skyline.go
│   ├── graphviz.go       # NEW - Graph visualization
│   └── insights.go       # NEW - LLM-enhanced output
├── mcp/                  # EXISTING - Enhanced
│   └── main.go           # +8 new tools
├── config/               # NEW - Configuration
│   └── config.go         # YAML config loading
├── main.go
├── go.mod
└── go.sum
```

---

## 3. Knowledge Graph Design

### 3.1 Node Types

```go
// graph/types.go

type NodeKind string

const (
    // Structural nodes
    NodeFile       NodeKind = "File"
    NodePackage    NodeKind = "Package"
    NodeModule     NodeKind = "Module"

    // Code entities
    NodeFunction   NodeKind = "Function"
    NodeMethod     NodeKind = "Method"
    NodeClass      NodeKind = "Class"
    NodeStruct     NodeKind = "Struct"
    NodeInterface  NodeKind = "Interface"
    NodeTrait      NodeKind = "Trait"
    NodeEnum       NodeKind = "Enum"
    NodeTypeAlias  NodeKind = "TypeAlias"

    // Variables and constants
    NodeVariable   NodeKind = "Variable"
    NodeConstant   NodeKind = "Constant"
    NodeField      NodeKind = "Field"
    NodeParameter  NodeKind = "Parameter"
)

type Node struct {
    ID          string            `json:"id"`          // Unique identifier
    Kind        NodeKind          `json:"kind"`        // Node type
    Name        string            `json:"name"`        // Symbol name
    QualifiedName string          `json:"qualified"`   // Full path (pkg.Type.Method)
    Path        string            `json:"path"`        // File path (relative)
    Line        int               `json:"line"`        // Definition line
    EndLine     int               `json:"end_line"`    // End of definition
    Language    string            `json:"language"`    // Source language
    Signature   string            `json:"signature,omitempty"`
    DocString   string            `json:"doc,omitempty"`
    IsExported  bool              `json:"exported"`
    Complexity  int               `json:"complexity,omitempty"` // Cyclomatic
    LOC         int               `json:"loc,omitempty"`        // Lines of code
    Embedding   []float32         `json:"embedding,omitempty"`  // Vector embedding
    Summary     string            `json:"summary,omitempty"`    // LLM-generated
    Properties  map[string]any    `json:"props,omitempty"`      // Extension point
    UpdatedAt   time.Time         `json:"updated_at"`
}

// ═══════════════════════════════════════════════════════════════════════════
// Deterministic Node ID Generation
// ═══════════════════════════════════════════════════════════════════════════
//
// Node IDs MUST be deterministic and canonical to enable:
// 1. Cache invalidation: Same symbol → same ID across rebuilds
// 2. Delta indexing: Compare old vs new graph by ID
// 3. Cross-session references: Agents can store and reuse IDs
//
// ID Format: sha256(QualifiedName + ":" + RelativePath)[:16]
//
// Examples:
// - Function: sha256("main.processFile:cmd/main.go")[:16] → "a7f3b2c1d4e5f6a8"
// - Method:   sha256("Scanner.Walk:scanner/walker.go")[:16] → "b8c4d5e6f7a8b9c0"
// - Type:     sha256("FileInfo:scanner/types.go")[:16] → "c9d5e6f7a8b9c0d1"
//
// For overloaded symbols (same name, different signatures), append signature hash:
// - sha256("Handler.ServeHTTP[sig:abc123]:http/handler.go")[:16]

func GenerateNodeID(qualifiedName, relativePath string) string {
    input := qualifiedName + ":" + relativePath
    hash := sha256.Sum256([]byte(input))
    return hex.EncodeToString(hash[:])[:16]
}

func GenerateOverloadedNodeID(qualifiedName, relativePath, signature string) string {
    sigHash := sha256.Sum256([]byte(signature))
    input := qualifiedName + "[sig:" + hex.EncodeToString(sigHash[:])[:6] + "]:" + relativePath
    hash := sha256.Sum256([]byte(input))
    return hex.EncodeToString(hash[:])[:16]
}
```

### 3.2 Edge Types

> **Note**: Edge types are categorized by implementation phase based on Tree-sitter capabilities.
> See [Section 1.4](#14-tree-sitter-limitations-important) for parser limitations.

```go
// graph/types.go

type EdgeKind string

const (
    // ══════════════════════════════════════════════════════════════
    // PHASE 1: High-precision edges (reliable via Tree-sitter)
    // ══════════════════════════════════════════════════════════════

    // Containment (deterministic from AST)
    EdgeContains      EdgeKind = "CONTAINS"       // File -> Function
    EdgeDeclares      EdgeKind = "DECLARES"       // Package -> Type

    // Dependencies (from import statements)
    EdgeImports       EdgeKind = "IMPORTS"        // File -> File/Package
    EdgeDependsOn     EdgeKind = "DEPENDS_ON"     // Package -> Package

    // Syntactic Call Graph (best-effort, see limitations)
    // NOTE: This is a "Candidate Call Graph" - may have false positives
    // due to lack of type resolution. Still valuable for impact analysis.
    EdgeCalls         EdgeKind = "CALLS"          // Function -> Function (syntactic)

    // Type relationships (from declarations)
    EdgeImplements    EdgeKind = "IMPLEMENTS"     // Type -> Interface
    EdgeExtends       EdgeKind = "EXTENDS"        // Class -> Class
    EdgeComposedOf    EdgeKind = "COMPOSED_OF"    // Struct -> Type (field)

    // ══════════════════════════════════════════════════════════════
    // PHASE 4+: Lower-precision edges (require semantic analysis)
    // These are deferred until LSP integration or language-specific
    // type analysis (e.g., go/types for Go) is implemented.
    // ══════════════════════════════════════════════════════════════

    // Function signature relationships
    EdgeReturns       EdgeKind = "RETURNS"        // Function -> Type
    EdgeReceives      EdgeKind = "RECEIVES"       // Function -> Type (param)
    EdgeThrows        EdgeKind = "THROWS"         // Function -> Type (error)
    EdgeInstantiates  EdgeKind = "INSTANTIATES"   // Function -> Type

    // Data flow (requires control flow analysis - DEFERRED)
    // These cannot be reliably extracted via Tree-sitter alone.
    EdgeReads         EdgeKind = "READS"          // Function -> Variable
    EdgeWrites        EdgeKind = "WRITES"         // Function -> Variable
    EdgeAssigns       EdgeKind = "ASSIGNS"        // Statement -> Variable
)

type Edge struct {
    ID        string            `json:"id"`
    From      string            `json:"from"`      // Source node ID
    To        string            `json:"to"`        // Target node ID
    Kind      EdgeKind          `json:"kind"`      // Relationship type
    Line      int               `json:"line,omitempty"`      // Where relation occurs
    Weight    float64           `json:"weight,omitempty"`    // For ranking
    Count     int               `json:"count,omitempty"`     // Occurrence count
    Properties map[string]any   `json:"props,omitempty"`
}

// Call Confidence Heuristics
// The Weight field for CALLS edges uses syntactic context to estimate reliability:
//
// | Pattern | Example | Weight | Rationale |
// |---------|---------|--------|-----------|
// | Qualified method call | `repo.Save()` | 1.0 | Receiver type known |
// | Package-qualified call | `strings.Split()` | 1.0 | Package explicit |
// | Direct function call | `Save()` | 0.5 | Could be local or imported |
// | Anonymous/closure | `fn(args...)` | 0.2 | Cannot track reference |
// | Reflection-based | `reflect.ValueOf().Call()` | 0.1 | Runtime resolution |
//
// Impact analysis tools should filter edges by Weight threshold (default: 0.5)
// to reduce noise from low-confidence syntactic matches.

type CallConfidence struct {
    Pattern     string  // e.g., "qualified_method", "direct_call", "closure"
    Weight      float64 // 0.0 - 1.0
    Description string
}

var DefaultCallConfidence = []CallConfidence{
    {"qualified_method", 1.0, "Method call with explicit receiver (obj.Method())"},
    {"qualified_package", 1.0, "Function call with package prefix (pkg.Func())"},
    {"direct_call", 0.5, "Unqualified function call (Func())"},
    {"closure_call", 0.2, "Anonymous function or closure invocation"},
    {"dynamic_call", 0.1, "Reflection or interface-based dynamic dispatch"},
}
```

### 3.2.1 False Positive Mitigation Strategies

> **Goal**: Reduce false positive CALLS edges without requiring LSP/semantic analysis.
> These strategies are applied in layers, each filtering out more invalid candidates.

#### Phase 1: Import Graph Filter (High Impact, Low Cost)

```go
// graph/validate.go

// ImportGraphFilter eliminates call edges that violate import relationships.
// If file A doesn't import package B, calls in A cannot reach functions in B.
type ImportGraphFilter struct {
    imports map[string][]string // file -> imported packages
}

func (f *ImportGraphFilter) IsValidEdge(edge *Edge, fromNode, toNode *Node) bool {
    // Same file - always valid
    if fromNode.Path == toNode.Path {
        return true
    }

    // Same package - always valid
    if fromNode.Package == toNode.Package {
        return true
    }

    // Check if caller's file imports callee's package
    importedPkgs := f.imports[fromNode.Path]
    for _, pkg := range importedPkgs {
        if pkg == toNode.Package || strings.HasSuffix(pkg, "/"+toNode.Package) {
            return true
        }
    }

    return false // No import relationship - edge is invalid
}

// Usage in GraphBuilder:
func (b *GraphBuilder) buildCallEdges(calls []CallSite) []*Edge {
    filter := NewImportGraphFilter(b.imports)
    var edges []*Edge

    for _, call := range calls {
        candidates := b.findCandidateFunctions(call.Name)
        for _, candidate := range candidates {
            edge := &Edge{From: call.CallerID, To: candidate.ID, Kind: EdgeCalls}
            if filter.IsValidEdge(edge, call.Caller, candidate) {
                edge.Weight = call.Confidence
                edges = append(edges, edge)
            }
            // Invalid edges are silently dropped
        }
    }
    return edges
}
```

**Impact**: Eliminates ~40-50% of false positives (cross-package mismatches).

---

#### Phase 1: Arity Matching (Medium Impact, Low Cost)

```go
// graph/validate.go

// ArityFilter eliminates call edges where argument count doesn't match.
type ArityFilter struct{}

func (f *ArityFilter) IsValidEdge(call *CallSite, candidate *Node) bool {
    // Unknown arity - can't filter, allow through
    if call.ArgCount < 0 || candidate.ParamCount < 0 {
        return true
    }

    // Variadic functions accept any number of args >= required
    if candidate.IsVariadic {
        return call.ArgCount >= candidate.RequiredParams
    }

    // Exact match required for non-variadic
    return call.ArgCount == candidate.ParamCount
}

// Extended CallSite to capture arity
type CallSite struct {
    Name       string
    CallerID   string
    Caller     *Node
    Line       int
    Confidence float64
    ArgCount   int  // Number of arguments at call site (-1 if unknown)
}

// Extended Node for functions
type Node struct {
    // ... existing fields ...
    ParamCount     int  `json:"param_count,omitempty"`
    RequiredParams int  `json:"required_params,omitempty"` // For variadic
    IsVariadic     bool `json:"variadic,omitempty"`
}
```

**Tree-sitter query extension** (Go example):
```scheme
; Capture argument count at call site
(call_expression
  function: (_) @call.name
  arguments: (argument_list) @call.args)

; In Go code, count children of @call.args to get arity
```

**Impact**: Eliminates ~20-30% of remaining false positives.

---

#### Phase 2: Receiver Type Inference (High Impact, Medium Cost)

```go
// graph/inference.go

// ReceiverInference attempts to infer the type of method call receivers
// by analyzing variable declarations in the same scope.
type ReceiverInference struct {
    declarations map[string]map[string]string // file -> varName -> typeName
}

// InferReceiverType tries to determine the type of a method call receiver
func (r *ReceiverInference) InferReceiverType(call *CallSite) (string, float64) {
    // Case 1: Chained call - NewFoo().Bar() → receiver is "Foo"
    if call.ReceiverExpr != "" && strings.HasPrefix(call.ReceiverExpr, "New") {
        typeName := strings.TrimPrefix(call.ReceiverExpr, "New")
        return typeName, 0.9 // High confidence
    }

    // Case 2: Variable lookup - foo.Bar() → lookup "foo" in declarations
    if varName := call.ReceiverVar; varName != "" {
        if typeName, ok := r.declarations[call.File][varName]; ok {
            return typeName, 0.8
        }
    }

    // Case 3: Parameter lookup - func(foo Foo) { foo.Bar() }
    if caller := call.Caller; caller != nil {
        for _, param := range caller.Parameters {
            if param.Name == call.ReceiverVar {
                return param.Type, 0.85
            }
        }
    }

    return "", 0.0 // Unknown
}

// Filter edges using inferred receiver type
func (r *ReceiverInference) FilterByReceiver(call *CallSite, candidate *Node) bool {
    inferredType, confidence := r.InferReceiverType(call)
    if confidence == 0 {
        return true // Can't infer, allow through (will use Weight)
    }

    // Check if candidate's receiver matches inferred type
    if candidate.ReceiverType == "" {
        return false // Candidate is a function, not a method
    }

    // Exact match or pointer match
    return candidate.ReceiverType == inferredType ||
           candidate.ReceiverType == "*"+inferredType ||
           "*"+candidate.ReceiverType == inferredType
}
```

**Impact**: Eliminates ~50-60% of method call false positives.

---

#### Phase 2: Lazy LLM Validation (High Impact, Variable Cost)

```go
// graph/validate_llm.go

// LLMValidator validates uncertain edges by asking the LLM
// Only invoked for edges with Weight < threshold during queries
type LLMValidator struct {
    llm       LLMClient
    cache     *ValidationCache
    threshold float64 // Default: 0.3
}

type ValidationResult struct {
    IsValid    bool
    Confidence float64
    Reason     string
}

// ValidateEdge asks LLM to confirm if a call edge is valid
func (v *LLMValidator) ValidateEdge(edge *Edge, caller, callee *Node) (*ValidationResult, error) {
    // Check cache first
    if cached, ok := v.cache.Get(edge.ID); ok {
        return cached, nil
    }

    prompt := fmt.Sprintf(`Analyze if this function call is valid:

CALLER (%s:%d):
%s

CALLEE (%s:%d):
%s

CALL SITE (line %d):
%s

Question: Does the call at line %d actually invoke the function %s defined in %s?
Answer with: YES (confident), LIKELY (probable), UNLIKELY (improbable), or NO (definitely not).
Explain briefly.`,
        caller.Path, caller.Line, caller.SourceCode,
        callee.Path, callee.Line, callee.SourceCode,
        edge.Line, extractCallContext(caller, edge.Line),
        edge.Line, callee.QualifiedName, callee.Path)

    response, err := v.llm.Complete(prompt)
    if err != nil {
        return nil, err
    }

    result := parseValidationResponse(response)
    v.cache.Set(edge.ID, result)
    return result, nil
}

// Usage in impact_analysis tool:
func (h *Handler) handleImpactAnalysis(input ImpactAnalysisInput) (*ImpactAnalysisOutput, error) {
    edges := h.graph.GetCallersOf(input.Symbol)

    var validEdges []*Edge
    for _, edge := range edges {
        if edge.Weight >= 0.5 {
            // High confidence - include directly
            validEdges = append(validEdges, edge)
        } else if edge.Weight >= 0.3 {
            // Medium confidence - validate with LLM if enabled
            if input.ValidateUncertain {
                result, _ := h.validator.ValidateEdge(edge, ...)
                if result.IsValid {
                    validEdges = append(validEdges, edge)
                }
            }
        }
        // Weight < 0.3 - exclude by default
    }
    // ...
}
```

**Impact**: Near-perfect precision for validated edges, but adds latency.

---

#### Phase 3+: Feedback Loop (Long-term Improvement)

```go
// graph/feedback.go

// EdgeFeedback stores user/agent corrections to edge validity
type EdgeFeedback struct {
    EdgeID    string    `json:"edge_id"`
    IsValid   bool      `json:"is_valid"`
    Source    string    `json:"source"`  // "user", "agent", "llm"
    Reason    string    `json:"reason,omitempty"`
    CreatedAt time.Time `json:"created_at"`
}

// FeedbackStore persists corrections for learning
type FeedbackStore struct {
    db *sql.DB
}

func (s *FeedbackStore) RecordFeedback(f *EdgeFeedback) error {
    _, err := s.db.Exec(`
        INSERT INTO edge_feedback (edge_id, is_valid, source, reason, created_at)
        VALUES (?, ?, ?, ?, ?)
        ON CONFLICT(edge_id) DO UPDATE SET
            is_valid = excluded.is_valid,
            source = excluded.source,
            reason = excluded.reason,
            created_at = excluded.created_at
    `, f.EdgeID, f.IsValid, f.Source, f.Reason, f.CreatedAt)
    return err
}

// ApplyFeedback adjusts edge weights based on feedback history
func (s *FeedbackStore) ApplyFeedback(edges []*Edge) {
    feedback := s.loadFeedback()
    for _, edge := range edges {
        if fb, ok := feedback[edge.ID]; ok {
            if fb.IsValid {
                edge.Weight = max(edge.Weight, 0.9) // Boost confirmed edges
            } else {
                edge.Weight = 0.0 // Mark invalid edges
            }
        }
    }
}

// MCP tool for feedback
type RecordFeedbackInput struct {
    Path     string `json:"path"`
    EdgeID   string `json:"edge_id"`
    IsValid  bool   `json:"is_valid"`
    Reason   string `json:"reason,omitempty"`
}
```

**Impact**: Precision improves over time with usage.

---

#### Summary: Mitigation Pipeline

```
┌─────────────────────────────────────────────────────────────────────────┐
│                    Call Edge Validation Pipeline                         │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                          │
│  Raw Call Sites ──┬──► Import Graph Filter ──┬──► ~50% eliminated       │
│                   │                          │                           │
│                   │    (same pkg? imports?)  │                           │
│                   │                          ▼                           │
│                   │    Arity Filter ─────────┬──► ~20% more eliminated  │
│                   │                          │                           │
│                   │    (arg count matches?)  │                           │
│                   │                          ▼                           │
│                   │    Receiver Inference ───┬──► ~30% more eliminated  │
│                   │                          │                           │
│                   │    (type matches?)       │                           │
│                   │                          ▼                           │
│                   │    Assign Weight ────────┬──► Edges with Weight     │
│                   │                          │                           │
│                   │                          ▼                           │
│                   │    ┌─────────────────────────────────────────┐      │
│                   │    │ Query Time (if ValidateUncertain=true)  │      │
│                   │    │                                         │      │
│                   │    │  Weight ≥ 0.5 ──► Include directly      │      │
│                   │    │  Weight 0.3-0.5 ──► LLM Validation      │      │
│                   │    │  Weight < 0.3 ──► Exclude               │      │
│                   │    └─────────────────────────────────────────┘      │
│                   │                          │                           │
│                   │                          ▼                           │
│                   └──────────────────► Final Valid Edges                │
│                                                                          │
└─────────────────────────────────────────────────────────────────────────┘

Expected False Positive Reduction:
├── After Import Filter:     ~50% eliminated
├── After Arity Filter:      ~60% total eliminated
├── After Receiver Infer:    ~75% total eliminated
├── After LLM Validation:    ~95% total eliminated (for queried edges)
└── With Feedback Loop:      ~98%+ over time
```

### 3.3 Graph Structure

```go
// graph/types.go

type CodeGraph struct {
    ID          string              `json:"id"`
    Root        string              `json:"root"`        // Project root path
    Name        string              `json:"name"`        // Project name
    Nodes       map[string]*Node    `json:"nodes"`
    Edges       []*Edge             `json:"edges"`

    // Indexes for fast lookup
    nodesByKind map[NodeKind][]*Node
    nodesByPath map[string][]*Node
    edgesByFrom map[string][]*Edge
    edgesByTo   map[string][]*Edge
    edgesByKind map[EdgeKind][]*Edge

    // Metadata
    Languages   []string            `json:"languages"`
    FileCount   int                 `json:"file_count"`
    NodeCount   int                 `json:"node_count"`
    EdgeCount   int                 `json:"edge_count"`
    IndexedAt   time.Time           `json:"indexed_at"`
    Version     string              `json:"version"`
}
```

### 3.4 Query Language (Cypher-like DSL)

```go
// graph/query.go

type QueryBuilder struct {
    graph *CodeGraph
}

// Fluent API for graph queries
func (g *CodeGraph) Query() *QueryBuilder

// Example queries:
// Find all functions that call a specific function
query.Match("(f:Function)-[:CALLS]->(target:Function)").
      Where("target.name = ?", "processPayment").
      Return("f")

// Find path between two nodes
query.ShortestPath("(a:Function)", "(b:Function)").
      Where("a.name = ?", "handleRequest").
      And("b.name = ?", "saveToDatabase").
      Return("path")

// Find all implementations of an interface
query.Match("(t:Type)-[:IMPLEMENTS]->(i:Interface)").
      Where("i.name = ?", "Repository").
      Return("t.name", "t.path")

// Multi-hop traversal
query.Match("(f:Function)-[:CALLS*1..3]->(t:Function)").
      Where("f.name = ?", "main").
      Return("t")
```

### 3.5 Graph Algorithms

```go
// graph/algorithms.go

type Algorithms struct {
    graph *CodeGraph
}

// Cycle detection
func (a *Algorithms) FindCycles() [][]string

// Shortest path between nodes
func (a *Algorithms) ShortestPath(from, to string) []*Node

// All paths up to depth N
func (a *Algorithms) AllPaths(from, to string, maxDepth int) [][]*Node

// Impact analysis - what depends on this node
func (a *Algorithms) ImpactAnalysis(nodeID string, depth int) *ImpactResult

// Centrality - most connected nodes (hubs)
func (a *Algorithms) PageRank() map[string]float64
func (a *Algorithms) BetweennessCentrality() map[string]float64

// Community detection - modules that belong together
func (a *Algorithms) DetectCommunities() [][]string

// Strongly connected components
func (a *Algorithms) StronglyConnectedComponents() [][]string
```

---

## 4. LLM Integration Design

### 4.1 LLM Client Interface

```go
// analyze/llm.go

type LLMClient interface {
    // Text generation
    Complete(ctx context.Context, prompt string, opts CompletionOpts) (string, error)

    // Chat completion
    Chat(ctx context.Context, messages []Message, opts CompletionOpts) (string, error)

    // Embedding generation
    Embed(ctx context.Context, text string) ([]float32, error)
    EmbedBatch(ctx context.Context, texts []string) ([][]float32, error)

    // Model info
    ModelName() string
    EmbeddingDimension() int
    MaxTokens() int

    // Health check
    Ping(ctx context.Context) error
}

type CompletionOpts struct {
    MaxTokens   int
    Temperature float64
    TopP        float64
    Stop        []string
}

type Message struct {
    Role    string // "system", "user", "assistant"
    Content string
}
```

### 4.2 Ollama Implementation

```go
// analyze/ollama.go

type OllamaClient struct {
    baseURL   string
    model     string
    embedModel string
    timeout   time.Duration
    client    *http.Client
}

func NewOllamaClient(cfg OllamaConfig) (*OllamaClient, error)

// Recommended models:
// - Chat/Completion: qwen2.5-coder:1.5b, codellama:7b-instruct, deepseek-coder:6.7b
// - Embeddings: nomic-embed-text, mxbai-embed-large
```

### 4.3 OpenAI/Anthropic Implementation

```go
// analyze/openai.go

type OpenAIClient struct {
    apiKey    string
    model     string
    embedModel string
    baseURL   string // For Azure or compatible APIs
}

func NewOpenAIClient(cfg OpenAIConfig) (*OpenAIClient, error)

// analyze/anthropic.go

type AnthropicClient struct {
    apiKey string
    model  string
}

func NewAnthropicClient(cfg AnthropicConfig) (*AnthropicClient, error)
```

### 4.4 Code Summarizer

```go
// analyze/summarizer.go

type Summarizer struct {
    llm      LLMClient
    cache    *Cache
    reader   *CodeReader  // NEW: Reads actual source code
}

// Summarize a single symbol
func (s *Summarizer) SummarizeSymbol(node *Node, context *SymbolContext) (string, error)

// Summarize a file
func (s *Summarizer) SummarizeFile(path string, analysis *FileAnalysis) (string, error)

// Summarize a module/package
func (s *Summarizer) SummarizeModule(path string, files []*FileAnalysis) (string, error)

// Summarize entire project
func (s *Summarizer) SummarizeProject(graph *CodeGraph) (string, error)

type SymbolContext struct {
    Callers      []*Node
    Callees      []*Node
    Implementers []*Node
    Usages       int
    Tests        []*Node
    SourceCode   string  // NEW: Actual source code of the symbol
}

// CodeReader extracts source code for symbols
type CodeReader struct {
    root string
}

// ReadSymbolSource reads the actual source code between Line and EndLine
func (r *CodeReader) ReadSymbolSource(node *Node, maxLines int) (string, error) {
    // Reads file, extracts lines from node.Line to node.EndLine
    // Truncates if > maxLines to avoid token overflow
}
```

#### Prompt Strategy (Critical for Quality)

> **Important**: LLM summarization quality depends heavily on providing **actual source code**,
> not just metadata. The prompt must include the real implementation.

```go
// Prompt templates - INCLUDE SOURCE CODE for better quality
const symbolPrompt = `Analyze this {{.Language}} {{.Kind}} and explain its purpose:

## Symbol Information
- Name: {{.Name}}
- File: {{.Path}}:{{.Line}}
{{if .Signature}}- Signature: {{.Signature}}{{end}}
{{if .DocString}}- Documentation: {{.DocString}}{{end}}

## Source Code
` + "```" + `{{.Language}}
{{.SourceCode}}
` + "```" + `

## Context
- Called by: {{range .Callers}}{{.Name}}, {{end}}
- Calls: {{range .Callees}}{{.Name}}, {{end}}
- Used {{.UsageCount}} times in codebase

## Task
Provide a concise 1-2 sentence summary explaining:
1. What this {{.Kind}} does
2. Why it exists (its role in the system)

Be specific and technical. Reference actual behavior from the code.`

// Fallback prompt when source code is unavailable
const fallbackPrompt = `Based on the following metadata, infer the purpose:

Name: {{.Name}}
Signature: {{.Signature}}
{{if .DocString}}Documentation: {{.DocString}}{{end}}
Called by: {{.Callers}}
Calls: {{.Callees}}

Provide a brief summary based on naming conventions and context.`
```

#### Fallback Strategy

```go
// SummarizeSymbol with fallback chain
func (s *Summarizer) SummarizeSymbol(node *Node, ctx *SymbolContext) (string, error) {
    // 1. Try LLM with full source code
    if s.llm != nil {
        source, err := s.reader.ReadSymbolSource(node, 50) // Max 50 lines
        if err == nil && source != "" {
            ctx.SourceCode = source
            if summary, err := s.llm.Complete(renderPrompt(symbolPrompt, node, ctx)); err == nil {
                return summary, nil
            }
        }
    }

    // 2. Fallback: Use docstring if available
    if node.DocString != "" {
        return node.DocString, nil
    }

    // 3. Fallback: Use signature as minimal summary
    if node.Signature != "" {
        return fmt.Sprintf("%s %s", node.Kind, node.Signature), nil
    }

    // 4. Final fallback: Just the name
    return fmt.Sprintf("%s %s", node.Kind, node.Name), nil
}
```

### 4.5 Pattern Detector

```go
// analyze/patterns.go

type PatternDetector struct {
    llm   LLMClient
    graph *CodeGraph
}

type Pattern struct {
    Name        string   // "Repository", "Factory", "Observer"
    Confidence  float64  // 0.0 - 1.0
    Nodes       []string // Node IDs involved
    Description string   // How it manifests
}

func (p *PatternDetector) DetectPatterns() ([]Pattern, error)

// Heuristic detection (no LLM)
func (p *PatternDetector) DetectRepositoryPattern() []Pattern
func (p *PatternDetector) DetectFactoryPattern() []Pattern
func (p *PatternDetector) DetectSingletonPattern() []Pattern
func (p *PatternDetector) DetectObserverPattern() []Pattern
func (p *PatternDetector) DetectMVCPattern() []Pattern

// LLM-enhanced detection
func (p *PatternDetector) DetectArchitecturalPatterns() ([]Pattern, error)
```

### 4.6 Embedding Manager

```go
// analyze/embedder.go

type Embedder struct {
    llm   LLMClient
    cache *Cache
    dim   int
}

// Generate embedding for code
func (e *Embedder) EmbedCode(code string, context string) ([]float32, error)

// Generate embedding for natural language query
func (e *Embedder) EmbedQuery(query string) ([]float32, error)

// Batch embed nodes
func (e *Embedder) EmbedNodes(nodes []*Node) error

// Similarity search
func (e *Embedder) FindSimilar(embedding []float32, k int) ([]*Node, error)

// Text to embed for a node
func (e *Embedder) NodeToText(node *Node) string {
    // Combines: name + signature + docstring + context
}
```

---

## 5. Hybrid Retrieval System

### 5.1 Retriever Interface

```go
// analyze/retriever.go

type Retriever interface {
    // Semantic search using embeddings
    SemanticSearch(query string, k int) ([]*RetrievalResult, error)

    // Structural search using graph
    StructuralSearch(query GraphQuery) ([]*RetrievalResult, error)

    // Hybrid: combines semantic + structural
    HybridSearch(query string, opts HybridOpts) ([]*RetrievalResult, error)
}

type RetrievalResult struct {
    Node       *Node
    Score      float64           // Relevance score
    Source     string            // "semantic", "structural", "hybrid"
    Context    *RetrievalContext // Related nodes from graph
    Snippet    string            // Relevant code snippet
}

type RetrievalContext struct {
    Callers    []*Node
    Callees    []*Node
    Siblings   []*Node  // Same file/package
    Related    []*Node  // Similar by embedding
}

type HybridOpts struct {
    SemanticWeight   float64 // Weight for embedding similarity
    StructuralWeight float64 // Weight for graph centrality
    ExpandHops       int     // How many hops to expand
    IncludeContext   bool    // Include callers/callees
    MaxResults       int
}
```

### 5.2 Hybrid Search Algorithm

```go
// analyze/retriever.go

func (r *HybridRetriever) HybridSearch(query string, opts HybridOpts) ([]*RetrievalResult, error) {
    // 1. Semantic search
    queryEmbed, _ := r.embedder.EmbedQuery(query)
    semanticResults := r.vectorSearch(queryEmbed, opts.MaxResults*2)

    // 2. Keyword extraction and structural search
    keywords := extractKeywords(query)
    structuralResults := r.graph.Query().
        Match("(n)").
        Where("n.name CONTAINS ANY ?", keywords).
        Return("n").
        Limit(opts.MaxResults * 2).
        Execute()

    // 3. Merge and re-rank
    merged := mergeResults(semanticResults, structuralResults, opts)

    // 4. Graph expansion
    for _, result := range merged {
        if opts.ExpandHops > 0 {
            result.Context = r.expandContext(result.Node, opts.ExpandHops)
        }
    }

    // 5. Final ranking
    return rankResults(merged, opts)[:opts.MaxResults], nil
}
```

### 5.3 Vector Storage

```go
// graph/vectors.go

type VectorIndex interface {
    // Add vectors
    Add(id string, embedding []float32) error
    AddBatch(items []VectorItem) error

    // Search
    Search(query []float32, k int) ([]VectorResult, error)
    SearchWithFilter(query []float32, k int, filter func(id string) bool) ([]VectorResult, error)

    // Management
    Delete(id string) error
    Count() int
    Dimension() int
}

// Simple in-memory implementation using cosine similarity
type MemoryVectorIndex struct {
    vectors map[string][]float32
    dim     int
}

// SQLite-backed implementation for persistence
type SQLiteVectorIndex struct {
    db  *sql.DB
    dim int
}
```

---

## 6. New MCP Tools

### 6.1 Tool Summary

| Tool | Category | Purpose |
|------|----------|---------|
| `index_project` | Graph | Build/update knowledge graph |
| `query_graph` | Graph | Execute graph queries |
| `trace_path` | Graph | Find paths between nodes |
| `find_cycles` | Graph | Detect circular dependencies |
| `impact_analysis` | Graph | Analyze change impact |
| `explain_symbol` | LLM | Get symbol explanation |
| `summarize_module` | LLM | Get module summary |
| `semantic_search` | Hybrid | Natural language code search |

### 6.2 Tool Specifications

```go
// mcp/tools_graph.go

// Tool: index_project
// Builds or updates the knowledge graph for a project
type IndexProjectInput struct {
    Path       string `json:"path"`
    Force      bool   `json:"force,omitempty"`      // Force full re-index
    Embeddings bool   `json:"embeddings,omitempty"` // Generate embeddings
}

type IndexProjectOutput struct {
    Status    string `json:"status"`
    Nodes     int    `json:"nodes"`
    Edges     int    `json:"edges"`
    Duration  string `json:"duration"`
    Languages []string `json:"languages"`
}

// Tool: query_graph
// Execute a graph query using Cypher-like syntax
type QueryGraphInput struct {
    Path  string `json:"path"`
    Query string `json:"query"` // e.g., "MATCH (f:Function)-[:CALLS]->(t) RETURN f,t"
    Limit int    `json:"limit,omitempty"`
}

// Tool: trace_path
// Find execution/dependency paths between two symbols
type TracePathInput struct {
    Path      string   `json:"path"`
    From      string   `json:"from"`       // Symbol name or pattern
    To        string   `json:"to"`         // Symbol name or pattern
    MaxDepth  int      `json:"max_depth,omitempty"`
    EdgeTypes []string `json:"edge_types,omitempty"` // Filter by edge type
}

type TracePathOutput struct {
    Paths [][]PathNode `json:"paths"`
    Count int          `json:"count"`
}

type PathNode struct {
    Name     string `json:"name"`
    Kind     string `json:"kind"`
    Path     string `json:"path"`
    Line     int    `json:"line"`
    EdgeType string `json:"edge,omitempty"` // Edge to next node
}

// Tool: find_cycles
// Detect circular dependencies in the codebase
type FindCyclesInput struct {
    Path      string   `json:"path"`
    Scope     string   `json:"scope,omitempty"`     // "files", "packages", "all"
    EdgeTypes []string `json:"edge_types,omitempty"`
}

type FindCyclesOutput struct {
    Cycles []Cycle `json:"cycles"`
    Count  int     `json:"count"`
}

type Cycle struct {
    Nodes       []string `json:"nodes"`
    Description string   `json:"description"`
    Severity    string   `json:"severity"` // "low", "medium", "high"
}

// Tool: impact_analysis
// Analyze what would be affected by changing a symbol
type ImpactAnalysisInput struct {
    Path   string `json:"path"`
    Symbol string `json:"symbol"` // Symbol name to analyze
    Depth  int    `json:"depth,omitempty"` // How many hops (default: 3)
}

type ImpactAnalysisOutput struct {
    Symbol         string        `json:"symbol"`
    DirectImpact   []ImpactNode  `json:"direct"`    // Depth 1
    IndirectImpact []ImpactNode  `json:"indirect"`  // Depth 2+
    TotalAffected  int           `json:"total"`
    RiskLevel      string        `json:"risk"` // "low", "medium", "high", "critical"
    Summary        string        `json:"summary"`
}

type ImpactNode struct {
    Name   string `json:"name"`
    Kind   string `json:"kind"`
    Path   string `json:"path"`
    Line   int    `json:"line"`
    Depth  int    `json:"depth"`  // Hops from source
    Reason string `json:"reason"` // "calls", "imports", "implements"
}
```

```go
// mcp/tools_llm.go

// Tool: explain_symbol
// Get an LLM-generated explanation of a symbol
type ExplainSymbolInput struct {
    Path    string `json:"path"`
    Symbol  string `json:"symbol"`
    Context bool   `json:"context,omitempty"` // Include callers/callees
    Detail  string `json:"detail,omitempty"`  // "brief", "detailed"
}

type ExplainSymbolOutput struct {
    Symbol      string   `json:"symbol"`
    Kind        string   `json:"kind"`
    Signature   string   `json:"signature,omitempty"`
    Explanation string   `json:"explanation"`

    // Source code of the symbol itself (for context)
    SourceCode  string   `json:"source_code,omitempty"`

    // Callers with actual usage snippets (not just names)
    Callers     []CallerContext `json:"callers,omitempty"`
    Callees     []string        `json:"callees,omitempty"`
    UsageCount  int             `json:"usage_count"`
}

// CallerContext provides actual usage context, not just names
type CallerContext struct {
    Name      string `json:"name"`       // e.g., "processFile"
    Path      string `json:"path"`       // e.g., "cmd/main.go"
    Line      int    `json:"line"`       // Line where call occurs
    Snippet   string `json:"snippet"`    // 5 lines around the call site
    Signature string `json:"signature,omitempty"`
}

// Example output:
// {
//   "symbol": "Scanner.Walk",
//   "source_code": "func (s *Scanner) Walk(root string) ([]*FileInfo, error) {\n...",
//   "callers": [
//     {
//       "name": "main.scanProject",
//       "path": "cmd/main.go",
//       "line": 45,
//       "snippet": "files, err := scanner.Walk(projectPath)\nif err != nil {\n    log.Fatal(err)\n}"
//     },
//     {
//       "name": "TestWalker",
//       "path": "scanner/walker_test.go",
//       "line": 23,
//       "snippet": "result, err := s.Walk(testDir)\nassert.NoError(t, err)"
//     }
//   ]
// }

// Tool: summarize_module
// Get a summary of a module/directory
type SummarizeModuleInput struct {
    Path   string `json:"path"`
    Module string `json:"module"` // Relative path to module/directory
}

type SummarizeModuleOutput struct {
    Module       string   `json:"module"`
    Summary      string   `json:"summary"`
    Purpose      string   `json:"purpose"`
    EntryPoints  []string `json:"entry_points"`
    Dependencies []string `json:"dependencies"`
    Patterns     []string `json:"patterns,omitempty"`
    FileCount    int      `json:"file_count"`
    FunctionCount int     `json:"function_count"`
}

// Tool: semantic_search
// Natural language search over the codebase with hybrid retrieval (semantic + structural)
type SemanticSearchInput struct {
    Path        string `json:"path"`
    Query       string `json:"query"`        // Natural language query
    Limit       int    `json:"limit,omitempty"`
    ExpandHops  int    `json:"expand_hops,omitempty"`
    IncludeCode bool   `json:"include_code,omitempty"`

    // ═══════════════════════════════════════════════════════════════════
    // Structural Filters (pre-filter before semantic search for precision)
    // ═══════════════════════════════════════════════════════════════════

    PathFilter     string   `json:"path_filter,omitempty"`     // Glob pattern: "src/database/**"
    KindFilter     []string `json:"kind_filter,omitempty"`     // ["Function", "Method", "Type"]
    ExportedOnly   bool     `json:"exported_only,omitempty"`   // Only exported symbols
    LanguageFilter []string `json:"language_filter,omitempty"` // ["go", "typescript"]
    MinWeight      float64  `json:"min_weight,omitempty"`      // Min edge confidence (for callers)
}

// Example usage:
// {
//   "query": "database connection pooling",
//   "path_filter": "src/database/**",
//   "exported_only": true,
//   "kind_filter": ["Function", "Method"],
//   "limit": 10
// }
// → Searches for "database connection pooling" only in exported functions/methods
//   within the src/database directory, returning the top 10 results.

type SemanticSearchOutput struct {
    Query   string         `json:"query"`
    Results []SearchResult `json:"results"`
    Count   int            `json:"count"`
}

type SearchResult struct {
    Name       string   `json:"name"`
    Kind       string   `json:"kind"`
    Path       string   `json:"path"`
    Line       int      `json:"line"`
    Score      float64  `json:"score"`
    Summary    string   `json:"summary,omitempty"`
    Snippet    string   `json:"snippet,omitempty"`
    RelatedTo  []string `json:"related,omitempty"`
}
```

---

## 7. CLI Enhancements

### 7.1 New Commands

```bash
# Index a project (builds knowledge graph)
codemap index [path]
codemap index --force          # Full re-index
codemap index --embeddings     # Include embeddings (requires LLM)

# Query the graph
codemap query "MATCH (f:Function)-[:CALLS]->(t) WHERE f.name = 'main' RETURN t"
codemap query --from main --to database --type path

# Explain a symbol
codemap explain UserService.Create
codemap explain --context ProcessPayment    # Include call graph

# Search semantically
codemap search "where is authentication handled"
codemap search "database connection" --expand 2

# Analyze impact
codemap impact UserRepository.Save --depth 3

# Find cycles
codemap cycles
codemap cycles --scope packages

# Summarize
codemap summarize src/services/
codemap summarize --project
```

### 7.2 New Flags for Existing Commands

```bash
# Enhanced --deps with graph info
codemap --deps --hubs           # Show most connected nodes
codemap --deps --cycles         # Include cycle warnings
codemap --deps --detail 2       # Full signatures + summaries

# Enhanced tree with insights
codemap --insights              # Add LLM summaries
codemap --complexity            # Show complexity metrics
```

---

## 8. Storage Strategy

### 8.1 Directory Structure

```
project/
├── .codemap/                    # Codemap data directory
│   ├── graph.db                 # SQLite database
│   ├── vectors.db               # Vector embeddings (SQLite)
│   ├── cache/                   # LLM response cache
│   │   └── summaries.json
│   └── config.yaml              # Project-specific config
└── ...
```

### 8.2 SQLite Schema

```sql
-- graph.db

-- Nodes table
CREATE TABLE nodes (
    id TEXT PRIMARY KEY,
    kind TEXT NOT NULL,
    name TEXT NOT NULL,
    qualified_name TEXT,
    path TEXT NOT NULL,
    line INTEGER,
    end_line INTEGER,
    language TEXT,
    signature TEXT,
    doc_string TEXT,
    is_exported INTEGER DEFAULT 0,
    complexity INTEGER,
    loc INTEGER,
    summary TEXT,
    properties TEXT,  -- JSON
    updated_at TEXT DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX idx_nodes_kind ON nodes(kind);
CREATE INDEX idx_nodes_path ON nodes(path);
CREATE INDEX idx_nodes_name ON nodes(name);

-- Edges table
CREATE TABLE edges (
    id TEXT PRIMARY KEY,
    from_id TEXT NOT NULL REFERENCES nodes(id),
    to_id TEXT NOT NULL REFERENCES nodes(id),
    kind TEXT NOT NULL,
    line INTEGER,
    weight REAL DEFAULT 1.0,
    count INTEGER DEFAULT 1,
    properties TEXT,  -- JSON
    UNIQUE(from_id, to_id, kind)
);

CREATE INDEX idx_edges_from ON edges(from_id);
CREATE INDEX idx_edges_to ON edges(to_id);
CREATE INDEX idx_edges_kind ON edges(kind);

-- Metadata table
CREATE TABLE metadata (
    key TEXT PRIMARY KEY,
    value TEXT
);

-- vectors.db

-- Embeddings table
CREATE TABLE embeddings (
    node_id TEXT PRIMARY KEY REFERENCES nodes(id),
    embedding BLOB NOT NULL,  -- float32 array as bytes
    model TEXT,
    created_at TEXT DEFAULT CURRENT_TIMESTAMP
);
```

### 8.3 Graph Serialization (Performance Critical)

> **Problem**: Loading 100k+ nodes from SQLite into `map[string]*Node` at every CLI invocation is slow.
> **Solution**: Binary serialization of the in-memory graph for fast loading.

```go
// graph/serialize.go

import (
    "encoding/gob"
    "os"
)

// SerializedGraph is the on-disk binary format
type SerializedGraph struct {
    Version   string
    Checksum  string              // Hash of file list for validation
    Graph     *CodeGraph
    CreatedAt time.Time
}

// SaveBinary serializes the graph to a fast-loading binary format
func (g *CodeGraph) SaveBinary(path string) error {
    file, _ := os.Create(path)
    defer file.Close()

    sg := &SerializedGraph{
        Version:   "1.0",
        Checksum:  g.computeChecksum(),
        Graph:     g,
        CreatedAt: time.Now(),
    }

    encoder := gob.NewEncoder(file)
    return encoder.Encode(sg)
}

// LoadBinary loads the graph from binary format (much faster than SQLite rebuild)
func LoadBinary(path string) (*CodeGraph, error) {
    file, err := os.Open(path)
    if err != nil {
        return nil, err
    }
    defer file.Close()

    var sg SerializedGraph
    decoder := gob.NewDecoder(file)
    if err := decoder.Decode(&sg); err != nil {
        return nil, err
    }

    return sg.Graph, nil
}
```

#### File Structure with Binary Cache

```
project/
└── .codemap/
    ├── graph.db          # SQLite - source of truth
    ├── graph.gob         # Binary cache - fast loading
    ├── graph.checksum    # File list hash for validation
    ├── vectors.db        # Embeddings
    └── cache/            # LLM responses
```

#### Loading Strategy

```go
// graph/loader.go

func LoadGraph(root string) (*CodeGraph, error) {
    dataDir := filepath.Join(root, ".codemap")
    gobPath := filepath.Join(dataDir, "graph.gob")
    dbPath := filepath.Join(dataDir, "graph.db")

    // 1. Try binary cache first (fast path: ~50ms for 100k nodes)
    if graph, err := LoadBinary(gobPath); err == nil {
        // Validate checksum
        if graph.isValid(root) {
            return graph, nil
        }
        // Checksum mismatch - cache is stale
    }

    // 2. Fallback to SQLite rebuild (slow path: ~2-5s for 100k nodes)
    graph, err := LoadFromSQLite(dbPath)
    if err != nil {
        return nil, err
    }

    // 3. Update binary cache for next time
    graph.SaveBinary(gobPath)

    return graph, nil
}
```

### 8.4 Index Validation (Fast Staleness Check)

> **Goal**: `codemap index` should return in milliseconds if nothing changed.

> **Optimization**: Reuse `scanner.ScanFiles()` output for manifest computation to avoid
> duplicate disk I/O. The existing `ScanFiles` already captures Size and ModTime.

```go
// graph/checksum.go

import (
    "crypto/sha256"
    "encoding/hex"
    "sort"

    "codemap/scanner"
)

// FileManifest captures file state for change detection
type FileManifest struct {
    Files map[string]FileState `json:"files"`
    Hash  string               `json:"hash"`
}

type FileState struct {
    Size    int64  `json:"size"`
    ModTime int64  `json:"mtime"`
}

// ComputeManifestFromScan builds manifest from existing ScanFiles output
// This is the preferred method - avoids duplicate filesystem traversal
func ComputeManifestFromScan(files []*scanner.FileInfo) *FileManifest {
    manifest := &FileManifest{Files: make(map[string]FileState, len(files))}
    for _, f := range files {
        manifest.Files[f.Path] = FileState{
            Size:    f.Size,
            ModTime: f.ModTime.Unix(),
        }
    }
    manifest.Hash = manifest.computeHash()
    return manifest
}

func (m *FileManifest) computeHash() string {
    // Sort paths for deterministic hash
    paths := make([]string, 0, len(m.Files))
    for p := range m.Files {
        paths = append(paths, p)
    }
    sort.Strings(paths)

    h := sha256.New()
    for _, p := range paths {
        f := m.Files[p]
        h.Write([]byte(fmt.Sprintf("%s:%d:%d\n", p, f.Size, f.ModTime)))
    }
    return hex.EncodeToString(h.Sum(nil))
}

// Optimized indexing flow:
//
// 1. Load stored hash from .codemap/graph.checksum (instant)
// 2. Run scanner.ScanFiles() (required for indexing anyway)
// 3. Compute manifest hash from scan output (in-memory only)
// 4. Compare hashes:
//    - Match: Load cached graph.gob (~50ms), return immediately
//    - Mismatch: Continue with full indexing

// IsGraphStale checks if re-indexing is needed (fast path)
func IsGraphStale(root string, storedHash string) (bool, []*scanner.FileInfo, error) {
    // ScanFiles is O(files), but required for indexing anyway
    files, err := scanner.ScanFiles(root)
    if err != nil {
        return true, nil, err
    }

    manifest := ComputeManifestFromScan(files)
    isStale := manifest.Hash != storedHash

    // Return files so caller can reuse them for indexing if needed
    return isStale, files, nil
}
```

#### SQLite Metadata Table

```sql
-- Add to graph.db schema
CREATE TABLE metadata (
    key TEXT PRIMARY KEY,
    value TEXT
);

-- Stored values:
-- 'manifest_hash': SHA256 of file manifest
-- 'indexed_at': Timestamp of last full index
-- 'version': Codemap version that created the index
-- 'node_count': Quick stats
-- 'edge_count': Quick stats
```

#### Fast Index Check

```go
// index_project tool - fast path
func handleIndexProject(ctx context.Context, req *mcp.CallToolRequest, input IndexProjectInput) {
    // 1. Check if re-index is needed (~10-50ms)
    storedHash := getMetadata(input.Path, "manifest_hash")
    isStale, _ := IsGraphStale(input.Path, storedHash)

    if !isStale && !input.Force {
        // Return immediately - no work needed
        return textResult("Index is up to date"), nil, nil
    }

    // 2. Perform full or incremental index
    // ...
}
```

### 8.5 LLM Response Cache

> **Optimization**: Cache LLM responses in MCP output format for zero-processing retrieval.
> When an agent requests `explain_symbol` for a cached node, return the cached JSON directly.

```go
// analyze/cache.go

type Cache struct {
    dir      string
    ttl      time.Duration
    maxSize  int64
}

// ═══════════════════════════════════════════════════════════════════════════
// Cache entries store pre-formatted MCP output structs
// ═══════════════════════════════════════════════════════════════════════════

type CacheEntry struct {
    Key       string    `json:"key"`
    Type      string    `json:"type"`     // "ExplainSymbolOutput", "SummarizeModuleOutput"
    Data      []byte    `json:"data"`     // JSON-encoded MCP output struct
    CreatedAt time.Time `json:"created"`
    NodeHash  string    `json:"hash"`     // For invalidation check
}

// Store saves an MCP output struct directly
func (c *Cache) Store(key string, output any) error {
    data, _ := json.Marshal(output)
    entry := CacheEntry{
        Key:       key,
        Type:      reflect.TypeOf(output).Name(),
        Data:      data,
        CreatedAt: time.Now(),
    }
    return c.write(key, entry)
}

// LoadExplainSymbol returns cached ExplainSymbolOutput or nil
// Returns the struct directly - no LLM call or processing needed
func (c *Cache) LoadExplainSymbol(nodeID string) (*ExplainSymbolOutput, bool) {
    entry, ok := c.load(summaryKey(nodeID))
    if !ok {
        return nil, false
    }
    var output ExplainSymbolOutput
    json.Unmarshal(entry.Data, &output)
    return &output, true
}

// Example usage in MCP handler:
//
// func handleExplainSymbol(input ExplainSymbolInput) (*ExplainSymbolOutput, error) {
//     nodeID := resolveNodeID(input.Path, input.Symbol)
//
//     // Fast path: return cached result directly
//     if cached, ok := cache.LoadExplainSymbol(nodeID); ok {
//         return cached, nil  // Zero LLM latency
//     }
//
//     // Slow path: generate and cache
//     output := summarizer.Explain(node, context)
//     cache.Store(summaryKey(nodeID), output)
//     return output, nil
// }

// Cache keys
func summaryKey(nodeID string) string   { return "summary:" + nodeID }
func embeddingKey(nodeID string) string { return "embed:" + nodeID }
func queryKey(query string) string      { return "query:" + hash(query) }

// Invalidation (triggered by file change detection)
func (c *Cache) InvalidateFile(path string)        // When file changes
func (c *Cache) InvalidateNode(nodeID string)      // When node changes
func (c *Cache) InvalidateAll()                    // Full clear
```

---

## 9. Implementation Phases

### Priority Guidelines

> **Critical Insight**: LLMs interact better with **natural language search** (semantic) than with
> **structured query syntax** (Cypher-like). Prioritize accordingly.

| Priority | Feature | Rationale |
|----------|---------|-----------|
| **P0 (Must Have)** | `semantic_search` | Most valuable for LLM agents |
| **P0 (Must Have)** | `index_project` | Required for everything else |
| **P1 (High)** | `explain_symbol` | High-value LLM integration |
| **P1 (High)** | `impact_analysis` | Practical for developers |
| **P2 (Medium)** | `query_graph` | Power users only |
| **P2 (Medium)** | `trace_path` | Useful but niche |
| **P3 (Low)** | `find_cycles` | Nice to have |

**Risk Mitigation**: If Phase 1 takes longer than expected, **protect Phase 3** (Semantic Search).
Consider shipping a minimal Phase 1 (just indexing + basic queries) and jump to Phase 3 for
semantic search, then backfill advanced graph features.

---

### Phase 1: Knowledge Graph Foundation (v3.0)

**Duration**: ~2-3 weeks
**Goal**: Build graph infrastructure without LLM dependency
**Risk Level**: Medium (Tree-sitter call extraction complexity)

#### Tasks

1. **Graph Types and Builder** (`graph/`)
   - [ ] Define Node and Edge types
   - [ ] Implement CodeGraph structure with indexes
   - [ ] Create GraphBuilder from FileAnalysis
   - [ ] Add node ID generation strategy

2. **Call Extraction** (`scanner/`)
   - [ ] Add tree-sitter queries for function calls (consolidated per language)
   - [ ] Extend FileAnalysis with Calls field
   - [ ] Handle method calls and receivers
   - [ ] Capture argument count (arity) at call sites
   - [ ] Support 16 languages

3. **Edge Validation** (`graph/validate.go`) - False Positive Mitigation
   - [ ] Implement ImportGraphFilter (eliminate cross-package false positives)
   - [ ] Implement ArityFilter (eliminate arity mismatches)
   - [ ] Integrate filters into GraphBuilder.buildCallEdges()
   - [ ] Apply CallConfidence weights based on syntactic patterns

4. **Storage Layer** (`graph/`)
   - [ ] Implement SQLite storage
   - [ ] Implement in-memory storage
   - [ ] Add migration support
   - [ ] Create storage interface

4. **Query Engine** (`graph/`)
   - [ ] Implement basic query DSL
   - [ ] Add graph traversal methods
   - [ ] Implement path finding
   - [ ] Add cycle detection

5. **MCP Tools - Graph** (`mcp/`)
   - [ ] `index_project` tool
   - [ ] `query_graph` tool
   - [ ] `trace_path` tool
   - [ ] `find_cycles` tool
   - [ ] `impact_analysis` tool

6. **CLI Commands** (`main.go`)
   - [ ] `codemap index` command
   - [ ] `codemap query` command
   - [ ] `codemap impact` command
   - [ ] `codemap cycles` command

#### Deliverables
- Graph database with nodes and edges
- 5 new MCP tools (graph-based)
- 4 new CLI commands
- No external dependencies (pure Go)

---

### Phase 2: LLM Integration (v3.1)

**Duration**: ~2 weeks
**Goal**: Add LLM-powered analysis

#### Tasks

1. **LLM Client Layer** (`analyze/`)
   - [ ] Define LLMClient interface
   - [ ] Implement OllamaClient
   - [ ] Implement OpenAIClient (optional)
   - [ ] Add retry and timeout handling

2. **Summarization** (`analyze/`)
   - [ ] Implement Summarizer
   - [ ] Create prompt templates
   - [ ] Add summary caching
   - [ ] Handle batch summarization

3. **Configuration** (`config/`)
   - [ ] Create config file structure
   - [ ] Support YAML configuration
   - [ ] Environment variable overrides
   - [ ] Sensible defaults (no LLM required)

4. **MCP Tools - LLM** (`mcp/`)
   - [ ] `explain_symbol` tool
   - [ ] `summarize_module` tool

5. **CLI Commands**
   - [ ] `codemap explain` command
   - [ ] `codemap summarize` command
   - [ ] `--insights` flag for tree view

6. **Graceful Degradation**
   - [ ] Detect LLM availability
   - [ ] Fallback to structural-only mode
   - [ ] Clear error messages

#### Deliverables
- Ollama integration
- 2 new MCP tools (LLM-based)
- 2 new CLI commands
- Configuration system

---

### Phase 3: Hybrid Retrieval (v3.2)

**Duration**: ~2 weeks
**Goal**: Combine semantic and structural search

#### Tasks

1. **Embedding System** (`analyze/`)
   - [ ] Implement Embedder
   - [ ] Add vector storage (SQLite)
   - [ ] Batch embedding generation
   - [ ] Embedding cache

2. **Vector Index** (`graph/`)
   - [ ] Implement cosine similarity search
   - [ ] Add approximate nearest neighbors (optional)
   - [ ] Support filtering during search

3. **Hybrid Retriever** (`analyze/`)
   - [ ] Implement HybridRetriever
   - [ ] Merge semantic + structural results
   - [ ] Implement re-ranking
   - [ ] Graph expansion for context

4. **MCP Tools - Hybrid** (`mcp/`)
   - [ ] `semantic_search` tool
   - [ ] Enhance existing tools with semantic awareness

5. **CLI Commands**
   - [ ] `codemap search` command
   - [ ] Natural language queries

#### Deliverables
- Vector embeddings for code
- Semantic search capability
- 1 new MCP tool
- Hybrid retrieval system

---

### Phase 4: Advanced Features (v3.3)

**Duration**: ~2 weeks
**Goal**: Polish and advanced capabilities

#### Tasks

1. **Pattern Detection** (`analyze/`)
   - [ ] Implement PatternDetector
   - [ ] Heuristic detection
   - [ ] LLM-enhanced detection

2. **Complexity Metrics** (`scanner/`)
   - [ ] Cyclomatic complexity
   - [ ] Cognitive complexity
   - [ ] LOC counting

3. **Visualization** (`render/`)
   - [ ] GraphViz DOT output
   - [ ] Interactive graph view (optional)
   - [ ] Complexity heatmap

4. **Incremental Updates**
   - [ ] Watch mode for graph updates
   - [ ] Delta indexing
   - [ ] Smart invalidation

5. **Documentation**
   - [ ] Update README
   - [ ] API documentation
   - [ ] Examples and tutorials

#### Deliverables
- Pattern detection
- Complexity metrics
- Visualization options
- Production-ready system

---

## 10. Performance Considerations

### 10.1 Benchmarks

| Operation | Target | Strategy |
|-----------|--------|----------|
| Full index (10k files) | < 30s | Parallel scanning, batch inserts |
| Incremental index | < 5s | Delta detection, targeted updates |
| Index staleness check | < 50ms | Manifest hash comparison |
| Graph load (from gob) | < 100ms | Binary serialization cache |
| Graph load (from SQLite) | < 3s | Fallback when cache invalid |
| Graph query | < 100ms | In-memory indexes, query optimization |
| Semantic search | < 500ms | Pre-computed embeddings, ANN |
| LLM summarization | < 2s | Caching, async generation |

### 10.2 Performance Targets by Project Size

| Project Size | Files | Expected Index Time | Graph Load Time |
|--------------|-------|---------------------|-----------------|
| Small | < 100 | < 2s | < 10ms |
| Medium | 100-1k | < 10s | < 30ms |
| Large | 1k-10k | < 30s | < 100ms |
| Very Large | 10k-100k | < 2min | < 500ms |

> **Note**: Very large projects (>50k files) should use streaming mode
> to avoid memory pressure during indexing.

### 10.3 Memory Management

```go
// Large project handling
type IndexOptions struct {
    MaxConcurrency int      // Limit parallel file processing
    BatchSize      int      // DB insert batch size
    StreamMode     bool     // Process files without full graph in memory
}

// For projects > 50k files
func (b *GraphBuilder) BuildStreaming(root string, opts IndexOptions) error
```

### 10.4 Caching Strategy

```
┌─────────────────────────────────────────────────────────────┐
│                      Cache Layers                            │
├─────────────────────────────────────────────────────────────┤
│  L1: In-Memory (hot data)                                   │
│      • Recent query results                                 │
│      • Active node data                                     │
│      • TTL: session                                         │
├─────────────────────────────────────────────────────────────┤
│  L2: SQLite (warm data)                                     │
│      • Graph structure                                      │
│      • Embeddings                                           │
│      • TTL: until file change                               │
├─────────────────────────────────────────────────────────────┤
│  L3: File Cache (cold data)                                 │
│      • LLM responses                                        │
│      • Generated summaries                                  │
│      • TTL: configurable (default 24h)                      │
└─────────────────────────────────────────────────────────────┘
```

---

## 11. Testing Strategy

### 11.1 Test Categories

```go
// Unit tests
graph/builder_test.go      // Graph construction
graph/query_test.go        // Query execution
graph/algorithms_test.go   // Graph algorithms
analyze/summarizer_test.go // Summarization (mocked LLM)
analyze/retriever_test.go  // Retrieval logic

// Integration tests
integration/index_test.go    // Full indexing flow
integration/mcp_test.go      // MCP tool handlers
integration/cli_test.go      // CLI commands

// Benchmark tests
bench/large_project_test.go  // Performance on large codebases
bench/query_perf_test.go     // Query performance
```

### 11.2 Test Projects

```
testdata/
├── small/           # 10 files, basic structure
├── medium/          # 100 files, multiple packages
├── large/           # 1000 files, complex dependencies
├── multilang/       # Mixed languages
└── cycles/          # Intentional circular dependencies
```

### 11.3 Manual Testing Checklist

- [ ] Index codemap itself
- [ ] Index a large open-source project (kubernetes, vscode)
- [ ] Test all MCP tools via Claude Desktop
- [ ] Test CLI commands
- [ ] Test without LLM configured
- [ ] Test with Ollama
- [ ] Test incremental updates

---

## 12. Migration Path

### 12.1 Backward Compatibility

- All existing CLI flags continue to work
- All existing MCP tools continue to work
- New features are additive
- LLM features are opt-in

### 12.2 Version Strategy

| Version | Features | Breaking Changes |
|---------|----------|------------------|
| v3.0 | Graph foundation | None |
| v3.1 | LLM integration | None |
| v3.2 | Hybrid retrieval | None |
| v3.3 | Advanced features | None |

### 12.3 Configuration Migration

```yaml
# ~/.config/codemap/config.yaml (NEW)
# If not present, all defaults apply and LLM is disabled

# v3.0 - Graph only, no config needed
# v3.1+ - Optional LLM config
llm:
  provider: ollama
  model: qwen2.5-coder:1.5b
  embed_model: nomic-embed-text
  endpoint: http://localhost:11434
  timeout: 30s

graph:
  storage: sqlite  # or "memory"
  cache_dir: .codemap

analysis:
  auto_summarize: false  # Generate summaries on index
  embed_on_index: false  # Generate embeddings on index
```

---

## Appendix A: Tree-sitter Query Architecture

### Query Consolidation Strategy

> **Design Decision**: All symbol extractions (Functions, Types, Calls, Imports) should be
> consolidated into a **single query file per language** rather than multiple separate files.

**Rationale:**
1. **Performance**: A single query execution is faster than multiple sequential queries
2. **Maintenance**: One file per language is easier to maintain than N files per language
3. **Atomicity**: All symbols from a file are extracted in one pass

**File Structure:**
```
scanner/queries/
├── go.scm          # All Go captures: @func, @type, @call, @import
├── python.scm      # All Python captures
├── typescript.scm  # All TS/JS captures
└── ...
```

**Capture Naming Convention:**
```scheme
; Functions/Methods
@func.name @func.params @func.return @func.receiver

; Types/Classes
@type.name @type.fields @type.methods

; Calls (with confidence classification)
@call.name @call.receiver @call.package @call.confidence

; Imports
@import.name @import.alias @import.path
```

The `GraphBuilder` transforms these captures into typed `Node` and `Edge` structures,
applying the call confidence heuristics defined in Section 3.2.

---

### Go Query Example

```scheme
; scanner/queries/go_calls.scm

; Direct function calls
(call_expression
  function: (identifier) @call.name)

; Method calls
(call_expression
  function: (selector_expression
    operand: (_) @call.receiver
    field: (field_identifier) @call.name))

; Package-qualified calls
(call_expression
  function: (selector_expression
    operand: (identifier) @call.package
    field: (identifier) @call.name))
```

### Python

```scheme
; scanner/queries/python_calls.scm

; Direct function calls
(call
  function: (identifier) @call.name)

; Method calls
(call
  function: (attribute
    object: (_) @call.receiver
    attribute: (identifier) @call.name))
```

### TypeScript/JavaScript

```scheme
; scanner/queries/typescript_calls.scm

; Direct function calls
(call_expression
  function: (identifier) @call.name)

; Method calls
(call_expression
  function: (member_expression
    object: (_) @call.receiver
    property: (property_identifier) @call.name))
```

---

## Appendix B: Example Outputs

### index_project Output

```
╭───────────────────────────── codemap index ─────────────────────────────╮
│ Project: my-app                                                          │
│ Status: Complete                                                         │
├──────────────────────────────────────────────────────────────────────────┤
│ Files scanned:     1,234                                                 │
│ Nodes created:    12,456                                                 │
│ Edges created:    34,567                                                 │
│ Languages:        Go, TypeScript, Python                                 │
│ Duration:         4.2s                                                   │
├──────────────────────────────────────────────────────────────────────────┤
│ Node breakdown:                                                          │
│   Functions:      4,521                                                  │
│   Types:          1,234                                                  │
│   Methods:        3,456                                                  │
│   Files:          1,234                                                  │
│   Packages:         89                                                   │
├──────────────────────────────────────────────────────────────────────────┤
│ Edge breakdown:                                                          │
│   CALLS:         15,678                                                  │
│   IMPORTS:        2,345                                                  │
│   CONTAINS:       8,901                                                  │
│   IMPLEMENTS:       234                                                  │
╰──────────────────────────────────────────────────────────────────────────╯
```

### impact_analysis Output

```
╭─────────────────────── Impact Analysis ───────────────────────╮
│ Symbol: UserRepository.Save                                    │
│ Location: repos/user.go:45                                     │
├────────────────────────────────────────────────────────────────┤
│ Risk Level: HIGH                                               │
│ Total Affected: 23 symbols                                     │
├────────────────────────────────────────────────────────────────┤
│ Direct Impact (depth 1):                                       │
│   ├── UserService.Create      services/user.go:78    [CALLS]  │
│   ├── UserService.Update      services/user.go:112   [CALLS]  │
│   ├── AdminService.BulkCreate services/admin.go:45   [CALLS]  │
│   └── UserRepo_test.TestSave  repos/user_test.go:23  [CALLS]  │
├────────────────────────────────────────────────────────────────┤
│ Indirect Impact (depth 2+):                                    │
│   ├── UserController.Create   api/user.go:34         [d=2]    │
│   ├── UserController.Update   api/user.go:67         [d=2]    │
│   ├── AdminController.Import  api/admin.go:89        [d=2]    │
│   └── ... 16 more                                              │
├────────────────────────────────────────────────────────────────┤
│ Summary:                                                       │
│ This function is a critical data persistence point. Changes    │
│ will affect 3 services and 4 API endpoints. Ensure thorough    │
│ testing of user creation and update flows.                     │
╰────────────────────────────────────────────────────────────────╯
```

### semantic_search Output

```
╭──────────────────── Semantic Search Results ────────────────────╮
│ Query: "where is user authentication handled"                   │
│ Results: 8 matches                                              │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│ 1. auth/middleware.go:23 - ValidateJWT()         Score: 0.94   │
│    Function that validates JWT tokens from request headers.     │
│    Related: AuthService.Login, UserController.*                 │
│                                                                 │
│ 2. auth/service.go:45 - AuthService.Login()      Score: 0.91   │
│    Authenticates user credentials and issues JWT token.         │
│    Related: UserRepository.FindByEmail, ValidateJWT             │
│                                                                 │
│ 3. api/handlers/auth.go:12 - HandleLogin()       Score: 0.87   │
│    HTTP handler for /api/login endpoint.                        │
│    Related: AuthService.Login, ValidateRequest                  │
│                                                                 │
│ 4. config/security.go:5 - JWTConfig              Score: 0.82   │
│    Configuration struct for JWT settings.                       │
│    Related: ValidateJWT, AuthService                            │
│                                                                 │
│ ... 4 more results                                              │
╰─────────────────────────────────────────────────────────────────╯
```

---

## Appendix C: Configuration Reference

```yaml
# ~/.config/codemap/config.yaml

# LLM Configuration
llm:
  # Provider: "ollama", "openai", "anthropic", "none"
  provider: ollama

  # Model for text generation
  model: qwen2.5-coder:1.5b

  # Model for embeddings
  embed_model: nomic-embed-text

  # API endpoint (for ollama/openai-compatible)
  endpoint: http://localhost:11434

  # API key (for openai/anthropic)
  api_key: ${OPENAI_API_KEY}

  # Request timeout
  timeout: 30s

  # Temperature for generation
  temperature: 0.1

# Graph Configuration
graph:
  # Storage backend: "sqlite", "memory"
  storage: sqlite

  # Data directory (relative to project or absolute)
  data_dir: .codemap

  # Maximum nodes to keep in memory cache
  cache_size: 10000

# Analysis Configuration
analysis:
  # Generate summaries during indexing
  auto_summarize: false

  # Generate embeddings during indexing
  embed_on_index: false

  # Maximum depth for impact analysis
  max_impact_depth: 5

  # Cache TTL for LLM responses
  cache_ttl: 24h

# Indexing Configuration
index:
  # File patterns to exclude (in addition to .gitignore)
  exclude:
    - "vendor/**"
    - "node_modules/**"
    - "**/*_test.go"
    - "**/*.min.js"

  # Maximum file size to process (bytes)
  max_file_size: 1048576  # 1MB

  # Maximum files to process
  max_files: 100000

  # Concurrent file processing
  concurrency: 8

# Output Configuration
output:
  # Default output format: "text", "json"
  format: text

  # Enable colors
  colors: true

  # Maximum width for text output
  max_width: 120
```

---

## Appendix D: Dependencies

### Required (Phase 1)
```go
// go.mod additions for Phase 1
require (
    github.com/mattn/go-sqlite3 v1.14.x  // SQLite driver
)
```

### Optional (Phase 2+)
```go
// go.mod additions for Phase 2+
require (
    github.com/ollama/ollama v0.x.x      // Ollama client (or HTTP)
    gopkg.in/yaml.v3 v3.0.x              // YAML config
)
```

### No External Graph Database Required
The implementation uses SQLite for persistence, avoiding the need for Neo4j, Memgraph, or other external graph databases. This keeps codemap lightweight and zero-dependency for users.

---

*Document Version: 1.0*
*Last Updated: 2024*
*Status: Ready for Implementation*
</file>
<file path="README.md">
# codemap: Codebase Analysis and Visualization Tool

## Project Overview

**codemap** is a powerful command-line interface (CLI) tool written in Go designed to analyze, map, and visualize the structure and dependencies of a codebase. It provides developers and automated systems (like LLM agents) with a clear, structured view of a project's architecture without needing to manually traverse the source code.

### Purpose and Main Functionality
The primary purpose of `codemap` is to transform raw source code into structured data models (`Project`, `DepsProject`) that can be consumed for various purposes, including:
1.  **Visualization:** Generating hierarchical file trees, "city skyline" representations of file complexity, and dependency graphs.
2.  **Context Generation:** Providing detailed, structured JSON output of a codebase's structure, functions, types, and imports, which is ideal for feeding into Large Language Models (LLMs) for context-aware tasks.
3.  **Change Impact Analysis:** Identifying and analyzing only the files that have changed relative to a Git reference, allowing for focused analysis and visualization.

### Key Features and Capabilities
*   **Multi-Mode Analysis:** Supports Tree View, Skyline View, Dependency Graph, and Public API View.
*   **Deep Code Parsing:** Uses **Tree-sitter** grammars for language-aware parsing to extract functions, types, and imports with configurable detail levels.
*   **Git Integration:** Respects `.gitignore` rules and performs Git diff analysis to focus on changed files.
*   **Machine-Readable Output:** Can output all analysis results as structured JSON for programmatic consumption.
*   **Model Context Protocol (MCP) Server:** Includes an optional server mode to expose its capabilities as tools for LLM agents.

### Likely Intended Use Cases
*   **Developer Onboarding:** Quickly generating a visual map of a new codebase.
*   **Code Review:** Analyzing the structural impact and dependencies of a pull request (`--diff` mode).
*   **LLM Tooling:** Serving as a reliable, structured data source for AI-powered code analysis and generation tools.
*   **Architectural Audits:** Mapping internal and external dependencies to identify coupling issues.

## Table of Contents
1.  [Project Overview](#project-overview)
2.  [Architecture](#architecture)
3.  [C4 Model Architecture](#c4-model-architecture)
4.  [Repository Structure](#repository-structure)
5.  [Dependencies and Integration](#dependencies-and-integration)
6.  [API Documentation](#api-documentation)
7.  [Development Notes](#development-notes)
8.  [Known Issues and Limitations](#known-issues-and-limitations)
9.  [Additional Documentation](#additional-documentation)

## Architecture

The `codemap` application follows a clear **Layered Architecture** or **Pipeline Pattern**, ensuring a strong separation of concerns between data acquisition, core logic, and presentation.

### High-level Architecture Overview
The execution flow is strictly unidirectional:

1.  **Control/Orchestration Layer (`main`):** Parses CLI flags and determines the execution mode.
2.  **Data Acquisition/Analysis Layer (`scanner`):** Performs all I/O (file system, Git) and core domain logic (Tree-sitter parsing, data modeling).
3.  **Presentation Layer (`render`):** Consumes the structured data models from the `scanner` and formats them for terminal output (TUI) or JSON serialization.

### Technology Stack and Frameworks
| Component | Technology | Purpose |
| :--- | :--- | :--- |
| **Core Language** | Go | Primary development language. |
| **Code Parsing** | Tree-sitter | Language-agnostic parsing engine for deep code analysis. |
| **C Interface** | `github.com/ebitengine/purego` | Used to interface with the Tree-sitter C libraries without Cgo. |
| **Terminal UI** | `github.com/charmbracelet/bubbletea` | Framework for building rich, interactive terminal user interfaces (TUI), used for Skyline and Depgraph visualizations. |
| **Git Integration** | `github.com/sabhiram/go-gitignore` | Used for loading and applying `.gitignore` rules. |
| **Server Mode** | `github.com/modelcontextprotocol/go-sdk` | Used to implement the Model Context Protocol (MCP) server. |

### Component Relationships (with mermaid diagrams)

The following diagram illustrates the high-level flow of control and data between the core internal packages.

```mermaid
graph LR
    subgraph Orchestration
        A[main Package (CLI Entry)]
        B[mcp/main Package (Server Entry)]
    end

    subgraph Core Logic
        C[scanner Package]
        D[scanner/types.go (Data Models)]
    end

    subgraph Presentation
        E[render Package]
    end

    A --> C : Calls Scan/Analyze
    B --> C : Calls Scan/Analyze
    C --> D : Defines/Populates Data Models
    A --> E : Passes Data Models for Output
    B --> E : Passes Data Models for Output
    E .-> D : Consumes Data Models (Project, DepsProject)

    style C fill:#ccf,stroke:#333,stroke-width:2px
    style E fill:#f9f,stroke:#333,stroke-width:2px
    style A fill:#afa,stroke:#333
    style B fill:#afa,stroke:#333
    style D fill:#eee,stroke:#999
```

### Key Design Patterns
*   **Data Transfer Object (DTO) Pattern:** The `scanner/types.go` structs (`Project`, `DepsProject`, `FileInfo`, etc.) act as pure data containers, defining the contract between the `scanner` and `render` layers.
*   **Strategy Pattern (Implicit):** The `main` function selects the appropriate rendering strategy (`render.Tree`, `render.Skyline`, `render.Depgraph`) based on the user's CLI flags.
*   **Adapter Pattern (Implicit):** The `scanner` package acts as an adapter, translating the language-agnostic Abstract Syntax Tree (AST) output from the Tree-sitter C libraries into the application's canonical Go DTOs.

## C4 Model Architecture

### <details><summary>Context Diagram (Level 1)</summary>

```mermaid
C4Context
    title Context Diagram for codemap
    Person(developer, "Developer/User", "Interacts with the tool via CLI to analyze code.")
    Person(llm_agent, "LLM Agent", "Consumes analysis data via the MCP server.")
    System(codemap, "codemap", "Codebase Analysis and Visualization Tool. Generates structural and dependency maps.")
    System_Ext(git, "Code Repository (Git)", "Provides file history, diff information, and ignore rules.")
    System_Ext(filesystem, "Local File System", "Source of all code files and project structure.")

    developer --> codemap : Executes commands (CLI)
    llm_agent --> codemap : Requests analysis (MCP Protocol)
    codemap --> git : Reads diffs and ignore rules
    codemap --> filesystem : Scans and reads source files
```
</details>

### <details><summary>Container Diagram (Level 2)</summary>

```mermaid
C4Container
    title Container Diagram for codemap
    System_Boundary(codemap_system, "codemap")
        Container(cli, "CLI Application", "Go Executable", "Handles command-line arguments and orchestrates analysis/rendering.")
        Container(mcp_server, "MCP Server", "Go Executable (mcp/main)", "Exposes core functionality as tools via the Model Context Protocol.")
        Container(scanner, "Scanner Package", "Go Library (scanner)", "Core logic: file traversal, Git integration, Tree-sitter parsing, data modeling.")
        Container(renderer, "Renderer Package", "Go Library (render)", "Presentation layer: formats data for TUI (Tree, Skyline, Depgraph) or JSON output.")
    System_Boundary(codemap_system)

    System_Ext(git, "Git", "Provides diff and ignore data.")
    System_Ext(terminal, "Terminal/TUI", "Displays visual output (Tree, Skyline, Depgraph).")
    System_Ext(llm_agent, "LLM Agent", "Consumes structured data.")
    System_Ext(grammars, "Tree-sitter Grammars", "C Libraries/Data", "Language-specific parsing rules.")

    cli --> scanner : Calls analysis functions
    cli --> renderer : Passes Project/DepsProject for output
    mcp_server --> scanner : Calls analysis functions
    mcp_server --> renderer : Passes Project/DepsProject for output

    scanner --> git : Reads repository state
    scanner --> grammars : Loads language parsing logic (via purego)

    renderer --> terminal : Renders TUI/Text output (via bubbletea)
    mcp_server --> llm_agent : Serves JSON analysis (MCP Protocol)
```
</details>

## Repository Structure

| Directory/File | Purpose |
| :--- | :--- |
| `/` | Contains the main application entry point (`main.go`) and configuration files. |
| `/scanner` | **Core Logic:** Houses the analysis engine, including file system traversal, Git integration, Tree-sitter parsing, and all core data models (`types.go`). |
| `/render` | **Presentation Layer:** Contains logic for all visualization modes (Tree, Skyline, Depgraph) and terminal formatting. |
| `/mcp` | Contains the entry point (`main.go`) and handlers for the Model Context Protocol (MCP) server implementation. |
| `/development-docs` | Stores detailed planning and technical documentation for feature development. |

## Dependencies and Integration

### Internal Package Dependencies
The project maintains a clear, hierarchical dependency structure:

| Package | Depends On | Nature of Dependency |
| :--- | :--- | :--- |
| **main** (`/`) | `scanner`, `render` | Orchestration (Control flow and data passing). |
| **mcp/main** | `scanner`, `render` | Orchestration (Server handlers). |
| **render** | `scanner` | Data Coupling (Consumes data structures like `scanner.Project`). |
| **scanner** | *None* | Highly cohesive core logic module. |

### External Service Integrations
The application integrates with two primary external systems:

1.  **Git:**
    *   The `scanner` package executes Git commands to load `.gitignore` rules (`LoadGitignore`) and calculate file differences (`GitDiffInfo`) against a specified reference branch.
    *   This integration is crucial for performance and for enabling the change impact analysis (`--diff` mode).

2.  **Model Context Protocol (MCP):**
    *   The `mcp/main.go` package implements an MCP server using the `go-sdk`.
    *   This integration allows the `codemap` tool to be called programmatically by LLM agents, exposing its core analysis functions (`get_structure`, `get_dependencies`, `find_symbol`, etc.) as structured tools.

## API Documentation

The `codemap` tool's API is defined by its command-line interface and the structured JSON output it produces when the `--json` flag is used.

### 1. Basic Structure Analysis (Tree/Skyline Mode)

This mode provides basic file metadata, size, and optional diff statistics.

| Attribute | Detail |
| :--- | :--- |
| **Method** | CLI Execution |
| **Path** | `codemap [path] [--skyline] [--diff] --json` |
| **Output Model** | `scanner.Project` |

**Key Request Parameters (Flags):**
| Parameter | Description |
| :--- | :--- |
| `[path]` | The root directory to scan (defaults to `.`). |
| `--skyline` | Enables the skyline visualization mode (TUI output only). |
| `--diff` | Filters the output to only include files changed relative to the Git reference (`--ref`). |
| `--json` | **Required** for machine-readable output. |

**Response Format (`scanner.Project` JSON):**
The response is a JSON object containing project metadata and an array of `FileInfo` objects.

```json
{
  "root": "./src",
  "mode": "tree",
  "files": [
    {
      "path": "file.go",
      "size": 3500,
      "ext": ".go",
      "tokens": 1000,
      "added": 15,
      "removed": 0
    }
  ],
  "impact": [ /* ... ImpactInfo objects if --diff is used */ ]
}
```

### 2. Deep Dependency Analysis (Dependency Graph/API View Mode)

This mode performs deep code parsing to extract structural elements and dependencies.

| Attribute | Detail |
| :--- | :--- |
| **Method** | CLI Execution |
| **Path** | `codemap --deps [path] [--detail N] --json` |
| **Output Model** | `scanner.DepsProject` |

**Key Request Parameters (Flags):**
| Parameter | Description |
| :--- | :--- |
| `--deps` | **Required** to enable deep code analysis mode. |
| `--detail N` | Sets the verbosity of extracted symbols: `0` (names only), `1` (names + signatures), `2` (signatures + type fields). |
| `--api` | Renders a compact view of only public (exported) symbols (TUI output only). |
| `--json` | **Required** for machine-readable output. |

**Response Format (`scanner.DepsProject` JSON):**
The response is a JSON object containing project metadata, an array of `FileAnalysis` objects, and a map of external dependencies.

```json
{
  "root": ".",
  "mode": "deps",
  "detail_level": 1,
  "files": [
    {
      "path": "service/api.go",
      "language": "go",
      "functions": [
        {
          "name": "NewClient",
          "signature": "func NewClient(cfg Config) *Client",
          "exported": true,
          "line": 42
        }
      ],
      "types": [ /* ... TypeInfo objects */ ],
      "imports": [ "fmt", "net/http" ]
    }
  ],
  "external_deps": {
    "github.com/external/lib": [ "service/api.go" ]
  }
}
```

## Development Notes

### Project-Specific Conventions
*   **Explicit Dependency Passing:** The application favors explicit dependency passing (e.g., passing the `GrammarLoader` and `GitIgnore` objects) rather than global state or formal DI containers, which is idiomatic for Go.
*   **Data-Centric Design:** The `scanner` package is designed to be a pure data producer, and the `render` package is a pure data consumer. All communication between layers is via the DTOs defined in `scanner/types.go`.
*   **Error Handling:** Errors are typically handled immediately by printing to `os.Stderr` and exiting with a non-zero status code, as is common for CLI tools.

### Testing Requirements
*   **Unit Testing:** Critical logic within the `scanner` package (e.g., `IsExportedName`, file filtering, token estimation heuristics) requires robust unit tests to ensure correctness across different languages and configurations.
*   **Integration Testing:** End-to-end tests are necessary to verify the entire pipeline, from CLI flag parsing to the final output (both TUI and JSON), especially for complex modes like `--deps` and `--diff`.
*   **Grammar Testing:** The Tree-sitter parsing logic must be tested against various language code snippets to ensure accurate extraction of `FuncInfo` and `TypeInfo` at different `DetailLevel` settings.

### Performance Considerations
*   **Grammar Loading:** The application relies on dynamically loading Tree-sitter grammars via `purego`. The performance of `scanner.NewGrammarLoader()` is critical, and grammar availability is a prerequisite for deep analysis.
*   **File Traversal:** The use of `.gitignore` rules via `scanner.LoadGitignore` is essential for pruning the file system traversal and maintaining performance on large repositories.
*   **Token Estimation:** The current token estimation (`Tokens` field in `FileInfo`) is based on a simple character-per-token heuristic. For more accurate performance analysis, this should be replaced or augmented with language-aware token counting.

## Known Issues and Limitations

*   **Tree-sitter Grammar Management:** The application requires pre-built Tree-sitter grammars to be available in a specific location. If grammars are missing, the `--deps` mode will fail, requiring manual setup by the user.
*   **Brittle Dependency Parsing:** The logic for reading external dependencies (e.g., `go.mod`, `package.json`) is implemented manually within `scanner/deps.go`. This logic is brittle and may break if package manager file formats change or if complex features (like conditional dependencies) are introduced.
*   **Tight TUI Coupling:** The `render` package is heavily coupled to the `charmbracelet/bubbletea` ecosystem. Changing the terminal rendering strategy would require a significant rewrite of the presentation layer.
*   **Incomplete Features:** The `AnalyzeImpact` function is inferred but its full implementation and accuracy, especially for complex dependency chains, may be a source of technical debt or an area for future enhancement.

## Additional Documentation
The following internal documents provide deeper insight into the project's design and future plans:

*   [Enhanced Code Analysis Plan](/development-docs/0001-enhanced-code-analysis-plan.md)
*   [Token Heuristics and Symbol Search Plan](/development-docs/0002-token-heuristics-symbol-search-plan.md)
*   [Project Overview (Internal)](/.serena/memories/project_overview.md)
*   *Note: Additional documentation on the specific implementation details of the Tree-sitter parsing logic would be highly beneficial.*
</file>
<file path="README.pt-br.md">
# codemap 🗺️

> **codemap — um cérebro de projeto para sua IA.**
> Dê aos LLMs contexto arquitetônico instantâneo sem queimar tokens.

![Licença](https://img.shields.io/badge/license-MIT-blue.svg)
![Go](https://img.shields.io/badge/go-1.21+-00ADD8.svg)

![captura de tela do codemap](assets/codemap.png)

## Índice

- [Por que o codemap existe](#por-que-o-codemap-existe)
- [Recursos](#recursos)
- [Como Funciona](#️-como-funciona)
- [Performance](#-performance)
- [Instalação](#instalação)
- [Uso](#uso)
- [Modo Diff](#modo-diff)
- [Modo Fluxo de Dependências](#modo-fluxo-de-dependências)
- [Modo Skyline](#modo-skyline)
- [Linguagens Suportadas](#linguagens-suportadas)
- [Integrações com Claude](#integrações-com-claude)
- [Roadmap](#roadmap)
- [Contribuindo](#contribuindo)
- [Licença](#licença)

## Por que o codemap existe

LLMs modernos são poderosos, mas cegos. Eles conseguem escrever código — mas só depois de você pedir para eles queimarem tokens procurando ou manualmente explicando toda a estrutura do seu projeto.

Isso significa:
*   🔥 **Queimando milhares de tokens**
*   🔁 **Repetindo contexto**
*   📋 **Colando árvores de diretórios**
*   ❓ **Respondendo "onde X está definido?"**

**O codemap resolve isso.**

Um comando → um "mapa cerebral" compacto e estruturado da sua base de código que os LLMs podem entender instantaneamente.

## Recursos

- 🧠 **Saída de Mapa Cerebral**: Visualiza a estrutura da sua base de código em um único bloco colável.
- 📉 **Econômico em Tokens**: Agrupa arquivos e simplifica nomes para economizar espaço vertical.
- ⭐️ **Destaque Inteligente**: Sinaliza automaticamente os 5 maiores arquivos de código fonte.
- 📂 **Achatamento Inteligente**: Mescla diretórios intermediários vazios (ex: `src/main/java`).
- 🎨 **Contexto Rico**: Codificado por cores por linguagem para fácil visualização.
- 🚫 **Redução de Ruído**: Ignora automaticamente `.git`, `node_modules` e assets (imagens, binários).

## ⚙️ Como Funciona

**codemap** é um único binário Go — rápido e sem dependências:
1.  **Scanner**: Atravessa instantaneamente seu diretório, respeitando `.gitignore` e ignorando arquivos indesejados.
2.  **Analisador**: Usa gramáticas tree-sitter para analisar imports/funcções em 16 linguagens.
3.  **Renderizador**: Produz um "mapa cerebral" limpo e denso que é legível por humanos e otimizado para LLMs.

## ⚡ Performance

**codemap** roda instantaneamente mesmo em repositórios grandes (centenas ou milhares de arquivos). Isso o torna ideal para workflows com LLMs — sem lag, sem dança de múltiplas ferramentas.

## Instalação

### Homebrew (macOS/Linux)

```bash
brew tap JordanCoin/tap
brew install codemap
```

### Scoop (Windows)

```powershell
scoop bucket add codemap https://github.com/JordanCoin/scoop-codemap
scoop install codemap
```

### Download do Binário

Binários pré-compilados com suporte completo para `--deps` estão disponíveis para todas as plataformas na [página de Releases](https://github.com/JordanCoin/codemap/releases):

- **macOS**: `codemap-darwin-amd64.tar.gz` (Intel) ou `codemap-darwin-arm64.tar.gz` (Apple Silicon)
- **Linux**: `codemap-linux-amd64.tar.gz` ou `codemap-linux-arm64.tar.gz`
- **Windows**: `codemap-windows-amd64.zip`

```bash
# Exemplo: download e instalação no Linux/macOS
curl -L https://github.com/JordanCoin/codemap/releases/latest/download/codemap-linux-amd64.tar.gz | tar xz
sudo mv codemap-linux-amd64/codemap /usr/local/bin/
sudo mv codemap-linux-amd64/grammars /usr/local/lib/codemap/
```

```powershell
# Exemplo: Windows (PowerShell)
Invoke-WebRequest -Uri "https://github.com/JordanCoin/codemap/releases/latest/download/codemap-windows-amd64.zip" -OutFile codemap.zip
Expand-Archive codemap.zip -DestinationPath C:\codemap
# Adicione C:\codemap\codemap-windows-amd64 ao seu PATH
```

Cada release inclui o binário, gramáticas tree-sitter e arquivos de query para suporte completo ao `--deps`.

### A partir do código fonte

```bash
git clone https://github.com/JordanCoin/codemap.git
cd codemap
go build -o codemap .
```

## Uso

Execute `codemap` em qualquer diretório:

```bash
codemap
```

Ou especifique um caminho:

```bash
codemap /caminho/para/meu/projeto
```

### Exemplo de Uso com IA

**O Caso de Uso Matador:**

1.  Execute o codemap e copie a saída:
    ```bash
    codemap . | pbcopy
    ```

2.  Ou simplesmente diga ao Claude, Codex, ou Cursor:
    > "Use codemap para entender a estrutura do meu projeto."

## Modo Diff

Veja o que você está trabalhando com `--diff`:

```bash
codemap --diff
```

```
╭─────────────────────────── meuprojeto ──────────────────────────╮
│ Alterados: 4 arquivos | +156 -23 linhas vs main                │
│ Principais Extensões: .go (3), .tsx (1)                        │
╰────────────────────────────────────────────────────────────────╯
meuprojeto
├── api/
│   └── (novo) auth.go         ✎ handlers.go (+45 -12)
├── web/
│   └── ✎ Dashboard.tsx (+82 -8)
└── ✎ main.go (+29 -3)

⚠ handlers.go é usado por 3 outros arquivos
⚠ api é usado por 2 outros arquivos
```

**O que mostra:**
- 📊 **Resumo de alterações**: Total de arquivos e linhas alteradas vs branch main
- ✨ **Novo vs modificado**: `(novo)` para arquivos não rastreados, `✎` para modificados
- 📈 **Contagem de linhas**: `(+45 -12)` mostra adições e deleções por arquivo
- ⚠️ **Análise de impacto**: Quais arquivos alterados são importados por outros (usa tree-sitter)

Compare com uma branch diferente:
```bash
codemap --diff --ref develop
```

## Modo Fluxo de Dependências

Veja como seu código se conecta com `--deps`:

```bash
codemap --deps /caminho/para/projeto
```

```
╭──────────────────────────────────────────────────────────────╮
│                   MyApp - Fluxo de Dependências              │
├──────────────────────────────────────────────────────────────┤
│ Go: chi, zap, testify                                        │
│ Py: fastapi, pydantic, httpx                                 │
╰──────────────────────────────────────────────────────────────╯

Backend ════════════════════════════════════════════════════
  server ───▶ validate ───▶ rules, config
  api ───▶ handlers, middleware

Frontend ═══════════════════════════════════════════════════
  App ──┬──▶ Dashboard
        ├──▶ Settings
        └──▶ api

HUBS: config (12←), api (8←), utils (5←)
45 arquivos · 312 funções · 89 deps
```

**O que mostra:**
- 📦 **Dependências externas** agrupadas por linguagem (de go.mod, requirements.txt, package.json, etc.)
- 🔗 **Cadeias de dependência internas** mostrando como os arquivos importam uns aos outros
- 🎯 **Arquivos Hub** — os arquivos mais importados da sua base de código

## Modo Skyline

Quer algo mais visual? Execute `codemap --skyline` para uma visualização em formato de paisagem urbana da sua base de código:

```bash
codemap --skyline --animate
```

![skyline do codemap](assets/skyline-animated.gif)

Cada prédio representa uma linguagem no seu projeto — prédios mais altos significam mais código. Adicione `--animate` para prédios subindo, estrelas piscando e estrelas cadentes.

## Linguagens Suportadas

O codemap suporta **16 linguagens** para análise de dependências:

| Linguagem | Extensões | Detecção de Import |
|-----------|-----------|-------------------|
| Go | .go | declarações import |
| Python | .py | import, from...import |
| JavaScript | .js, .jsx, .mjs | import, require |
| TypeScript | .ts, .tsx | import, require |
| Rust | .rs | use, mod |
| Ruby | .rb | require, require_relative |
| C | .c, .h | #include |
| C++ | .cpp, .hpp, .cc | #include |
| Java | .java | import |
| Swift | .swift | import |
| Kotlin | .kt, .kts | import |
| C# | .cs | using |
| PHP | .php | use, require, include |
| Dart | .dart | import |
| R | .r, .R | library, require, source |
| Bash | .sh, .bash | source, . |

## Integrações com Claude

O codemap oferece três formas de integração com Claude:

### CLAUDE.md (Recomendado)

Adicione o `CLAUDE.md` incluído à raiz do seu projeto. O Claude Code lê automaticamente e sabe quando executar o codemap:

```bash
cp /caminho/para/codemap/CLAUDE.md seu-projeto/
```

Isso ensina o Claude a:
- Executar `codemap .` antes de iniciar tarefas
- Executar `codemap --deps` ao refatorar
- Executar `codemap --diff` ao revisar alterações

### Skill do Claude Code

Para invocação automática, instale a skill do codemap:

```bash
# Copie para seu projeto
cp -r /caminho/para/codemap/.claude/skills/codemap seu-projeto/.claude/skills/

# Ou instale globalmente
cp -r /caminho/para/codemap/.claude/skills/codemap ~/.claude/skills/
```

Skills são invocadas pelo modelo — Claude decide automaticamente quando usar o codemap baseado nas suas perguntas, sem necessidade de comandos explícitos.

### Servidor MCP

Para a integração mais profunda, execute o codemap como um servidor MCP:

```bash
# Compile o servidor MCP
make build-mcp

# Adicione ao Claude Code
claude mcp add --transport stdio codemap -- /caminho/para/codemap-mcp
```

Ou adicione ao `.mcp.json` do seu projeto:

```json
{
  "mcpServers": {
    "codemap": {
      "command": "/caminho/para/codemap-mcp",
      "args": []
    }
  }
}
```

**Claude Desktop:**

> ⚠️ Claude Desktop não pode ver seus arquivos locais por padrão. Este servidor MCP roda na sua máquina e dá ao Claude essa capacidade.

Adicione ao `~/Library/Application Support/Claude/claude_desktop_config.json`:

```json
{
  "mcpServers": {
    "codemap": {
      "command": "/caminho/para/codemap-mcp"
    }
  }
}
```

**Ferramentas MCP:**
| Ferramenta | Descrição |
|------------|-----------|
| `status` | Verifica conexão MCP e acesso ao sistema de arquivos local |
| `list_projects` | Descobre projetos em um diretório pai (com filtro opcional) |
| `get_structure` | Visualização em árvore do projeto com tamanhos de arquivo e detecção de linguagem |
| `get_dependencies` | Fluxo de dependências com imports, funções e arquivos hub |
| `get_diff` | Arquivos alterados com contagem de linhas e análise de impacto |
| `find_file` | Encontra arquivos por padrão de nome |
| `get_importers` | Encontra todos os arquivos que importam um arquivo específico |

## Roadmap

- [x] **Modo Diff** (`codemap --diff`) — mostra arquivos alterados com análise de impacto
- [x] **Modo Skyline** (`codemap --skyline`) — visualização de paisagem urbana ASCII
- [x] **Fluxo de Dependências** (`codemap --deps`) — análise de função/import com suporte para 16 linguagens
- [x] **Skill Claude Code** — invocação automática baseada em perguntas do usuário
- [x] **Servidor MCP** — integração profunda com 7 ferramentas para análise de base de código

## Contribuindo

Adoramos contribuições!
1.  Faça o fork do repositório.
2.  Crie uma branch (`git checkout -b feature/minha-feature`).
3.  Commit suas alterações.
4.  Push e abra um Pull Request.

## Licença

MIT
</file>
<file path="release.sh">
#!/bin/bash

# release.sh - Automate codemap release process

set -e

# Configuration
TAP_DIR="../homebrew-tap"
FORMULA_FILE="codemap.rb"
REPO_URL="https://github.com/JordanCoin/codemap"

# 1. Check for uncommitted changes
if ! git diff-index --quiet HEAD --; then
    echo "❌ Error: You have uncommitted changes."
    echo "Please commit or stash them before releasing."
    exit 1
fi

# 2. Get current version from git tags
# If no tags exist, default to v1.0 (since user just released 1.0 manually)
CURRENT_VERSION=$(git describe --tags --abbrev=0 2>/dev/null || echo "v1.0")
# Remove 'v' prefix
CURRENT_VERSION=${CURRENT_VERSION#v}

echo "Current version: $CURRENT_VERSION"

# 3. Calculate next version
IFS='.' read -r -a parts <<< "$CURRENT_VERSION"
MAJOR=${parts[0]}
MINOR=${parts[1]}

# User requested logic: 1.9 -> 2.0
if [ "$MINOR" -ge 9 ]; then
    NEXT_MAJOR=$((MAJOR + 1))
    NEXT_MINOR=0
else
    NEXT_MAJOR=$MAJOR
    NEXT_MINOR=$((MINOR + 1))
fi

NEXT_VERSION="$NEXT_MAJOR.$NEXT_MINOR"
TAG_NAME="v$NEXT_VERSION"

echo "Preparing to release: $TAG_NAME"
read -p "Press enter to continue or Ctrl+C to cancel..."

# 4. Create git tag and push
echo "Creating git tag $TAG_NAME..."
git tag "$TAG_NAME"
git push origin "$TAG_NAME"

# 5. Create GitHub Release (if gh is installed)
if command -v gh &> /dev/null; then
    echo "Creating GitHub Release..."
    gh release create "$TAG_NAME" --generate-notes
else
    echo "⚠️ 'gh' CLI not found. Skipping GitHub Release creation."
    echo "You can create it manually at: $REPO_URL/releases/new?tag=$TAG_NAME"
fi

echo "Waiting 5 seconds for GitHub to generate tarball..."
sleep 5

# 6. Calculate SHA256
TARBALL_URL="$REPO_URL/archive/refs/tags/$TAG_NAME.tar.gz"
echo "Downloading tarball from $TARBALL_URL..."
SHA256=$(curl -L -s "$TARBALL_URL" | shasum -a 256 | awk '{print $1}')

if [ -z "$SHA256" ] || [ ${#SHA256} -ne 64 ]; then
    echo "Error: Failed to calculate valid SHA256. Got: $SHA256"
    exit 1
fi

echo "Calculated SHA256: $SHA256"

# 7. Update codemap.rb locally
echo "Updating $FORMULA_FILE..."
# Use sed to replace url and sha256 (macOS compatible sed -i '')
# We match "url" and "sha256" at the start of the line (indented) to avoid matching the resource block
sed -i '' "s|^  url \".*\"|  url \"$TARBALL_URL\"|" "$FORMULA_FILE"
sed -i '' "s|^  sha256 \".*\"|  sha256 \"$SHA256\"|" "$FORMULA_FILE"

# 8. Push local changes
echo "Committing updated formula to main repo..."
git add "$FORMULA_FILE"
git commit -m "Bump version to $TAG_NAME"
git push origin main

# 9. Update Homebrew Tap
if [ -d "$TAP_DIR" ]; then
    echo "Updating Homebrew Tap at $TAP_DIR..."
    cp "$FORMULA_FILE" "$TAP_DIR/$FORMULA_FILE"
    
    # Capture current directory
    CURRENT_DIR=$(pwd)
    
    cd "$TAP_DIR"
    git add "$FORMULA_FILE"
    git commit -m "Update codemap to $TAG_NAME"
    git push origin main
    
    # Return to original directory
    cd "$CURRENT_DIR"
    
    echo "Homebrew Tap updated successfully!"
else
    echo "Warning: Directory $TAP_DIR not found."
    echo "Skipping automatic tap update."
    echo "Please manually copy $FORMULA_FILE to your homebrew-tap repo and push."
fi

echo "✅ Release $TAG_NAME complete!"
</file>


---

## Instructions

Please analyze the provided information and:

1. Understand the task requirements
2. Review the project structure
3. Consider the specified rules and constraints
4. Provide a detailed solution
